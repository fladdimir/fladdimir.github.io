<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Availability and Consistency of an App with Multiple Datasources | wh</title><meta name=keywords content="Debezium,Transactional Outbox,Java,Quarkus,Kafka,S3,Elasticsearch"><meta name=description content="Debezium, Quarkus, Kafka - the Transactional Outbox pattern in action"><meta name=author content><link rel=canonical href=https://fladdimir.github.io/post/document-search/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://fladdimir.github.io/icon.png><link rel=icon type=image/png sizes=16x16 href=https://fladdimir.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://fladdimir.github.io/icon.png><link rel=apple-touch-icon href=https://fladdimir.github.io/apple-touch-icon.png><link rel=mask-icon href=https://fladdimir.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script data-goatcounter=https://fmghio.goatcounter.com/count async src=//gc.zgo.at/count.js></script><meta property="og:title" content="Availability and Consistency of an App with Multiple Datasources"><meta property="og:description" content="Debezium, Quarkus, Kafka - the Transactional Outbox pattern in action"><meta property="og:type" content="article"><meta property="og:url" content="https://fladdimir.github.io/post/document-search/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-12-17T00:00:00+00:00"><meta property="article:modified_time" content="2022-12-17T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Availability and Consistency of an App with Multiple Datasources"><meta name=twitter:description content="Debezium, Quarkus, Kafka - the Transactional Outbox pattern in action"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://fladdimir.github.io/post/"},{"@type":"ListItem","position":2,"name":"Availability and Consistency of an App with Multiple Datasources","item":"https://fladdimir.github.io/post/document-search/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Availability and Consistency of an App with Multiple Datasources","name":"Availability and Consistency of an App with Multiple Datasources","description":"Debezium, Quarkus, Kafka - the Transactional Outbox pattern in action","keywords":["Debezium","Transactional Outbox","Java","Quarkus","Kafka","S3","Elasticsearch"],"articleBody":"Did you ever have the feeling that you know for sure that you did read about something, but you just cannot remember where? Sounds like it would be great to be able to index and search some stuff using a full-text search-engine..\nSimple design Consider the following simple design for an application\npersisting an uploaded document in an object-storage, saving metadata to a database, and indexing the document via a dedicated search-engine: After an upload request succeeded the search-index can be queried and relevant documents can be viewed/downloaded.\nAnd if something goes wrong? As described by Martin Kleppmann in his awesome book Designing Data-Intensive Applications, every component of a system should be expected to fail at any time (in particular when they are connected via network).\nThus, while the design shown above is simple, it may suffer from a couple of issues related to:\nAvailability: In the design shown above, all three data sinks need to be available to successfully process a document upload. If either one of them is (temporarily) unavailable, the request fails. In particular, the expensive indexing operation may become a bottleneck when processing concurrent requests. Consistency: Furthermore, only some of the three storage requests may actually succeed while others may fail. No matter how the three storage requests are ordered, a failure may leave the system in an inconsistent state, e.g. being able to find a document when searching via the index, but not when looking for the data in the object-storage (or vice-versa). These are known as dual-write issues. Decoupling components to improve availability Since the indexing is just relying on data which is also saved to the other stores, it could be postponed so that an upload request can succeed without requiring the search index to be available. In the following design, a message-queue is used to buffer indexing requests for asynchronous processing:\nThis may improve performance characteristics, since the indexing can limit the number of concurrently executed tasks by limiting the number of concurrently processed messages. Furthermore, the asnychronous processing of an indexing request can be automatically retried in case of temporary failures until it is successfully completed.\nHowever, upload requests will now succeed without the document actually being ready to be searched, which may be perceived as a kind of (temporary) inconsistency.\nAnd another problem: this still requires the message-queue to be available at upload-time and may suffer the same inconsistency issues as described above, since sending a message to the queue may also succeed or fail independently of the other storage requests.\nKeeping resources in sync One way to avoid having only some of the requests succeed is to let all resources participate in the same global, distributed transaction, using the 2-phase-commit protocol.\nWhile this is a common approach, it may not be supported by all resources, and it carries some complexity as it may entail manual recovery procedures (such as “system manager intervention” in case of deviating heuristic decisions after communication breakdowns).\nAnother way to avoid dual-write inconsistencies without resorting to 2-phase-commit is to persist the requirement of updating other resources as part of a local transaction, e.g. by using the transactional-outbox pattern.\nIn the following design, the indexing requirement is saved as part of the metadata storage transaction into an outbox table, which is monitored by a message relay component then creating messages for later processing to update the search-index:\nThis way, it is ensured that indexing messages are only created in case the transaction spanning the outbox-table-insert successfully committed.\nGiven a relay component that can asynchonously monitor the outbox table, there is also no need for the relay component or the message-queue to be available at upload-time to let a document upload request succeed.\nNevertheless, one dual-write remains in the system: during the initial processing of the upload request, the document is first stored in the object-storage, and the metadata is then stored together with the indexing request inside the database. In case the object-storage successfully completes the request but the database insertions fail, an orphan document will remain in the object-storage. This problem still needs to be mitigated, e.g. by periodically checking the object-storage for orphan documents which have no persisted metadata.\nAnother thing which needs to be taken into account is the possibility of failures during the processing of outbox entries and messages, since:\nthe relay component needs both to successfully create a message and to acknowledge the processing of the outbox entry the message both needs to be processed successfully and the successfull processing needs to be acknowledged Depending on whether the acknowledgements are done after or before the processing, this results in at-least-once or at-most-once processing.\nChoosing at-least-once to make sure that no documents remain non-indexed, repeated processing of indexing messages can occur. In our case, this should not be a problem since the processing may be made idempotent by first querying the index to check for already indexed documents, or the indexing could just be executed again since it can also be considered idempotent already.\nCDC with Debezium and the transactional-outbox pattern To implement the message relay component, microservices.io lists two options: polling the outbox table for events to be published as well as tailing the transaction log. The latter option is described as “relatively obscure although becoming increasingly common”, which is where Debezium comes into play, allowing for a convenient setup of the log-tailing approach.\nDebezium is a platform for change data capture, which is able to reliably capture data changes from a variety of sources (such as popular relational databases), and to emit these changes as an event stream via a variety of messaging infrastructures.\nIn our sample app, we use PostgreSQL for saving metadata on uploaded documents (and for the outbox table), Minio, an S3-compatible object-storage for the documents themselves, and OpenSearch for indexing and searching (an open-source fork of Elasticsearch). Redpanda is used as an Apache Kafka-like message broker, and Quarkus for implementing the backend of the user-facing application.\nAll required components can be setup locally using docker and docker-compose. Just clone the repository from Github and run the following commands from within the directory:\n# start needed services: # (postgres, minio, opensearch, kafka, debezium) docker-compose up # run the app, listening at http://localhost:8085 # (this will first build the app in a separate container) docker-compose -f docker-compose.app.yml To point it to a running Kafka instance, the Debezium Docker container is supplied an environment variable:\ndebezium: image: debezium/connect depends_on: - kafka environment: BOOTSTRAP_SERVERS: \"kafka:9092\" And for setting up Debezium to tail the transaction log of a specific table in a Postgres database, one request is needed:\ncurl --request POST \\ --url http://localhost:8083/connectors \\ --header 'Content-Type: application/json' \\ --data '{ \"name\": \"upload-service-outbox-connector\", \"config\": { \"connector.class\": \"io.debezium.connector.postgresql.PostgresConnector\", \"plugin.name\": \"pgoutput\", \"database.hostname\": \"localhost\", \"database.port\": \"5432\", \"database.user\": \"postgres\", \"database.password\": \"postgres\", \"database.dbname\" : \"postgres\", \"table.include.list\": \"public.outboxevent\", \"topic.prefix\": \"upload-service-outbox\", \"transforms\": \"outbox\", \"transforms.outbox.type\": \"io.debezium.transforms.outbox.EventRouter\", \"topic.creation.default.partitions\": \"2\", \"topic.creation.default.replication.factor\": \"1\" } }' Publishing and consuming messages with Quarkus For simple setup during development, the request shown above may also be issued automatically during Quarkus startup, e.g. using a microprofile RestClient:\n@IfBuildProfile(\"dev\") @ApplicationScoped public class SetupDebeziumOnStartup { @Inject @RestClient DebeziumSetupService service; public void onStart(@Observes StartupEvent ev) throws Exception { try { service.setupConnector(getBody()); } catch (ConflictException e) { // ok, already setup } } @IfBuildProfile(\"dev\") @ApplicationScoped @RegisterRestClient(baseUri = \"http://debezium:8083\") // configurable @RegisterProvider(ConflictDetectingResponseMapper.class) public static interface DebeziumSetupService { @POST @Path(\"/connectors\") @Consumes(MediaType.APPLICATION_JSON) void setupConnector(JsonObject body); } } Having this configuration in place, the Quarkus app can then start to write to the outbox table, which can be further simplified by including the corresponding Quarkus extension as a Gradle dependency:\nimplementation 'io.debezium:debezium-quarkus-outbox' This allows to write to the outbox table by simply firing a sub-classed ExportedEvent:\n@Inject Event\u003cIndexingRequiredEvent\u003e outbox; @Transactional(value = TxType.MANDATORY) public void indexAsync(DocEntity doc) { IndexingRequiredEvent event = new IndexingRequiredEvent(doc.getFilename(), doc.getFilename(), Instant.now()); outbox.fire(event); } If configured, the Quarkus extension will also take care of immediately deleting entries from the outbox table to prevent it from growing over time.\nDebezium will then start to capture the data changes and publish corresponding messages to the configured Kafka topic.\nReading messages from a Kafka topic with Quarkus is also straightforward as described in the corresponding guide, using Smallrye Reactive Messaging:\n@Incoming(\"indexing-events\") // configured to map to a specific Kafka topic @Blocking(ordered = false) // messages only affect distinct documents, so ordering is expendable public void receive(String message) { String payload = getPayload(message); indexingProcessor.processIndexingRequest(payload); } The message processing should be extended by automatically retrying message processing in case of transient failures (e.g. caused by unavailable upstream services), as well as by eventually handling persistent problems, e.g. in a way described in this article (my personal favorite being the Robinhood approach which allows for the simple implementation of a dedicated UI for flexibly triggering a reprocessing of messages e.g. after bugfixes have been deployed).\nWhen processing an indexing request message, the document to be indexed is first downloaded from the Minio object-storage using the Quarkus Minio extension which provides convenient access to the Minio Java API.\nSubsequently, an indexing request is send to OpenSearch using the low-level RestClient. To be able to index PDF-documents, a special ingest-plugin for attachment processing needs to be installed:\n# custom OpenSearch Dockerfile to install the ingest-attachment plugin FROM opensearchproject/opensearch:2 RUN /usr/share/opensearch/bin/opensearch-plugin install --batch ingest-attachment Further OpenSearch configuration is automatically done on app startup via the RestClient.\nResult The following screenshots show how uploading and searching documents looks like and how the data processing proceeds:\nPDFs can be uploaded by dropping them onto the page:\nFiles are uploaded to Minio, as shown by the built-in UI:\nUpload-requests complete successfully, however no documents have been indexed yet:\nMetadata was saved to Postgres, together with the outbox table entries (automatic deletion disabled):\nDebezium captures the inserts and creates corresponding Kafka messages, which can be inspected e.g. using the Redpanda Console:\nThe app then processes the messages and indexes the documents, which can then be queried. Results also include highlights showing the context in which search terms occured, and the document can be viewed:\nThere should have been a video here but your browser does not seem to support it. Obviously, the presented example system is overengineered. Just using PostgreSQL for storing the documents as well as using it’s built-in full-text search capabilities would probably have resulted in a sufficient user-experience without ever having to worry about more than one single, local, ACID transaction.\nNevertheless, the example could still be extended in numerous ways, e.g. by adding dead-letter handling, taking full advantage of OpenSearch’s various search options, or properly splitting the uploading-related and the indexing-related code into two separate services, which would further decrease the coupling at the code-level and could increase the maintainability. Another interesting extension could include a user notification right after the indexing of an uploaded completed, implemented e.g. by publishing corresponding events and subscribing a dedicated backend service which could then ping the user e.g. via a server-sent event.\n","wordCount":"1808","inLanguage":"en","datePublished":"2022-12-17T00:00:00Z","dateModified":"2022-12-17T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://fladdimir.github.io/post/document-search/"},"publisher":{"@type":"Organization","name":"wh","logo":{"@type":"ImageObject","url":"https://fladdimir.github.io/icon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://fladdimir.github.io/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://fladdimir.github.io/tags/ title=/tags><span>/tags</span></a></li><li><a href=https://fladdimir.github.io/search title="/search (Alt + /)" accesskey=/><span>/search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://fladdimir.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://fladdimir.github.io/post/>Posts</a></div><h1 class=post-title>Availability and Consistency of an App with Multiple Datasources</h1><div class=post-meta><span title='2022-12-17 00:00:00 +0000 UTC'>December 17, 2022</span>&nbsp;·&nbsp;9 min</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#simple-design>Simple design</a></li><li><a href=#and-if-something-goes-wrong>And if something goes wrong?</a></li><li><a href=#decoupling-components-to-improve-availability>Decoupling components to improve availability</a></li><li><a href=#keeping-resources-in-sync>Keeping resources in sync</a></li><li><a href=#cdc-with-debezium-and-the-transactional-outbox-pattern>CDC with Debezium and the transactional-outbox pattern</a></li><li><a href=#publishing-and-consuming-messages-with-quarkus>Publishing and consuming messages with Quarkus</a></li><li><a href=#result>Result</a></li></ul></nav></div></details></div><div class=post-content><p>Did you ever have the feeling that you know for sure that you <em>did</em> read about something, but you just cannot remember <em>where</em>?
Sounds like it would be great to be able to index and search some stuff using a full-text search-engine..</p><h2 id=simple-design>Simple design<a hidden class=anchor aria-hidden=true href=#simple-design>#</a></h2><p>Consider the following simple design for an application</p><ul><li>persisting an uploaded document in an object-storage,</li><li>saving metadata to a database,</li><li>and indexing the document via a dedicated search-engine:</li></ul><p><img loading=lazy src=img/simple_design.drawio.png alt=simple-design></p><p>After an upload request succeeded the search-index can be queried and relevant documents can be viewed/downloaded.</p><h2 id=and-if-something-goes-wrong>And if something goes wrong?<a hidden class=anchor aria-hidden=true href=#and-if-something-goes-wrong>#</a></h2><p>As described by Martin Kleppmann in his awesome book <a href=https://www.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/>Designing Data-Intensive Applications</a>, every component of a system should be expected to fail at any time (in particular when they are connected via network).<br>Thus, while the design shown above is simple, it may suffer from a couple of issues related to:</p><ul><li><strong>Availability</strong>: In the design shown above, all three data sinks need to be available to successfully process a document upload.
If either one of them is (temporarily) unavailable, the request fails.
In particular, the expensive indexing operation may become a bottleneck when processing concurrent requests.</li><li><strong>Consistency</strong>: Furthermore, only some of the three storage requests may actually succeed while others may fail.
No matter how the three storage requests are ordered, a failure may leave the system in an inconsistent state, e.g. being able to find a document when searching via the index, but not when looking for the data in the object-storage (or vice-versa).
These are known as <a href=https://thorben-janssen.com/dual-writes/>dual-write</a> issues.</li></ul><h2 id=decoupling-components-to-improve-availability>Decoupling components to improve availability<a hidden class=anchor aria-hidden=true href=#decoupling-components-to-improve-availability>#</a></h2><p>Since the indexing is just relying on data which is also saved to the other stores, it could be postponed so that an upload request can succeed without requiring the search index to be available.
In the following design, a message-queue is used to buffer indexing requests for asynchronous processing:</p><p><img loading=lazy src=img/message_queue_design.drawio.png alt=message_queue_design></p><p>This may improve performance characteristics, since the indexing can limit the number of concurrently executed tasks by limiting the number of concurrently processed messages.
Furthermore, the asnychronous processing of an indexing request can be automatically retried in case of temporary failures until it is successfully completed.</p><p>However, upload requests will now succeed without the document actually being ready to be searched, which may be perceived as a kind of (temporary) inconsistency.</p><p>And another problem: this still requires the <em>message-queue</em> to be available at upload-time and may suffer the same inconsistency issues as described above, since sending a message to the queue may also succeed or fail independently of the other storage requests.</p><h2 id=keeping-resources-in-sync>Keeping resources in sync<a hidden class=anchor aria-hidden=true href=#keeping-resources-in-sync>#</a></h2><p>One way to avoid having only some of the requests succeed is to let all resources participate in the same global, distributed transaction, using the <a href=https://martinfowler.com/articles/patterns-of-distributed-systems/two-phase-commit.html>2-phase-commit</a> protocol.<br>While this is a common approach, it may not be supported by all resources, and it carries some complexity as it may entail manual recovery procedures (such as <a href=https://docs.jboss.org/jbossas/docs/Server_Configuration_Guide/4/html/TransactionJTA_Overview-Heuristic_exceptions.html>&ldquo;system manager intervention&rdquo;</a> in case of deviating heuristic decisions after communication breakdowns).</p><p>Another way to avoid dual-write inconsistencies without resorting to 2-phase-commit is to persist the requirement of updating other resources as part of a local transaction, e.g. by using the <a href=https://microservices.io/patterns/data/transactional-outbox.html>transactional-outbox pattern</a>.<br>In the following design, the indexing requirement is saved as part of the metadata storage transaction into an <em>outbox table</em>, which is monitored by a message relay component then creating messages for later processing to update the search-index:</p><p><img loading=lazy src=img/transactional_outbox_design.drawio.png alt=transactional_outbox_design></p><p>This way, it is ensured that indexing messages are only created in case the transaction spanning the outbox-table-insert successfully committed.<br>Given a relay component that can asynchonously monitor the outbox table, there is also no need for the relay component or the message-queue to be available at upload-time to let a document upload request succeed.</p><p>Nevertheless, <strong>one dual-write remains</strong> in the system: during the initial processing of the upload request, the document is first stored in the object-storage, and the metadata is then stored together with the indexing request inside the database.
In case the object-storage successfully completes the request but the database insertions fail, an orphan document will remain in the object-storage.
This problem still needs to be mitigated, e.g. by periodically checking the object-storage for orphan documents which have no persisted metadata.</p><p>Another thing which needs to be taken into account is the possibility of failures during the processing of outbox entries and messages, since:</p><ul><li>the relay component needs both to successfully create a message and to acknowledge the processing of the outbox entry</li><li>the message both needs to be processed successfully and the successfull processing needs to be acknowledged</li></ul><p>Depending on whether the acknowledgements are done after or before the processing, this results in <em>at-least-once</em> or <em>at-most-once</em> processing.<br>Choosing at-least-once to make sure that no documents remain non-indexed, repeated processing of indexing messages can occur.
In our case, this should not be a problem since the processing may be made <a href=https://microservices.io/patterns/communication-style/idempotent-consumer.html>idempotent</a> by first querying the index to check for already indexed documents, or the indexing could just be executed again since it can also be considered idempotent already.</p><h2 id=cdc-with-debezium-and-the-transactional-outbox-pattern>CDC with Debezium and the transactional-outbox pattern<a hidden class=anchor aria-hidden=true href=#cdc-with-debezium-and-the-transactional-outbox-pattern>#</a></h2><p>To implement the message relay component, <em>microservices.io</em> lists two options: <a href=https://microservices.io/patterns/data/polling-publisher.html>polling the outbox table for events to be published</a> as well as <a href=https://microservices.io/patterns/data/transaction-log-tailing.html>tailing the transaction log</a>.
The latter option is described as <em>&ldquo;relatively obscure although becoming increasingly common&rdquo;</em>, which is where <em>Debezium</em> comes into play, allowing for a convenient setup of the log-tailing approach.</p><p><a href=https://debezium.io/>Debezium</a> is a platform for <em>change data capture</em>, which is able to reliably capture data changes from a <a href=https://debezium.io/documentation/reference/stable/connectors/index.html>variety of sources</a> (such as popular relational databases), and to emit these changes as an event stream via a <a href=https://debezium.io/documentation/reference/stable/architecture.html>variety of messaging infrastructures</a>.</p><p>In our sample app, we use <a href=https://www.postgresql.org/>PostgreSQL</a> for saving metadata on uploaded documents (and for the outbox table), <a href=https://min.io/>Minio</a>, an <a href=https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html>S3</a>-compatible object-storage for the documents themselves, and <a href=https://opensearch.org/>OpenSearch</a> for indexing and searching (an open-source fork of Elasticsearch).
<a href=https://redpanda.com/>Redpanda</a> is used as an <a href=https://kafka.apache.org/>Apache Kafka</a>-like message broker, and <a href=https://quarkus.io/>Quarkus</a> for implementing the backend of the user-facing application.</p><p>All required components can be setup locally using docker and docker-compose.
Just clone the <a href=https://github.com/fladdimir/document-search>repository from Github</a> and run the following commands from within the directory:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=c1># start needed services:</span>
</span></span><span class=line><span class=cl><span class=c1># (postgres, minio, opensearch, kafka, debezium)</span>
</span></span><span class=line><span class=cl>docker-compose up
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># run the app, listening at http://localhost:8085</span>
</span></span><span class=line><span class=cl><span class=c1># (this will first build the app in a separate container)</span>
</span></span><span class=line><span class=cl>docker-compose -f docker-compose.app.yml
</span></span></code></pre></div><p>To point it to a running Kafka instance, the Debezium Docker container is supplied an environment variable:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yml data-lang=yml><span class=line><span class=cl><span class=w>  </span><span class=nt>debezium</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>debezium/connect</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>BOOTSTRAP_SERVERS</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;kafka:9092&#34;</span><span class=w>
</span></span></span></code></pre></div><p>And for setting up Debezium to tail the transaction log of a specific table in a Postgres database, <a href=https://debezium.io/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/>one request is needed</a>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>curl --request POST <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --url http://localhost:8083/connectors <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --header <span class=s1>&#39;Content-Type: application/json&#39;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --data <span class=s1>&#39;{
</span></span></span><span class=line><span class=cl><span class=s1>  &#34;name&#34;: &#34;upload-service-outbox-connector&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>  &#34;config&#34;: {
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;connector.class&#34;: &#34;io.debezium.connector.postgresql.PostgresConnector&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;plugin.name&#34;: &#34;pgoutput&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;database.hostname&#34;: &#34;localhost&#34;, 
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;database.port&#34;: &#34;5432&#34;, 
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;database.user&#34;: &#34;postgres&#34;, 
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;database.password&#34;: &#34;postgres&#34;, 
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;database.dbname&#34; : &#34;postgres&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;table.include.list&#34;: &#34;public.outboxevent&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;topic.prefix&#34;: &#34;upload-service-outbox&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;transforms&#34;: &#34;outbox&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;transforms.outbox.type&#34;: &#34;io.debezium.transforms.outbox.EventRouter&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;topic.creation.default.partitions&#34;: &#34;2&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;topic.creation.default.replication.factor&#34;: &#34;1&#34;
</span></span></span><span class=line><span class=cl><span class=s1>  }
</span></span></span><span class=line><span class=cl><span class=s1>}&#39;</span>
</span></span></code></pre></div><h2 id=publishing-and-consuming-messages-with-quarkus>Publishing and consuming messages with Quarkus<a hidden class=anchor aria-hidden=true href=#publishing-and-consuming-messages-with-quarkus>#</a></h2><p>For simple setup during development, the request shown above may also be issued automatically during Quarkus startup, e.g. using a microprofile <code>RestClient</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=nd>@IfBuildProfile</span><span class=o>(</span><span class=s>&#34;dev&#34;</span><span class=o>)</span> 
</span></span><span class=line><span class=cl><span class=nd>@ApplicationScoped</span>
</span></span><span class=line><span class=cl><span class=kd>public</span> <span class=kd>class</span> <span class=nc>SetupDebeziumOnStartup</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@Inject</span>
</span></span><span class=line><span class=cl>    <span class=nd>@RestClient</span>
</span></span><span class=line><span class=cl>    <span class=n>DebeziumSetupService</span> <span class=n>service</span><span class=o>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>onStart</span><span class=o>(</span><span class=nd>@Observes</span> <span class=n>StartupEvent</span> <span class=n>ev</span><span class=o>)</span> <span class=kd>throws</span> <span class=n>Exception</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=k>try</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=n>service</span><span class=o>.</span><span class=na>setupConnector</span><span class=o>(</span><span class=n>getBody</span><span class=o>());</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span> <span class=k>catch</span> <span class=o>(</span><span class=n>ConflictException</span> <span class=n>e</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=c1>// ok, already setup
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=nd>@IfBuildProfile</span><span class=o>(</span><span class=s>&#34;dev&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>    <span class=nd>@ApplicationScoped</span>
</span></span><span class=line><span class=cl>    <span class=nd>@RegisterRestClient</span><span class=o>(</span><span class=n>baseUri</span> <span class=o>=</span> <span class=s>&#34;http://debezium:8083&#34;</span><span class=o>)</span> <span class=c1>// configurable
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nd>@RegisterProvider</span><span class=o>(</span><span class=n>ConflictDetectingResponseMapper</span><span class=o>.</span><span class=na>class</span><span class=o>)</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kd>static</span> <span class=kd>interface</span> <span class=nc>DebeziumSetupService</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nd>@POST</span>
</span></span><span class=line><span class=cl>        <span class=nd>@Path</span><span class=o>(</span><span class=s>&#34;/connectors&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>        <span class=nd>@Consumes</span><span class=o>(</span><span class=n>MediaType</span><span class=o>.</span><span class=na>APPLICATION_JSON</span><span class=o>)</span>
</span></span><span class=line><span class=cl>        <span class=kt>void</span> <span class=nf>setupConnector</span><span class=o>(</span><span class=n>JsonObject</span> <span class=n>body</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>Having this configuration in place, the Quarkus app can then start to write to the outbox table, which can be further simplified by including the corresponding <a href=https://debezium.io/documentation/reference/stable/integrations/outbox.html>Quarkus extension</a> as a Gradle dependency:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gradle data-lang=gradle><span class=line><span class=cl><span class=n>implementation</span> <span class=s1>&#39;io.debezium:debezium-quarkus-outbox&#39;</span>
</span></span></code></pre></div><p>This allows to write to the outbox table by simply firing a sub-classed <code>ExportedEvent</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@Inject</span>
</span></span><span class=line><span class=cl>    <span class=n>Event</span><span class=o>&lt;</span><span class=n>IndexingRequiredEvent</span><span class=o>&gt;</span> <span class=n>outbox</span><span class=o>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@Transactional</span><span class=o>(</span><span class=n>value</span> <span class=o>=</span> <span class=n>TxType</span><span class=o>.</span><span class=na>MANDATORY</span><span class=o>)</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>indexAsync</span><span class=o>(</span><span class=n>DocEntity</span> <span class=n>doc</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>IndexingRequiredEvent</span> <span class=n>event</span> <span class=o>=</span> <span class=k>new</span> <span class=n>IndexingRequiredEvent</span><span class=o>(</span><span class=n>doc</span><span class=o>.</span><span class=na>getFilename</span><span class=o>(),</span> <span class=n>doc</span><span class=o>.</span><span class=na>getFilename</span><span class=o>(),</span>
</span></span><span class=line><span class=cl>                <span class=n>Instant</span><span class=o>.</span><span class=na>now</span><span class=o>());</span>
</span></span><span class=line><span class=cl>        <span class=n>outbox</span><span class=o>.</span><span class=na>fire</span><span class=o>(</span><span class=n>event</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span></code></pre></div><p>If configured, the Quarkus extension will also take care of <a href=https://debezium.io/documentation/reference/stable/integrations/outbox.html#quarkus-debezium-outbox-remove-after-insert>immediately deleting entries from the outbox table</a> to prevent it from growing over time.</p><p>Debezium will then start to capture the data changes and publish corresponding messages to the configured Kafka topic.</p><p>Reading messages from a Kafka topic with Quarkus is also straightforward as described in the corresponding <a href=https://quarkus.io/guides/kafka>guide</a>, using <a href=https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/3.4/kafka/kafka.html>Smallrye Reactive Messaging</a>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl>    <span class=nd>@Incoming</span><span class=o>(</span><span class=s>&#34;indexing-events&#34;</span><span class=o>)</span> <span class=c1>// configured to map to a specific Kafka topic
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nd>@Blocking</span><span class=o>(</span><span class=n>ordered</span> <span class=o>=</span> <span class=kc>false</span><span class=o>)</span> <span class=c1>// messages only affect distinct documents, so ordering is expendable
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>receive</span><span class=o>(</span><span class=n>String</span> <span class=n>message</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>String</span> <span class=n>payload</span> <span class=o>=</span> <span class=n>getPayload</span><span class=o>(</span><span class=n>message</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=n>indexingProcessor</span><span class=o>.</span><span class=na>processIndexingRequest</span><span class=o>(</span><span class=n>payload</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span></code></pre></div><p>The message processing should be extended by <a href=https://quarkus.io/guides/smallrye-fault-tolerance>automatically retrying</a> message processing in case of transient failures (e.g. caused by unavailable upstream services), as well as by eventually handling persistent problems, e.g. in a way described in <a href=https://www.kai-waehner.de/blog/2022/05/30/error-handling-via-dead-letter-queue-in-apache-kafka/>this article</a> (my personal favorite being the <a href=https://www.confluent.io/events/current-2022/dead-letter-queues-for-kafka-consumers-in-robinhood/>Robinhood approach</a> which allows for the simple implementation of a dedicated UI for flexibly triggering a reprocessing of messages e.g. after bugfixes have been deployed).</p><p>When processing an indexing request message, the document to be indexed is first downloaded from the Minio object-storage using the <a href=https://github.com/quarkiverse/quarkus-minio>Quarkus Minio extension</a> which provides convenient access to the <a href=https://min.io/docs/minio/linux/developers/java/API.html>Minio Java API</a>.</p><p>Subsequently, an indexing request is send to OpenSearch using the low-level <a href=https://quarkus.io/guides/elasticsearch>RestClient</a>.
To be able to index PDF-documents, a special ingest-plugin for attachment processing needs to be installed:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-Dockerfile data-lang=Dockerfile><span class=line><span class=cl><span class=c># custom OpenSearch Dockerfile to install the ingest-attachment plugin</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>FROM</span><span class=s> opensearchproject/opensearch:2</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> /usr/share/opensearch/bin/opensearch-plugin install --batch ingest-attachment<span class=err>
</span></span></span></code></pre></div><p>Further OpenSearch configuration is automatically done on app startup via the RestClient.</p><hr><h2 id=result>Result<a hidden class=anchor aria-hidden=true href=#result>#</a></h2><p>The following screenshots show how uploading and searching documents looks like and how the data processing proceeds:</p><p>PDFs can be uploaded by dropping them onto the page:</p><p><img loading=lazy src=img/upload_documents.gif alt=upload_documents></p><hr><p>Files are uploaded to Minio, as shown by the built-in UI:</p><p><img loading=lazy src=img/minio_console.png alt=minio_console></p><hr><p>Upload-requests complete successfully, however no documents have been indexed yet:</p><p><img loading=lazy src=img/index_empty.png alt=empty_index></p><hr><p>Metadata was saved to Postgres, together with the outbox table entries (automatic deletion disabled):</p><p><img loading=lazy src=img/outbox_table.png alt=outbox_table></p><hr><p>Debezium captures the inserts and creates corresponding Kafka messages, which can be inspected e.g. using the <a href=https://github.com/redpanda-data/console>Redpanda Console</a>:</p><p><img loading=lazy src=img/kafka_topic.png alt=kafka_topic></p><hr><p>The app then processes the messages and indexes the documents, which can then be queried.
Results also include <a href=https://opensearch.org/docs/2.4/opensearch/search/highlight/>highlights</a> showing the context in which search terms occured, and the document can be viewed:</p><video style=width:100% autoplay loop controls src=img/search.mp4 type=video/mp4>
There should have been a video here but your browser does not seem
to support it.</video><hr><p>Obviously, the presented example system is overengineered.
Just using PostgreSQL for storing the documents as well as using it&rsquo;s built-in full-text search capabilities would probably have resulted in a sufficient user-experience without ever having to worry about more than one single, local, ACID transaction.<br>Nevertheless, the example could still be extended in numerous ways, e.g. by adding dead-letter handling, taking full advantage of OpenSearch&rsquo;s various search options, or properly splitting the uploading-related and the indexing-related code into two separate services, which would further decrease the coupling at the code-level and could increase the maintainability.
Another interesting extension could include a user notification right after the indexing of an uploaded completed, implemented e.g. by publishing corresponding events and subscribing a dedicated backend service which could then ping the user e.g. via a server-sent event.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://fladdimir.github.io/tags/debezium/>Debezium</a></li><li><a href=https://fladdimir.github.io/tags/transactional-outbox/>Transactional Outbox</a></li><li><a href=https://fladdimir.github.io/tags/java/>Java</a></li><li><a href=https://fladdimir.github.io/tags/quarkus/>Quarkus</a></li><li><a href=https://fladdimir.github.io/tags/kafka/>Kafka</a></li><li><a href=https://fladdimir.github.io/tags/s3/>S3</a></li><li><a href=https://fladdimir.github.io/tags/elasticsearch/>Elasticsearch</a></li></ul><nav class=paginav><a class=prev href=https://fladdimir.github.io/post/testing-legacy-code/><span class=title>« Prev</span><br><span>Testing Legacy Software</span></a>
<a class=next href=https://fladdimir.github.io/post/stack-2022/><span class=title>Next »</span><br><span>Credit-Card-Free Web Application Stack for 2022</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://fladdimir.github.io/>wh</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>