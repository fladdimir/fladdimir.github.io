<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Testing Legacy Software | wh</title>
<meta name=keywords content="Testing,Legacy Code,Clean Architecture,Java"><meta name=description content="On useful automated tests and how to get there when not developing a system from scratch"><meta name=author content><link rel=canonical href=https://fladdimir.github.io/post/testing-legacy-code/><link crossorigin=anonymous href=/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://fladdimir.github.io/icon.png><link rel=icon type=image/png sizes=16x16 href=https://fladdimir.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://fladdimir.github.io/icon.png><link rel=apple-touch-icon href=https://fladdimir.github.io/apple-touch-icon.png><link rel=mask-icon href=https://fladdimir.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script data-goatcounter=https://fmghio.goatcounter.com/count async src=//gc.zgo.at/count.js></script><meta property="og:title" content="Testing Legacy Software"><meta property="og:description" content="On useful automated tests and how to get there when not developing a system from scratch"><meta property="og:type" content="article"><meta property="og:url" content="https://fladdimir.github.io/post/testing-legacy-code/"><meta property="article:section" content="post"><meta property="article:published_time" content="2023-04-10T00:00:00+00:00"><meta property="article:modified_time" content="2023-04-10T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Testing Legacy Software"><meta name=twitter:description content="On useful automated tests and how to get there when not developing a system from scratch"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://fladdimir.github.io/post/"},{"@type":"ListItem","position":2,"name":"Testing Legacy Software","item":"https://fladdimir.github.io/post/testing-legacy-code/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Testing Legacy Software","name":"Testing Legacy Software","description":"On useful automated tests and how to get there when not developing a system from scratch","keywords":["Testing","Legacy Code","Clean Architecture","Java"],"articleBody":"Automated testing has become an essential part of software development. Good test support is a core feature of many modern application frameworks, and there is rarely a debate about whether tests should be written or not, but rather on how and which tests should be written.\nHowever, there is also a reality of some existing systems having few - if any - automated tests in place. While this might not be a problem per se, a degrading understanding of a system can make it harder to confidently make necessary changes - up to a point where no one dares to touch anything anymore, in fear of not noticing that a change breaks existing functionality. Having a suite of automated tests in place can greatly reduce that risk and thereby enable the continuous evolution of the system.\nTo explore this in some more detail, three questions will be discussed in the following:\nWhat are properties that automated tests should have in order to maximize the value they provide over the lifetime of a system? How can systems be designed to facilitate the creation of useful tests? What can be done if a system is not (yet) designed in a way which allows to accomodate such tests? Most of the aspects reflected on below are described in-depth i.a. in the following books:\nWorking Effectively with Legacy Code, M. C. Feathers, 2005 - an often-recommended classic motivating why to create automated tests, and how to make it possible [Feathers, 2005] Software Engineering at Google, T. Winters, T. Manshreck, and H. Wright, 2020 - devoting several chapters to the way tests are used in that huge software organization [Winters et al., 2020] Clean Architecture, R. C. Martin, 2017 - containing general advice on how to structure (testable) systems [Martin, 2017] Object-Oriented Reengineering Patterns, S. Demeyer, S. Ducasse, O. Nierstrasz, 2003 - a collection of approaches for restructuring existing systems, showing ways to improve the design, and describing strategies to use and grow test-suites [Demeyer et al., 2003] 1. Working with legacy code Most relevant software lives for long periods of time and the continuous adaption to new requirements is a relevant challenge.\nWith growing size, age, and complexity of a system, it seems not to be unusual for even seemingly simple changes to take longer and longer to be implemented, and to carry increasing risks of breaking existing functionality. Of course, this holds especially true for systems which are developed just relying on “working-with-care” (sometimes also known as “professionalism”). When it comes to making further changes, [Feathers, 2005] describes developers to then “edit and pray” that the change does not break anything, building confidence upon their experience with the system and some exploratory manual testing.\nObviously this only gets riskier, once different people start to extend different parts of the system, and once experienced contributors leave the team while new developers join. Slowly, the architectural vision of the design starts to blur, and the understanding of how the systems works gets lost up to the point where no one really knows anymore what is going on. Needless to say, that just continues to increase the risk of breaking changes (ultimately, how could one do any regression testing when not even knowing at all how the system is supposed to behave?).\nAs an alternative way, Feathers describes an approach of covering existing functionality with automated tests, providing a “safety net”, which allows for controlled refactorings as well as the controlled addition of new features or fixes. This way, the chance to break existing functionality is reduced and all developers (experienced or not) are provided with confidence into the correctness of the software.\nSo how could those automated tests look like?\n2. Properties of useful automated tests [Winters et al., 2020] mention different dimensions to classify automated tests:\nscope (describing the amount of validated code) narrow (e.g. class, or even single function) medium (e.g. multiple classes) large (e.g. system / end-to-end tests, verifying the interaction of sub-systems) size (describing the amount of resources the test needs) small (the test and its dependencies all run inside a single thread) medium (everything runs locally, in different processes, network calls to localhost, or file-system access are allowed) large (calls to external systems are allowed) Fast and deterministic The execution time of a test is typically determined by its size, and the larger the test the more flaky it tends to be, since e.g. network calls to external systems may timeout (flakiness - the extent to which a test tends to fail sometimes, not being caused by any actually problematic code change).\nTo keep a test suite fast and deterministic, it is recommended to rely on a majority of small tests whenever possible (not leaving room for any flakiness, and even providing the option for simple parallel execution by multiple threads). Furthermore, [Winters et al., 2020] emphasize the fact that only fast, small tests are practical to be run as part of the normal development workflow, and experience shows that longer-running tests tend to be not executed. However, the importance of larger tests is also acknowledged in order to cover aspects that small tests cannot verify.\nRobust and maintainable When it comes to scope, there are different aspects to keep in mind:\nOn the one hand, narrow-scoped tests (e.g. testing a single implementation class) usually allow for a quick and precise analysis of the root-cause in the event of failure. On the other hand, narrow-scoped tests tend to be brittle (they break on unrelated changes), since a simple redistribution of some logic between collaborating classes can already cause a lot of test failures. [Winters et al., 2020] recommend to test business-relevant behaviour via the public API instead of directly depending on implementation details, to avoid frequently changing the tests (“Don’t depend on volatile things!” - [Martin, 2017] even recommends to use a dedicated testing API to shield tests from changing implementation details).\nPure refactorings should not break tests, and doing so may indicate an innapropriate level of abstraction (test behaviour - not methods/classes). The same holds true for changes that introduce new features or fix bugs, which also should not require an adjustment of existing tests. So with respect to scope, following these recommendations may typically result in testing at least several related classes together.\nAnother interesting aspect of scope is that it is defined by the amount of validated code, as opposed to executed. In particular, [Winters et al., 2020] argue that - if possible - a test should stick with the real implementations of the dependencies of the tested code, instead of replacing them with test doubles by default (preferring classical over mockist testing):\n“Using real implementations can cause your test to fail if there is a bug in the real implementation. This is good! You want your tests to fail in such cases because it indicates that your code won’t work properly in production.”\nThis is especially true when the dependency itself is not properly tested on its own.\nObviously, dependencies on things running outside the test thread (e.g. external services, databases) must be replaced by test doubles in order to keep the test small. Here, [Winters et al., 2020] prefer the usage of lightweight fake implementations over mocks to be able to test state instead of interactions.\nWith respect to scope, [Feathers, 2005] also mentions the importance of narrow-scoped tests, i.a. because of the simplicity with which failure causes can be located.\nWhile I certainly also like this property, I also fear that it tends to motivate me to slavishly create tests for each and every single class, leading to the brittleness problems described above. More often than not it should be easy to spot the root cause of a problem even among a couple of collaborators. Nevertheless, this does of course not mean that I would oppose occasionally making some pure function package-private to be able to quickly test some nasty regex in isolation.\n3. How to make code untestable While it may sound just great to have a blazingly fast, deterministic, robust, and maintainable test suite in place, it really needs to be kept in mind that this must not be an afterthought during development. If not carefully taken into account, it is surprisingly easy to end up with code which makes it incredibly hard to add any useful (fast, small) automated tests ex-post (an endavour hard to describe other than painful).\nConsider the following Java sample:\n@Service class CalculationServiceImpl implements CalculationService { /** * @return true, if successful */ @Override public boolean calculate(int input) { Result result = new FirstCalculator().calculateFirstPart(input); // 1. SecondProcessor.calculateSecondPart(result, input); // 2. SessionContext.store(\"myResult1\", result); // 3. boolean isSuccessful = result.getValue32() == 13; // 4. if (isSuccessful) { ThirdProcessor.calculateThirdPart(); // 5. NotificationService.sendKafkaMessageToCalculationsTopic(); // 6. } return isSuccessful; } } class FirstCalculator { Result calculateFirstPart(int input) { int baseValue = new MariaDbDatabaseAccess().getBaseValue(); // 1.1 // [...] some calculation logic return result; } } class SecondProcessor { static void calculateSecondPart(Result result, int input) { int extraInfo = CalculationHelperWebService.getExtraInfo(); // 2.1 // [...] some calculation logic } } class ThirdProcessor { static void calculateThirdPart() { Result result = (Result) (SessionContext.get(\"myResult1\")); // 5.1 // [...] some calculation logic } } // [...] various other classes Imagine that we’d want to write a test for the calculate functionality of the CalculationService (public API).\nWe notice that the actual calculation logic seems to be distributed over at least three different collaborator classes, but the distribution seems rather arbitrarily. In order to avoid creating a brittle test which is broken by the first upcoming refactoring, we avoid the temptation to test any of the three calculation parts in isolation.\nnew FirstCalculator().calculateFirstPart(input)\nFirst, there is a call to a collaborating class (FirstCalculator), which in turn collects some additional information from a database (1.1):\nint baseValue = new MariaDbDatabaseAccess().getBaseValue();\nThis may already become a first problem, since there is no simple way to replace the MariaDB with a lightweight fake implementation, so that we would need to either run the complete test against a real MariaDB (making the test larger), or resort to advanced mocking library features (which are hopefully available).\nSecondProcessor.calculateSecondPart(result, input);\nThen the collaborator SecondProcessor is called, which first fetches some needed information from a remote service via network before running its calculations (2.1):\nint extraInfo = CalculationHelperWebService.getExtraInfo();\nAgain, replacing this static call may require advanced magic to be available (again also including possibly surprising side-effects in case the static mock is not properly cleaned up at the end of the test).\nSessionContext.store(\"myResult1\", result);\nThis shows another possibly hard-to-replace static call that depends on some framework-provided (thread-local?) session state to be setup, so that later parts of the calculation logic can then retrieve that state (e.g. 5.1 and 6). Relying on side-effects like this is just a great option to create a sufficiently confusing data flow which does not ease creating relevant test cases in general.\nWhy would one ever resort to using some sort of SessionContext at all here? Well, at least it allowed us to share information between different places without having been required to refactor much existing logic which would have been risky to touch..\nboolean isSuccessful = result.getValue32() == 13;\nAt 4. the orchestrating logic of the calculate method is suspended by some core business logic, breaking with the abstraction level of the method. Apart from making it harder to understand the now even more widespread calculation logic, this does not really hinder creating the test. It merely serves as an example of needed refactoring and is probably again a symptom of missing tests, since it was probably too risky to put it elsewhere in the first place. This also illustrates the importance of testing via stable interfaces (public API), since implementation details such as the distribution of logic among collaborating classes may be likely to change - especially in systems where missing tests prevented adding new features at the right places.\nFinally, 5. just represents some dependency on the SessionContext, and 6. another hard-coded dependency on external systems. Obviously the overall sample is kept short and the length of realistic methods won’t contribute a lot to make writing tests any easier.\nSumming up some general problems which may add up over time and result in hard-to-test code:\nhard-wired dependencies to external systems (hard to fake/mock) dependencies hidden deep in the core business logic behavior relying on side-effects and arcane features of the used framework mangling different aspects and abstraction levels, just to avoid changing code at other places 4. Design for testability As shown in the previous part, testability should be a key aspect during system design/implementation. So how can code be structured to allow for useful tests?\nProviding Seams The Seam is a central concept of [Feathers, 2005], described as “a place to alter behavior without editing that place”. In particular, Object Seams are recommended, i.e. providing places to allow replacing problematic dependencies with subtypes.\nDependency injection (DI) is a central functionality of many popular frameworks such as Spring or Quarkus (just to give some Java examples), and both DI containers allow to replace existing bindings of (problematic) implementation classes with mocks or own fake implementations. However, when using constructor injection it is also simply possible to construct instances of the classes under test by hand, without relying on any DI framework functionality. Of course, this manual construction has the disadvantage of having to manually create the complete dependency graph, but may speed up test execution significantly.\nFor the problematic FirstCalculator above, a better testable version could look like this:\nclass FirstCalculator { private final MariaDbDatabaseAccess dbAccess; // constructor allows to provide fake/mock dependencies FirstCalculator(MariaDbDatabaseAccess dbAccess) { this.dbAccess = dbAccess; } Result calculateFirstPart(int input) { int baseValue = dbAccess.getBaseValue(); // [...] some calculation logic return result; } } This way, a fake-implementation of MariaDbDatabaseAccess could be provided (subclassing it and overriding problematic behavior).\nAdditionally, the CalculationServiceImpl would also need to offer a seam by providing a constructor allowing to inject the FirstCalculator instance with the faked database access dependency:\n@Service class CalculationServiceImpl implements CalculationService { private final FirstCalculator firstCalculator; // constructor allows to provide test-specific dependencies CalculationServiceImpl(FirstCalculator firstCalculator) { this.firstCalculator = firstCalculator; } @Override public boolean calculate(int input) { Result result = firstCalculator.calculateFirstPart(input); // [...] } } (Luckily, lombok may save us at least some of this constructor boilerplate.)\nClean architecture [Martin, 2017] describes clean architecture, a general approach to structure a system so that central business logic is properly separated from external dependencies. The main idea is also at the core of similar concepts like hexagonal architecture or onion architecture.\nIn particular, a Dependency Rule is formulated which states that:\n“Source code dependencies must point only inward, toward higher-level policies.”\nWhen core business logic needs to invoke functionality from outer layers, this dependency must be inverted (Dependency Inversion Principle), so that the source-code dependency still only points inward, opposing the flow of control.\nConsider the sample above:\nA cleaner version of the code sample shown above could be realized as follows, replacing the low-level MariaDB dependency of the core logic with the abstract interface BaseValueProvider:\n// core business logic class FirstCalculator { private final BaseValueProvider baseValueProvider; // abstract dependency // constructor allows to provide fake/mock dependencies FirstCalculator(BaseValueProvider baseValueProvider) { this.baseValueProvider = baseValueProvider; } Result calculateFirstPart(int input) { // core logic directly invokes functionality from outer layers, // but has no source-code dependency int baseValue = baseValueProvider.getBaseValue(); // [...] some calculation logic return result; } interface BaseValueProvider { // part of the core business logic int getBaseValue(); // abstract functionality needed by the core logic } } // --- // implementation detail, outside the core logic class MariaDbDatabaseAccess implements BaseValueProvider { @Override public int getBaseValue() { // [...] actual MariaDB access logic } } As a result, central business logic can be kept independent from external influences and low-level details, be it frameworks, UI, or databases. This does not only make it simpler to replace a specific database or UI technology when a popular new one emerges, but also makes it simple to provide seams which allow to swap out problematic dependencies with mocks or lightweight fake implementations. Consequently, the creation of small, useful automated tests is facilitated.\nWhen implementing clean architectures it may also be helpful to enforce the dependency rule e.g. in Java with help of ArchUnit tests.\nSidenote: on the over-usage of Java interfaces Another, somehow related and sometimes observed problem in Java is a general tendency towards the over-usage of interfaces. Consider the sample introduced above:\n@Service class CalculationServiceImpl implements CalculationService { @Override public boolean calculate(int input) { // [...] } } Imagine the calculate method being called exclusively by some CalculationRestController upon an HTTP-request initiated by user interaction. In that case, there would not be any problem having a direct dependency from the CalculationRestController (low-level detail) towards the CalculationServiceImpl (core business logic). Infact, we might just be able reduce some clutter by removing the useless CalculationService interface as well as the annoying Impl postfix. In many cases using interfaces is not required and should be a conscious decision rather than the default.\n5. Reengineering for testability Given some system that was not designed with clean architecture and useful automated tests in mind, how can we still get there? [Demeyer et al., 2003] give a number of useful recommendations on reengineering, i.e. on how to restructure systems in an improved form.\nOne chapter touches on the question of which parts of a system to prioritize. Understandibly, reengineering efforts should not focus on stable, flawlessly working parts, but rather on the faulty ones, which require change and suffer the worst from reliance on outdated technologies, developer fluctuation, insufficient documentation, duplicated code, or tangled structure.\nStarting with the most problematic parts, the core business functionalities as well as dependencies and auxiliary functions need to be analyzed to identify a cleaner, more testable target design as well as the corresponding target scope of useful automated tests.\nIn order to safely make the necessary code changes (e.g. introducing seams to break and invert dependencies), [Demeyer et al., 2003] recommend to incrementally introduce tests for the parts of the system which are changed.\nHowever, isn’t there the chicken-and-egg problem of already requiring tests to safely do changes which only enable the creation of tests?\nYes, that’s what [Feathers, 2005] calls the legacy code dilemma. To alleviate this problem, a two-step approach can be taken:\nstart with larger-sized tests which allow to keep as many dependencies in place as possible, minimizing the amount of necessary code changes to create the tests refactor the covered code so that creating small tests of the core business logic becomes feasible First, this may e.g. involve running tests against an existing database or other external services. Even though running the larger tests may take time and will be subject to flakiness, it will still provide the necessary safety net to incrementally move towards a cleaner design with faster tests.\n[Demeyer et al., 2003] advise to start with black-box tests of big abstractions, focusing on business values, instead of individual sub-components. In particular, one recommendation is to record business rules as tests, aiming to represent core functionality by a set of canonical examples with well-defined actions and clear, observable results. Since covering all rules may not be feasible (depending on their number and the runtime of the larger tests), it is suggested to start with essential cases. The 80/20 rule may apply here as well, maybe 80% of production cases only exercise 20% of the business logic?.\nHaving the larger-sized tests in place, the necessary refactorings can be done to break the problematic dependencies and introduce a cleaner architecture. Subsequently, the implemented test scenarios of the larger-sized tests can be nicely reused to create fast-running small tests, swapping out problematic dependencies with leightweight fake implementations. Furthermore, more small tests can be added to further increase the amount of covered business rules.\nWhile the small tests can be run quickly and often as part of the local development workflow, the larger-sized tests should still be run on a regular basis in order to verify the functionality against the actual dependencies. (Drawing from own experience, errors seem to come as often from self-developed business logic as from unexpected behavior of dependencies - be it caused by actual bugs or just by unclear documentation.)\nSumming up To be fast and not flaky, automated tests must be small in size (running inside a single thread). To be maintainable and not brittle, automated tests should test through stable interfaces (public API), focusing on business requirements instead of being too narrow-scoped. This leaves room to freely refactor the internal implementation. Being able to build useful automated tests requires conscious management of source code dependencies. This needs to be kept in mind when designing and implementing a system. Adding useful automated tests to a grown system ex-post can be a laborious - yet worthwile - endavour, which may benefit from first creating larger-sized tests as an intermediate step towards fast and deterministic smaller tests. ","wordCount":"3489","inLanguage":"en","datePublished":"2023-04-10T00:00:00Z","dateModified":"2023-04-10T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://fladdimir.github.io/post/testing-legacy-code/"},"publisher":{"@type":"Organization","name":"wh","logo":{"@type":"ImageObject","url":"https://fladdimir.github.io/icon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://fladdimir.github.io/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://fladdimir.github.io/tags/ title=/tags><span>/tags</span></a></li><li><a href=https://fladdimir.github.io/search title="/search (Alt + /)" accesskey=/><span>/search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://fladdimir.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://fladdimir.github.io/post/>Posts</a></div><h1 class=post-title>Testing Legacy Software</h1><div class=post-meta><span title='2023-04-10 00:00:00 +0000 UTC'>April 10, 2023</span>&nbsp;·&nbsp;17 min</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1-working-with-legacy-code>1. Working with legacy code</a></li><li><a href=#2-properties-of-useful-automated-tests>2. Properties of useful automated tests</a><ul><li><a href=#fast-and-deterministic>Fast and deterministic</a></li><li><a href=#robust-and-maintainable>Robust and maintainable</a></li></ul></li><li><a href=#3-how-to-make-code-untestable>3. How to make code untestable</a></li><li><a href=#4-design-for-testability>4. Design for testability</a><ul><li><a href=#providing-_seams_>Providing <em>Seams</em></a></li><li><a href=#clean-architecture>Clean architecture</a></li></ul></li><li><a href=#5-reengineering-for-testability>5. Reengineering for testability</a></li><li><a href=#summing-up>Summing up</a></li></ul></nav></div></details></div><div class=post-content><p>Automated testing has become an essential part of software development.
Good test support is a core feature of many modern application frameworks, and there is rarely a debate about <em>whether</em> tests should be written or not, but rather on <em>how</em> and <em>which</em> tests should be written.<br>However, there is also a reality of some existing systems having few - if any - automated tests in place.
While this might not be a problem per se, a degrading understanding of a system can make it harder to confidently make necessary changes - up to a point where no one dares to touch anything anymore, in fear of not noticing that a change breaks existing functionality.
Having a suite of automated tests in place can greatly reduce that risk and thereby enable the continuous evolution of the system.</p><p>To explore this in some more detail, three questions will be discussed in the following:</p><ol><li>What are properties that automated tests should have in order to maximize the value they provide over the lifetime of a system?</li><li>How can systems be designed to facilitate the creation of useful tests?</li><li>What can be done if a system is not (yet) designed in a way which allows to accomodate such tests?</li></ol><p>Most of the aspects reflected on below are described in-depth i.a. in the following books:</p><ul><li>Working Effectively with Legacy Code, M. C. Feathers, 2005 - an often-recommended classic motivating why to create automated tests, and how to make it possible [Feathers, 2005]</li><li>Software Engineering at Google, T. Winters, T. Manshreck, and H. Wright, 2020 - devoting several chapters to the way tests are used in that huge software organization [Winters et al., 2020]</li><li>Clean Architecture, R. C. Martin, 2017 - containing general advice on how to structure (testable) systems [Martin, 2017]</li><li>Object-Oriented Reengineering Patterns, S. Demeyer, S. Ducasse, O. Nierstrasz, 2003 - a collection of approaches for restructuring existing systems, showing ways to improve the design, and describing strategies to use and grow test-suites [Demeyer et al., 2003]</li></ul><h2 id=1-working-with-legacy-code>1. Working with legacy code<a hidden class=anchor aria-hidden=true href=#1-working-with-legacy-code>#</a></h2><p>Most relevant software lives for long periods of time and the continuous adaption to new requirements is a relevant challenge.</p><p>With growing size, age, and complexity of a system, it seems not to be unusual for even seemingly simple changes to take longer and longer to be implemented, and to carry increasing risks of breaking existing functionality.
Of course, this holds especially true for systems which are developed just relying on &ldquo;working-with-care&rdquo; (sometimes also known as &ldquo;professionalism&rdquo;).
When it comes to making further changes, [Feathers, 2005] describes developers to then &ldquo;edit and pray&rdquo; that the change does not break anything, building confidence upon their experience with the system and some exploratory manual testing.<br>Obviously this only gets riskier, once different people start to extend different parts of the system, and once experienced contributors leave the team while new developers join.
Slowly, the architectural vision of the design starts to blur, and the understanding of how the systems works gets lost up to the point where no one really knows anymore what is going on.
Needless to say, that just continues to increase the risk of breaking changes (ultimately, how could one do any regression testing when not even knowing at all how the system is supposed to behave?).</p><p>As an alternative way, Feathers describes an approach of covering existing functionality with automated tests, providing a &ldquo;safety net&rdquo;, which allows for controlled refactorings as well as the controlled addition of new features or fixes.
This way, the chance to break existing functionality is reduced and all developers (experienced or not) are provided with confidence into the correctness of the software.</p><p>So how could those automated tests look like?</p><h2 id=2-properties-of-useful-automated-tests>2. Properties of useful automated tests<a hidden class=anchor aria-hidden=true href=#2-properties-of-useful-automated-tests>#</a></h2><p>[Winters et al., 2020] mention different dimensions to classify automated tests:</p><ul><li><strong>scope</strong> (describing the amount of validated code)<ul><li>narrow (e.g. class, or even single function)</li><li>medium (e.g. multiple classes)</li><li>large (e.g. system / end-to-end tests, verifying the interaction of sub-systems)</li></ul></li><li><strong>size</strong> (describing the amount of resources the test needs)<ul><li>small (the test and its dependencies all run inside a single thread)</li><li>medium (everything runs locally, in different processes, network calls to <em>localhost</em>, or file-system access are allowed)</li><li>large (calls to external systems are allowed)</li></ul></li></ul><h3 id=fast-and-deterministic>Fast and deterministic<a hidden class=anchor aria-hidden=true href=#fast-and-deterministic>#</a></h3><p>The execution time of a test is typically determined by its <em>size</em>, and the larger the test the more <em>flaky</em> it tends to be, since e.g. network calls to external systems may timeout (<em>flakiness</em> - the extent to which a test tends to fail sometimes, not being caused by any actually problematic code change).</p><p>To keep a test suite fast and deterministic, it is recommended to rely on a majority of <em>small</em> tests whenever possible (not leaving room for any flakiness, and even providing the option for simple parallel execution by multiple threads).
Furthermore, [Winters et al., 2020] emphasize the fact that only fast, small tests are practical to be run as part of the normal development workflow, and experience shows that longer-running tests tend to be not executed.
However, the importance of larger tests is also acknowledged in order to cover aspects that small tests cannot verify.</p><h3 id=robust-and-maintainable>Robust and maintainable<a hidden class=anchor aria-hidden=true href=#robust-and-maintainable>#</a></h3><p>When it comes to <em>scope</em>, there are different aspects to keep in mind:</p><ul><li>On the one hand, narrow-scoped tests (e.g. testing a single implementation class) usually allow for a quick and precise analysis of the root-cause in the event of failure.</li><li>On the other hand, narrow-scoped tests tend to be <em>brittle</em> (they break on unrelated changes), since a simple redistribution of some logic between collaborating classes can already cause a lot of test failures.</li></ul><p>[Winters et al., 2020] recommend to test business-relevant behaviour via the public API instead of directly depending on implementation details, to avoid frequently changing the tests (<em>&ldquo;Don&rsquo;t depend on volatile things!&rdquo;</em> - [Martin, 2017] even recommends to use a dedicated <em>testing API</em> to shield tests from changing implementation details).<br>Pure refactorings should not break tests, and doing so may indicate an innapropriate level of abstraction (test <em>behaviour</em> - not methods/classes).
The same holds true for changes that introduce new features or fix bugs, which also should not require an adjustment of existing tests.
So with respect to scope, following these recommendations may typically result in testing at least several related classes together.</p><p>Another interesting aspect of scope is that it is defined by the amount of <em>validated</em> code, as opposed to <em>executed</em>.
In particular, [Winters et al., 2020] argue that - if possible - a test should stick with the real implementations of the dependencies of the tested code, instead of replacing them with test doubles by default (preferring <a href=https://martinfowler.com/articles/mocksArentStubs.html#ClassicalAndMockistTesting><em>classical</em> over <em>mockist</em> testing</a>):</p><blockquote><p>&ldquo;Using real implementations can cause your test to fail if there is a bug in the real implementation. This is good!
You want your tests to fail in such cases because it indicates that your code won’t work properly in production.&rdquo;</p></blockquote><p>This is especially true when the dependency itself is not properly tested on its own.</p><p>Obviously, dependencies on things running outside the test thread (e.g. external services, databases) must be replaced by test doubles in order to keep the test <em>small</em>.
Here, [Winters et al., 2020] prefer the usage of lightweight fake implementations over mocks to be able to test <em>state</em> instead of <em>interactions</em>.</p><p>With respect to scope, [Feathers, 2005] also mentions the importance of narrow-scoped tests, i.a. because of the simplicity with which failure causes can be located.<br>While I certainly also like this property, I also fear that it tends to motivate me to slavishly create tests for each and every single class, leading to the brittleness problems described above.
More often than not it should be easy to spot the root cause of a problem even among a couple of collaborators.
Nevertheless, this does of course not mean that I would oppose occasionally making some pure function package-private to be able to quickly test some nasty regex in isolation.</p><h2 id=3-how-to-make-code-untestable>3. How to make code untestable<a hidden class=anchor aria-hidden=true href=#3-how-to-make-code-untestable>#</a></h2><p>While it may sound just great to have a blazingly fast, deterministic, robust, and maintainable test suite in place, it really needs to be kept in mind that this must not be an afterthought during development.
If not carefully taken into account, it is surprisingly easy to end up with code which makes it incredibly hard to add any useful (fast, small) automated tests ex-post (an endavour hard to describe other than <em>painful</em>).</p><p>Consider the following Java sample:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nd>@Service</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>class</span> <span class=nc>CalculationServiceImpl</span><span class=w> </span><span class=kd>implements</span><span class=w> </span><span class=n>CalculationService</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=cm>/**
</span></span></span><span class=line><span class=cl><span class=cm>   * @return true, if successful
</span></span></span><span class=line><span class=cl><span class=cm>   */</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nd>@Override</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>public</span><span class=w> </span><span class=kt>boolean</span><span class=w> </span><span class=nf>calculate</span><span class=p>(</span><span class=kt>int</span><span class=w> </span><span class=n>input</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>Result</span><span class=w> </span><span class=n>result</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=k>new</span><span class=w> </span><span class=n>FirstCalculator</span><span class=p>().</span><span class=na>calculateFirstPart</span><span class=p>(</span><span class=n>input</span><span class=p>);</span><span class=w> </span><span class=c1>// 1.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>SecondProcessor</span><span class=p>.</span><span class=na>calculateSecondPart</span><span class=p>(</span><span class=n>result</span><span class=p>,</span><span class=w> </span><span class=n>input</span><span class=p>);</span><span class=w> </span><span class=c1>// 2.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>SessionContext</span><span class=p>.</span><span class=na>store</span><span class=p>(</span><span class=s>&#34;myResult1&#34;</span><span class=p>,</span><span class=w> </span><span class=n>result</span><span class=p>);</span><span class=w> </span><span class=c1>// 3.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=kt>boolean</span><span class=w> </span><span class=n>isSuccessful</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>result</span><span class=p>.</span><span class=na>getValue32</span><span class=p>()</span><span class=w> </span><span class=o>==</span><span class=w> </span><span class=n>13</span><span class=p>;</span><span class=w> </span><span class=c1>// 4.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>if</span><span class=w> </span><span class=p>(</span><span class=n>isSuccessful</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=n>ThirdProcessor</span><span class=p>.</span><span class=na>calculateThirdPart</span><span class=p>();</span><span class=w> </span><span class=c1>// 5.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=n>NotificationService</span><span class=p>.</span><span class=na>sendKafkaMessageToCalculationsTopic</span><span class=p>();</span><span class=w> </span><span class=c1>// 6.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>return</span><span class=w> </span><span class=n>isSuccessful</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>class</span> <span class=nc>FirstCalculator</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>Result</span><span class=w> </span><span class=nf>calculateFirstPart</span><span class=p>(</span><span class=kt>int</span><span class=w> </span><span class=n>input</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=kt>int</span><span class=w> </span><span class=n>baseValue</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=k>new</span><span class=w> </span><span class=n>MariaDbDatabaseAccess</span><span class=p>().</span><span class=na>getBaseValue</span><span class=p>();</span><span class=w> </span><span class=c1>// 1.1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// [...] some calculation logic</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>return</span><span class=w> </span><span class=n>result</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>class</span> <span class=nc>SecondProcessor</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>static</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=nf>calculateSecondPart</span><span class=p>(</span><span class=n>Result</span><span class=w> </span><span class=n>result</span><span class=p>,</span><span class=w> </span><span class=kt>int</span><span class=w> </span><span class=n>input</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=kt>int</span><span class=w> </span><span class=n>extraInfo</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>CalculationHelperWebService</span><span class=p>.</span><span class=na>getExtraInfo</span><span class=p>();</span><span class=w> </span><span class=c1>// 2.1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// [...] some calculation logic</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>class</span> <span class=nc>ThirdProcessor</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>static</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=nf>calculateThirdPart</span><span class=p>()</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>Result</span><span class=w> </span><span class=n>result</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>(</span><span class=n>Result</span><span class=p>)</span><span class=w> </span><span class=p>(</span><span class=n>SessionContext</span><span class=p>.</span><span class=na>get</span><span class=p>(</span><span class=s>&#34;myResult1&#34;</span><span class=p>));</span><span class=w> </span><span class=c1>// 5.1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// [...] some calculation logic</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1>// [...] various other classes</span><span class=w>
</span></span></span></code></pre></div><p>Imagine that we&rsquo;d want to write a test for the <code>calculate</code> functionality of the <code>CalculationService</code> (public API).<br>We notice that the actual calculation logic seems to be distributed over at least three different collaborator classes, but the distribution seems rather arbitrarily.
In order to avoid creating a brittle test which is broken by the first upcoming refactoring, we avoid the temptation to test any of the three calculation parts in isolation.</p><ol><li><p><code>new FirstCalculator().calculateFirstPart(input)</code><br>First, there is a call to a collaborating class (<code>FirstCalculator</code>), which in turn collects some additional information from a database (<code>1.1</code>):<br><code>int baseValue = new MariaDbDatabaseAccess().getBaseValue();</code><br>This may already become a first problem, since there is no simple way to replace the MariaDB with a lightweight fake implementation, so that we would need to either run the complete test against a real MariaDB (making the test <em>larger</em>), or resort to <a href=https://javadoc.io/doc/org.mockito/mockito-core/latest/org/mockito/Mockito.html#mocked_construction>advanced mocking library features</a> (which are hopefully available).</p></li><li><p><code>SecondProcessor.calculateSecondPart(result, input);</code><br>Then the collaborator <code>SecondProcessor</code> is called, which first fetches some needed information from a remote service via network before running its calculations (<code>2.1</code>):<br><code>int extraInfo = CalculationHelperWebService.getExtraInfo();</code><br>Again, replacing this static call may require <a href=https://javadoc.io/doc/org.mockito/mockito-core/latest/org/mockito/Mockito.html#static_mocks>advanced magic</a> to be available (again also including possibly surprising side-effects in case the static mock is not properly cleaned up at the end of the test).</p></li><li><p><code>SessionContext.store("myResult1", result);</code><br>This shows another possibly hard-to-replace static call that depends on some framework-provided (thread-local?) session state to be setup, so that later parts of the calculation logic can then retrieve that state (e.g. <code>5.1</code> and <code>6</code>).
Relying on side-effects like this is just a great option to create a sufficiently confusing data flow which does not ease creating relevant test cases in general.<br>Why would one ever resort to using some sort of <code>SessionContext</code> at all here? Well, at least it allowed us to share information between different places without having been required to refactor much existing logic which would have been risky to touch..</p></li><li><p><code>boolean isSuccessful = result.getValue32() == 13;</code><br>At <code>4.</code> the orchestrating logic of the <code>calculate</code> method is suspended by some core business logic, breaking with the abstraction level of the method.
Apart from making it harder to understand the now even more widespread calculation logic, this does not really hinder creating the test.
It merely serves as an example of needed refactoring and is probably again a symptom of missing tests, since it was probably too risky to put it elsewhere in the first place.
This also illustrates the importance of testing via stable interfaces (public API), since implementation details such as the distribution of logic among collaborating classes may be likely to change - especially in systems where missing tests prevented adding new features at the right places.</p></li></ol><p>Finally, <code>5.</code> just represents some dependency on the <code>SessionContext</code>, and <code>6.</code> another hard-coded dependency on external systems.
Obviously the overall sample is kept short and the length of realistic methods won&rsquo;t contribute a lot to make writing tests any easier.</p><p>Summing up some general problems which may add up over time and result in hard-to-test code:</p><ul><li>hard-wired dependencies to external systems (hard to fake/mock)</li><li>dependencies hidden deep in the core business logic</li><li>behavior relying on side-effects and arcane features of the used framework</li><li>mangling different aspects and abstraction levels, just to avoid changing code at other places</li></ul><h2 id=4-design-for-testability>4. Design for testability<a hidden class=anchor aria-hidden=true href=#4-design-for-testability>#</a></h2><p>As shown in the previous part, testability should be a key aspect during system design/implementation.
So how can code be structured to allow for useful tests?</p><h3 id=providing-_seams_>Providing <em>Seams</em><a hidden class=anchor aria-hidden=true href=#providing-_seams_>#</a></h3><p>The <em>Seam</em> is a central concept of [Feathers, 2005], described as &ldquo;a place to alter behavior without editing that place&rdquo;.
In particular, <em>Object Seams</em> are recommended, i.e. providing places to allow replacing problematic dependencies with subtypes.<br>Dependency injection (DI) is a central functionality of many popular frameworks such as
<a href=https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/test/mock/mockito/MockBean.html>Spring</a>
or <a href=https://quarkus.io/guides/getting-started-testing#quarkus_mock>Quarkus</a>
(just to give some Java examples),
and both DI containers allow to replace existing bindings of (problematic) implementation classes with mocks or own fake implementations.
However, when using constructor injection it is also simply possible to construct instances of the classes under test by hand, without relying on any DI framework functionality.
Of course, this manual construction has the disadvantage of having to manually create the complete dependency graph, but may speed up test execution significantly.</p><p>For the problematic <code>FirstCalculator</code> above, a better testable version could look like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=kd>class</span> <span class=nc>FirstCalculator</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>private</span><span class=w> </span><span class=kd>final</span><span class=w> </span><span class=n>MariaDbDatabaseAccess</span><span class=w> </span><span class=n>dbAccess</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1>// constructor allows to provide fake/mock dependencies</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>FirstCalculator</span><span class=p>(</span><span class=n>MariaDbDatabaseAccess</span><span class=w> </span><span class=n>dbAccess</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>this</span><span class=p>.</span><span class=na>dbAccess</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>dbAccess</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>Result</span><span class=w> </span><span class=nf>calculateFirstPart</span><span class=p>(</span><span class=kt>int</span><span class=w> </span><span class=n>input</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=kt>int</span><span class=w> </span><span class=n>baseValue</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>dbAccess</span><span class=p>.</span><span class=na>getBaseValue</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// [...] some calculation logic</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>return</span><span class=w> </span><span class=n>result</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>This way, a fake-implementation of <code>MariaDbDatabaseAccess</code> could be provided (subclassing it and overriding problematic behavior).</p><p>Additionally, the <code>CalculationServiceImpl</code> would also need to offer a seam by providing a constructor allowing to inject the <code>FirstCalculator</code> instance with the faked database access dependency:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=nd>@Service</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>class</span> <span class=nc>CalculationServiceImpl</span><span class=w> </span><span class=kd>implements</span><span class=w> </span><span class=n>CalculationService</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>private</span><span class=w> </span><span class=kd>final</span><span class=w> </span><span class=n>FirstCalculator</span><span class=w> </span><span class=n>firstCalculator</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1>// constructor allows to provide test-specific dependencies</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>CalculationServiceImpl</span><span class=p>(</span><span class=n>FirstCalculator</span><span class=w> </span><span class=n>firstCalculator</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>this</span><span class=p>.</span><span class=na>firstCalculator</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>firstCalculator</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nd>@Override</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>public</span><span class=w> </span><span class=kt>boolean</span><span class=w> </span><span class=nf>calculate</span><span class=p>(</span><span class=kt>int</span><span class=w> </span><span class=n>input</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>Result</span><span class=w> </span><span class=n>result</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>firstCalculator</span><span class=p>.</span><span class=na>calculateFirstPart</span><span class=p>(</span><span class=n>input</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// [...]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>(Luckily, <a href=https://projectlombok.org/features/constructor>lombok</a> may save us at least some of this constructor boilerplate.)</p><h3 id=clean-architecture>Clean architecture<a hidden class=anchor aria-hidden=true href=#clean-architecture>#</a></h3><p>[Martin, 2017] describes <em>clean architecture</em>, a general approach to structure a system so that central business logic is properly separated from external dependencies.
The main idea is also at the core of similar concepts like <em>hexagonal architecture</em> or <em>onion architecture</em>.<br>In particular, a <em>Dependency Rule</em> is formulated which states that:</p><blockquote><p>&ldquo;Source code dependencies must point only inward, toward higher-level policies.&rdquo;</p></blockquote><p>When core business logic needs to invoke functionality from outer layers, this dependency must be inverted (<em>Dependency Inversion Principle</em>), so that the source-code dependency still only points inward, <em>opposing the flow of control</em>.</p><p>Consider the sample above:</p><p><img loading=lazy src=img/outward_source_code_dependency.drawio.svg alt=outward-dependency></p><p>A cleaner version of the code sample shown above could be realized as follows, replacing the low-level MariaDB dependency of the core logic with the abstract interface <code>BaseValueProvider</code>:</p><p><img loading=lazy src=img/inverted_dependency.drawio.svg alt=inverted-dependency></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=c1>// core business logic</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>class</span> <span class=nc>FirstCalculator</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>private</span><span class=w> </span><span class=kd>final</span><span class=w> </span><span class=n>BaseValueProvider</span><span class=w> </span><span class=n>baseValueProvider</span><span class=p>;</span><span class=w> </span><span class=c1>// abstract dependency</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1>// constructor allows to provide fake/mock dependencies</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>FirstCalculator</span><span class=p>(</span><span class=n>BaseValueProvider</span><span class=w> </span><span class=n>baseValueProvider</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>this</span><span class=p>.</span><span class=na>baseValueProvider</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>baseValueProvider</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>Result</span><span class=w> </span><span class=nf>calculateFirstPart</span><span class=p>(</span><span class=kt>int</span><span class=w> </span><span class=n>input</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// core logic directly invokes functionality from outer layers,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// but has no source-code dependency</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=kt>int</span><span class=w> </span><span class=n>baseValue</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>baseValueProvider</span><span class=p>.</span><span class=na>getBaseValue</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// [...] some calculation logic</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>return</span><span class=w> </span><span class=n>result</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>interface</span> <span class=nc>BaseValueProvider</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=c1>// part of the core business logic</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=kt>int</span><span class=w> </span><span class=nf>getBaseValue</span><span class=p>();</span><span class=w> </span><span class=c1>// abstract functionality needed by the core logic</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// ---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// implementation detail, outside the core logic</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>class</span> <span class=nc>MariaDbDatabaseAccess</span><span class=w> </span><span class=kd>implements</span><span class=w> </span><span class=n>BaseValueProvider</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nd>@Override</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>public</span><span class=w> </span><span class=kt>int</span><span class=w> </span><span class=nf>getBaseValue</span><span class=p>()</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// [...] actual MariaDB access logic</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>As a result, central business logic can be kept independent from external influences and low-level details, be it frameworks, UI, or databases.
This does not only make it simpler to replace a specific database or UI technology when a popular new one emerges, but also makes it simple to provide seams which allow to swap out problematic dependencies with mocks or lightweight fake implementations.
Consequently, the creation of <em>small</em>, useful automated tests is facilitated.</p><p>When implementing clean architectures it may also be helpful to enforce the dependency rule e.g. in Java with help of <a href=https://www.archunit.org/userguide/html/000_Index.html#_onion_architecture>ArchUnit</a> tests.</p><h4 id=sidenote-on-the-over-usage-of-java-interfaces>Sidenote: on the over-usage of Java interfaces<a hidden class=anchor aria-hidden=true href=#sidenote-on-the-over-usage-of-java-interfaces>#</a></h4><p>Another, somehow related and sometimes observed problem in Java is a general <a href=https://www.adam-bien.com/roller/abien/entry/how_to_deal_with_interfaces>tendency towards the over-usage of interfaces</a>.
Consider the sample introduced above:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=nd>@Service</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>class</span> <span class=nc>CalculationServiceImpl</span><span class=w> </span><span class=kd>implements</span><span class=w> </span><span class=n>CalculationService</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nd>@Override</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>public</span><span class=w> </span><span class=kt>boolean</span><span class=w> </span><span class=nf>calculate</span><span class=p>(</span><span class=kt>int</span><span class=w> </span><span class=n>input</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// [...]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>Imagine the <code>calculate</code> method being called exclusively by some <code>CalculationRestController</code> upon an HTTP-request initiated by user interaction.
In that case, there would not be any problem having a direct dependency from the <code>CalculationRestController</code> (low-level detail) towards the <code>CalculationServiceImpl</code> (core business logic).
Infact, we might just be able reduce some clutter by removing the useless <code>CalculationService</code> interface as well as the annoying <code>Impl</code> postfix.
In many cases using interfaces is not required and should be a conscious decision rather than the default.</p><h2 id=5-reengineering-for-testability>5. Reengineering for testability<a hidden class=anchor aria-hidden=true href=#5-reengineering-for-testability>#</a></h2><p>Given some system that was not designed with clean architecture and useful automated tests in mind, how can we still get there?
[Demeyer et al., 2003] give a number of useful recommendations on <em>reengineering</em>, i.e. on how to restructure systems in an improved form.</p><p>One chapter touches on the question of which parts of a system to prioritize.
Understandibly, reengineering efforts should not focus on stable, flawlessly working parts, but rather on the faulty ones, which require change and suffer the worst from reliance on outdated technologies, developer fluctuation, insufficient documentation, duplicated code, or tangled structure.</p><p>Starting with the most problematic parts, the core business functionalities as well as dependencies and auxiliary functions need to be analyzed to identify a cleaner, more testable target design as well as the corresponding target scope of useful automated tests.</p><p>In order to safely make the necessary code changes (e.g. introducing seams to break and invert dependencies), [Demeyer et al., 2003] recommend to incrementally introduce tests for the parts of the system which are changed.</p><blockquote><p>However, isn&rsquo;t there the <em>chicken-and-egg</em> problem of already requiring tests to safely do changes which only enable the creation of tests?</p></blockquote><p>Yes, that&rsquo;s what [Feathers, 2005] calls <em>the legacy code dilemma</em>.
To alleviate this problem, a two-step approach can be taken:</p><ol><li>start with <em>larger-sized</em> tests which allow to keep as many dependencies in place as possible, minimizing the amount of necessary code changes to create the tests</li><li>refactor the covered code so that creating <em>small</em> tests of the core business logic becomes feasible</li></ol><p>First, this may e.g. involve running tests against an existing database or other external services.
Even though running the larger tests may take time and will be subject to flakiness, it will still provide the necessary safety net to incrementally move towards a cleaner design with faster tests.</p><p>[Demeyer et al., 2003] advise to start with black-box tests of big abstractions, focusing on business values, instead of individual sub-components.
In particular, one recommendation is to <em>record business rules as tests</em>, aiming to represent core functionality by a set of canonical examples with well-defined actions and clear, observable results.
Since covering all rules may not be feasible (depending on their number and the runtime of the larger tests), it is suggested to start with essential cases.
The 80/20 rule may apply here as well, maybe 80% of production cases only exercise 20% of the business logic?.</p><p>Having the larger-sized tests in place, the necessary refactorings can be done to break the problematic dependencies and introduce a cleaner architecture.
Subsequently, the implemented test scenarios of the larger-sized tests can be nicely reused to create fast-running small tests, swapping out problematic dependencies with leightweight fake implementations.
Furthermore, more small tests can be added to further increase the amount of covered business rules.</p><p>While the small tests can be run quickly and often as part of the local development workflow, the larger-sized tests should still be run on a regular basis in order to verify the functionality against the actual dependencies. (Drawing from own experience, errors seem to come as often from self-developed business logic as from unexpected behavior of dependencies - be it caused by actual bugs or just by unclear documentation.)</p><h2 id=summing-up>Summing up<a hidden class=anchor aria-hidden=true href=#summing-up>#</a></h2><ul><li>To be fast and not <em>flaky</em>, automated tests must be <em>small</em> in size (running inside a single thread).</li><li>To be maintainable and not <em>brittle</em>, automated tests should test through stable interfaces (public API), focusing on business requirements instead of being too narrow-scoped. This leaves room to freely refactor the internal implementation.</li><li>Being able to build useful automated tests requires conscious management of source code dependencies. This needs to be kept in mind when designing and implementing a system.</li><li>Adding useful automated tests to a grown system ex-post can be a laborious - yet worthwile - endavour, which may benefit from first creating <em>larger-sized</em> tests as an intermediate step towards fast and deterministic smaller tests.</li></ul><p><img loading=lazy src=img/small_and_larger_tests.drawio.svg alt=small-sized_larger-sized_tests></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://fladdimir.github.io/tags/testing/>Testing</a></li><li><a href=https://fladdimir.github.io/tags/legacy-code/>Legacy Code</a></li><li><a href=https://fladdimir.github.io/tags/clean-architecture/>Clean Architecture</a></li><li><a href=https://fladdimir.github.io/tags/java/>Java</a></li></ul><nav class=paginav><a class=prev href=https://fladdimir.github.io/post/glosa/><span class=title>« Prev</span><br><span>Green-Light Optimized Speed Advisory for Cycling in Hamburg</span>
</a><a class=next href=https://fladdimir.github.io/post/document-search/><span class=title>Next »</span><br><span>Availability and Consistency of an App with Multiple Datasources</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://fladdimir.github.io/>wh</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>