[{"authors":["fladdimir"],"categories":null,"content":"Hi, I am a software developer living in Hamburg, Germany.\nBorn in Dresden and completing high-school in Berlin, I later studied in Magdeburg, Grenoble and Tampere. While studying I was fascinated by logistics simulation, be it for urban transport planning or digital twins of manufacturing systems. Recent projects focus on web-development, mostly involving backend and Java, as well as Python. In my free time you may find me tinkering around with new technologies, doing calisthenics, or spending time with my fiancée and friends in Hamburg-Altona.\n","date":1635379200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1635379200,"objectID":"ac3c180d339617d6149c90522af90de9","permalink":"/authors/fladdimir/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/fladdimir/","section":"authors","summary":"Hi, I am a software developer living in Hamburg, Germany.\nBorn in Dresden and completing high-school in Berlin, I later studied in Magdeburg, Grenoble and Tampere. While studying I was fascinated by logistics simulation, be it for urban transport planning or digital twins of manufacturing systems.","tags":null,"title":"Wladimir Hofmann","type":"authors"},{"authors":["Wladimir Hofmann","Clemens L. Schwarz","Fredrik Branding"],"categories":null,"content":"Presented at: The 35th annual European Simulation and Modelling Conference, ESM\u0026rsquo;2021, Rome, Italy\nFull text on researchgate.\n","date":1635379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635379200,"objectID":"1c50bcd5c190e1f6aa5eaf16b282ca8a","permalink":"/publication/esm2021/","publishdate":"2021-08-28T00:00:00Z","relpermalink":"/publication/esm2021/","section":"publication","summary":"Reinforcement Learning is an emerging machine learning technique to autonomously derive complex action sequences in dynamic environments, as successful application and active development in robotics and gaming prove. This paper presents an open-source tool stack for the application in logistics, based on popular packages from the Python ecosystem - OpenAI gym and stable-baselines for reinforcement learning, and SimPy for discrete event simulation. These libraries are combined to investigate an industrial case study on dynamically dispatching a tugger train for material provision in an assembly line system. The implementation demonstrates the applicability of the chosen technologies, provides a benchmark, and helps to point out conceptual and implementation-related challenges.","tags":null,"title":"Towards the Productive Application of Reinforcement Learning in Logistics: A Case Study on Assembly Line Material Provision Planning","type":"publication"},{"authors":["Wladimir Hofmann"],"categories":null,"content":"Back at university we had a great time playing around with miniaturized Fischertechnik conveying systems. We learned about the challenges of PLC programming and the joy of using Arduino micro-controller boards to bring conveyor belts and turntables to life. We were learning about simulation-based controls testing using Emulate3D (awesome 3D physics engine, robot emulations) and Plant Simulation (also great for testing higher-level controls).\nHowever, the restrictive licensing - USB dongles and notoriously limited pool-licenses - made it challenging to create a simple and accessible controls development workflow suitable for all project team members.\nLet\u0026rsquo;s sketch the idea of a material flow simulation environment for developing, debugging and testing C-code inside a Python-based simulation model - non-proprietary and ready to be run anywhere, e.g. as part of CI.\n Public repo: https://github.com/fladdimir/material-flow-control-c-emulation\n 1. Scenario \u0026amp; Scope The \u0026ldquo;turntable\u0026rdquo; (image above) represents a typical Fischertechnik conveying module. It consists of 2 motors and 3 sensors:\n conveyor belt (motor 1) proximity sensor or photoelectric barrier to identify whether some item is present on the module (sensor 1) turning unit for changing the belt rotation by 90 degrees (motor 2) stop position sensors for checking whether the module fully rotated (sensors 2+3, both at 0 and 90 degrees)  Even though the motors typically require 24V, relays can be used to control a module with a micro-controller boards typically working at 3-5V pin voltage. Micro-controller boards such as Arduinos also offer further options for interfacing with other systems via serial communication.\nPutting together multiple turntable modules, grid-like conveying layouts can be realized.\nHowever, writing control logic for Arduino can be challenging, especially since debugging code running on a connected board is not as simple. Additionally, central material flow control software also needs to be tested in interaction with module controls.\n2. System Structure A structure for controlling the flow of goods through a grid of connected turntable modules could look like this:\n every turntable\u0026rsquo;s sensors and actors are controlled by a micro-controller (I/O) every micro-controller has a serial connection to communicate with a central material flow control server the server logic consists of different parts dedicated to communicating with connected modules, as well as central functions e.g. for pathfinding/routing of items through the system  While systems such as Flexconveyor claim to work in a decentralized way without the need for a central \u0026ldquo;routing brain\u0026rdquo;, the described structure tries to shift all functions without hard real-time requirements from the micro-controllers to a central server (which makes particular sense when running on low-budget, resource-constrained boards such as the Arduino Uno).\n3. Emulation Interfaces Within the described setup, every micro-controller interacts with its environment via sensor-reads, actor-writes, and byte-wise serial-reads/writes. To be able to run the control logic on a development computer, the actual hardware-dependent read/write calls need to be replaced by interactions with simulated counterparts.\nOne way of achieving that using a Python-based emulation environment and exploiting the simple interfacing with C code could look like this:\n module control C code is called from a Python runtime with help of a generated CFFI wrapper device-dependent interaction methods are setup to call corresponding Python functions providing simulated inputs/outputs sensor-reads \u0026amp; actor-writes are run against a shared memory, which is also read/written by a simulation of the physical modules serial reads \u0026amp; writes are going to a pipe, which represents a connection to the server-side module agent a dedicated sub-process is created for every module control so that no global C variables are shared between different module controls   CFFI allows for the simple creation of functions which are declared in C and called from Python, as well as the other way around. When generating the CFFI wrapper code, C header files can be used to prepare C functions to be called from Python. To be able to implement forward-declared C functions in Python, the follwing definition can be set:\nextern \u0026quot;Python+C\u0026quot; bool _light_barrier(); // provide info whether sensor is triggered  This way, an implementing Python function can then be wired:\n@ffi.def_extern() def _light_barrier() -\u0026gt; bool: return shared_array[LIGHT_BARRIER_IDX] # simulated value from memory instead of actual sensor  4. 2D-Simulation To be able to emulate physical interactions of the module control code, real system components need to be simulated. While there are Python wrappers for awesome (3D) physics engines such as chrono, this implementation just uses a minimal 2D engine with very limited physics.\nSupported features include:\n nested element structures in 2D cheap collision//overlap detection for certain combinations of simple geometries (rectangles, straights, points) relative transition and rotation movements of elements and child-elements movement limits (e.g. to realize max. 90 degrees of rotation for turntables)  While an elements global position is determined by its local position relative to the parent-element it is attached to, the global position is cached to avoid recalculation for nested objects in case no position changes occured for any parent element.\nThe collision detection uses a simple 2-phase check, first checking cheap circumcycles to identify potentially colliding objects before performing a more expensive cohen-sutherland evaluation. Collisions are used in the simulation e.g. to identify when a box is hitting a light barrier, or which conveyor belt movements are changing a box\u0026rsquo;s position.\n5. Putting it all together The screencast shows an animation of a small sample test scenario consisting of several modules forwarding one box towards randomly chosen target modules (indicated by \u0026lsquo;X\u0026rsquo;):\nThe visualization is created with help of the Arcade game engine, which allows to simply step forward the simulation inside the game loop and animate the current state. In addition to the advent of the simulated time, the (C-coded) control loop of each module is invoked sequentially to allow a reaction to potential sensor state changes.\nOn the server-side of the control hierarchy, the forwarding/receiving of boxes between modules and the awaiting of modules to reach readiness is realized using asyncio coroutines.\nThe determination of which modules to visit in order to reach a distant target module is done with help of networkx and a corresponding graph constructed from the module locations.\n The cool thing about all this: we can debug every single layer of the control code at any point in time!\n In addition to normal Python debugging (part of the VS Code Python extension) of the server-side control code, we can attach a C (gcc) debugger to any of the module sub-processes running the C code.\nThis also works great from within VS Code, where we can even run different debugging sessions at the same time.\nBeing able to \u0026ldquo;look inside\u0026rdquo; the current state of a C module control makes it amazingly easy to discover bugs, such as the bad evaluation of commands received via serial communication, confirmation serial writes at bad times, plain wrong if-conditions, misplaced early returns etc..\nAs animation is fully optional, running a \u0026ldquo;headless\u0026rdquo; simulation can be easily used for validating checked-in control code agains a set of defined test scenarios / module layouts e.g. as part of a CI pipeline.\nLimits and Shortcomings Despite the good level of support for development and debugging, there are serious shortcomings of the presented approach, so that there still remains the need for properly testing the complete physical system:\n C code is run on a normal PC instead of a resource-constrained micro-controller, so e.g. memory usage should be carefully checked the defined \u0026ldquo;hardware abstraction layer\u0026rdquo; hides the complexity of actual communication hardware and technologies (pins/bus systems/rxtx/i2c/\u0026hellip;) all control code is invoked sequentially and the simulation waits for all control loops to finish before the next time step, so real-time requirements should be checked with special care on the target hardware  ","date":1629676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629676800,"objectID":"a7bc5a945f16047157fe8be7e382e1fd","permalink":"/post/material-flow-control-emulation/","publishdate":"2021-08-23T00:00:00Z","relpermalink":"/post/material-flow-control-emulation/","section":"post","summary":"Running C code as part of a Python simulation using CFFI","tags":null,"title":"Python-based Emulation for Developing Material Flow Controls in C","type":"post"},{"authors":["Wladimir Hofmann"],"categories":null,"content":"Getting up late every morning, efficient processes are crucial. Luckily, there are tools which enable the lazy late riser to get some structure into the start of the day. The diagram above shows a BPMN-definition of what needs to be achieved in which order on a typical morning.\nThe workflow engine Camunda can turn the corresponding BPMN file into an executable process, made of a series of completable user-tasks. Vaadin and SpringBoot enable the fast creation of a simple web-ui, showing the tasks which need to be completed next, combined with a progress-bar:\nParallel tasks can be completed in any order, and the current progress as well as the complete history with start times and task durations are saved to a Postgres database for further analysis.\n Start the morning with a clear plan.\n ","date":1623196800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623196800,"objectID":"1a54be8b54e66ee96b76baf5072fbcab","permalink":"/post/camunda-task-list/","publishdate":"2021-06-09T00:00:00Z","relpermalink":"/post/camunda-task-list/","section":"post","summary":"Managing the start into the day with help of Camunda, Vaadin, and SpringBoot","tags":null,"title":"Camunda Morning Task-List","type":"post"},{"authors":["Wladimir Hofmann"],"categories":null,"content":"The huge effort for lifting oneself up from the couch and moving the distance to the connected PC makes it almost unbearable to do audio volume changes when watching Netflix on the big screen (not even speaking of the pain bending the fingers to reach hotkeys).\nLuckily, there are great libraries available to alleviate this agony with just a few lines of Python.\nOn the Ubuntu laptop, pyalsaaudio gives simple control over the system\u0026rsquo;s audio level, pycaw offers the same on Windows.\n Flask exposes a corresponding command-endpoint as well as a minimal web UI.\nTouch input within the dashed area is captured and translated to mouse cursor movements using pynput, giving a simple option for start \u0026amp; pause.\n Start the ease of the pain.\n ","date":1623196800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623196800,"objectID":"d9752eb2059330891aa72dc670002099","permalink":"/post/audio-remote-control/","publishdate":"2021-06-09T00:00:00Z","relpermalink":"/post/audio-remote-control/","section":"post","summary":"The huge effort for lifting oneself up from the couch and moving the distance to the connected PC makes it almost unbearable to do audio volume changes when watching Netflix on the big screen (not even speaking of the pain bending the fingers to reach hotkeys).","tags":null,"title":"Minimal Web-based Remote Control with Python","type":"post"},{"authors":["Wladimir Hofmann"],"categories":null,"content":"Wouldn\u0026rsquo;t it be cool to be able to share your location with friends, but without relying on established service providers, which most probably already know way more about you than they should?\nThis post will look at a small web-app implementing essential basics of that functionality, using React and Leaflet at the frontend, Micronaut at the backend, Okta as identity provider, and Heroku for free hosting.\n Get the repo: https://github.com/fladdimir/locsharex.\nTL;DR - just show me the app!\n(first request may take some seconds, due to a possibly sleeping Heroku dyno)\n  Features and UI Login screen To get a first impression without sign-up, 3 pre-defined test-users allow you to quickly see the app in action. Just click to login and play around.\nOkta-Login To create your own user, sign-in via Okta, a free Open-ID-Connect identity provider.\n(Well, free for any app as long as there are no more than 15k monthly users.)\nThe Map Main screen of the app, where you can see your and your friends\u0026rsquo; locations.\nEdit your location by dragging the marker onto the map, stop sharing your position, or rely on your browser/device location (consent needed). Filter for username in case of searching for someone specific.\nSettings The contact-administration page, with lots of space for more friends ;)\nLook for not-yet-connected people by username, change the name by which people may find you. Sign-out to try another test-user or check back later.\n Technologies Frontend Single-page react-app, created with create-react-app and Material-UI. Open-street-maps integration with help of leaflet and react-leaflet for simple usage within react components with great typescript support. VSCode.\nWorth mentioning might be the awesome create-react-app tooling, including a proxy-mode for forwarding of /api requests to another locally running server (no cors hustle), and the HTTPS support required for using the geo-location browser api.\nBackend  Micronaut, a popular JVM-based microservice framework, aiming for lower memory footprints and faster start-up times than Spring-Boot, and ( at least currently) still with better support for creating native images with GraalVM (for further start-up time reduction). Thanks to the java-extension, VSCode also provides great support for backend development.\nConvenient entity persistence with Data Repositories and Hibernate. Below is a simple entity-relationship-model for the app, showing the AppUser with it\u0026rsquo;s app-internal ID, name, (embedded) position, and associated users (m-n self-reference):\nIn addition to the REST-API, Micronaut also provides the possibility to serve static files.\nIdentity Provider  Micronaut Security offers a variety of options for securing an app, including support for OpenID Connect-based authentication flows. To link persisted user-entities with actual users authenticating via OIDC, the entity also contains information on the identity provider and the sub (a user ID from the identity provider). That information is only used once during login to identify the logged-in user before issuing a new JWT. No info from the identity-provider is given anywhere but to the database.\nMicronaut Security includes support for a couple of different OIDC providers out of the box (e.g. Auth0, AWS-Cognito, Okta, Keycloak).\n Keycloak is a popular open-source identity and access management solution, lately starting to move from Wildfly to Quarkus - Keycloak-X. Great for just spinning up a container for local development.\nAlternatively it is simple to switch to a managed IDP such as Okta.\nShown below is an overview of the application components and their interaction during OIDC login:\n The user decides to login and issues a request to initiate the flow The response redirects to the identity provider The IDP login is loaded, where the user enters credentials Upon successful IDP login, the user is redirected to a callback-endpoint of the app (including a one-time code) The user issues the callback request (including the one-time code) The app backend makes a secure back-channel request to exchange the user-related one-time code for an ID-token (together with an app-specific, pre-configured client-secret) The IDP returns an ID-token containing user information The app backend creates a new JWT containing the app-internal user ID and returns the JWT as an http-only cookie as part of a redirecting response The browser then sends the cookie with every API request, allowing the backend to validate the JWT and the permission of the user to access requested resources  During logout the user needs to clear the existing IDP session as well as the app session, which can be achieved by a series of redirects between the logout endpoints.\nSee e.g. this presentation for an in-depth explanation of OAuth 2 and OIDC.\nHeroku  Heroku is a platform-as-service which offers a simple way to run an app in the cloud, including a free tier of 550 micro instance-hours per month and a postgres-database with a 10k row limit. Applications can be provided e.g. in form of jars or docker images (the latter may require custom processing of the environment variable storing the Database credentials). After 30 mins of inactivity without incoming requests, an instance is put to sleep and stops consuming instance-hours. To quickly respond to a request when waking up an instance, the usage of a native image of the app can be beneficial (reducing the app startup time from ~4.1 seconds to ~0.24s).\n Feel free to register for a free Okta account (no gmail needed), and share your favorite location ;)\nhttps://locsharex.herokuapp.com\n","date":1609113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609113600,"objectID":"28db03a7682c4cabd42bc84af0095340","permalink":"/post/location-sharing/","publishdate":"2020-12-28T00:00:00Z","relpermalink":"/post/location-sharing/","section":"post","summary":"A simple web-app for sharing geo-locations with friends","tags":null,"title":"Playing around with React, Leaflet, Micronaut, Okta, \u0026 Heroku","type":"post"},{"authors":["Wladimir Hofmann"],"categories":null,"content":"When creating Python-based simulation models with Casymda / SimPy, a frequent remark is that Python - being a slow, dynamic, interpreted language - would be a bad choice for this type of endeavour.\nSo could compiled, statically-typed SimPy alternatives make model execution faster, therefore being a better choice for development?\nThis post will have a look at Uia-Sim and SimSharp, two SimPy ports for discrete event simulation in Java and C#. As a proof-of-concept, two small block-based modeling libraries were created, similar to Casymda for SimPy, and their execution speed was compared with help of a simple benchmark model.\nUia-Sim: SimPy for Java  Uia-Sim is a recently published Java port of SimPy, published by UIA Java Solutions. Since Java does not provide generators/coroutines out of the box, the creator developed a \u0026ldquo;yield-like API\u0026rdquo; to enable blocking and resuming of simulation processes with help of threads.\nBased on Uia-Sim, a Casymda-like library for block-based composition of discrete event simulation models was created as a proof-of-concept. Csa4j implements some of the ideas from Casymda:\n a Block as the basic class to compose simulation models  is executing processing logic for received entities, and forwarding to successor-blocks can be extended for custom processing logic (e.g. elapsing time, as Delay)   Source-blocks spawn entities and initiate their processing Sink-blocks end entity processing and cause removal from the simulation basic animation capabilities can visualize the entity flow between model blocks for debug / presentation  As an improvement over Casymda, animation-related behavior and data was properly seperated from the simulation-related behavior of basic blocks, which just provide notifications whenever block-states change or entity movements occur.\nSimilar to Casymda\u0026rsquo;s debug animation based on Tkinter, corresponding visualizations can be created in Csa4j with JavaFX. While browser-based animation was out of scope for this PoC, the multitude of existing (micro-) web-frameworks for Java would make it easy to provide corresponding functionality. Further missing features which are present in Casymda include the parsing of .bpmn files to generate simulation model classes, the state-tracking of blocks, and tilemap-movements.\nThe project uses a basic gradle setup with Java 14 and JUnit-tests. Coverage info and static code analysis can be obtained with help of jacoco, sonarqube, and a sonarqube gradle plugin. Since Uia-Sim seems to be not yet available via maven-central, this dependency can be built locally and primarily be retrieved via a local maven repository. VSCode and its Java extension pack provide a great development experience.\nSimSharp: SimPy for .NET  SimSharp is a .NET port of SimPy which is developed by the research group \u0026ldquo;Heuristic and Evolutionary Algorithms Laboratory\u0026rdquo; (HEAL) from Austria (also known for the HeuristicLab optimization framework). Similar to SimPy (and different to Uia-Sim), SimSharp is using iterators for resumable simulation-processes.\nCreated for this PoC, the Csa4cs-library provides the same features as \u0026ldquo;Csa4j\u0026rdquo; (described in the previous section), including a simple canvas animation based on skiasharp and gtksharp.\nThe project is based on the .NET 5.0 SDK, using the XUnit test framework. Similar to the Java project, coverage info and static code analysis can be obtained conveniently with sonarqube (even though the scan step requires a bit more setup effort compared with the gradle plugin usage in Java). Thanks to its C# extension, VSCode can offer great development support.\nPerformance Comparison To evaluate the execution speed of the simulation libraries, the same model was implemented using Casymda/SimPy, Csa4j/Uia-Sim, and Csa4cs/SimSharp. Additionally, the SimPy-model was executed using CPython and PyPy. Identical assertions on the results of the simulations verify the correctness of the model implementations.\nThe benchmark model is made of typically used, basic processing blocks and is shown below.\nOne source produces entities with a given inter-arrival-time and forwards them to a gateway, which alternatingly chooses either a delay-block with infinite capacity (parallel processing), or a buffer which is placed before a delay-block with capacity 1 (sequential processing). A second gateway joins both entity flows.\nDepending on the inter-arrival-time, 2 main scenarios can be simulated:\n inter-arrival-time \u0026gt; processing time  not causing any queues or actually parallel processing, representing a plain processing of entities with a short event queue   inter-arrival-time \u0026lt; processing time  leading to a queue before the sequential processing (up to n/2 entities waiting), and a simultaneous processing of the other n/2 entities    Different experiments simulate the processing of 10 to 200_000 entities and were carried out on an Ubuntu notebook with i5 processor.\nThe diagram below shows the execution time of the simulation runs for the first scenario where no queing occurs, depending on the number of created entities:\nAs we can see - and as one might expect - the execution time linearly grows with the number of processed entities on all platforms. Interestingly, the Java model (red) is considerably slower than the Python and the C# versions, so that the longer experiments were omitted. This performance drawback could be explained by fact that one os-thread is created per entity-process, combined with a high computational overhead of threads compared to generator/iterable-based coroutine-objects. Even for short runs, the PyPy JIT compiler (orange) can reach an impressive speed-up compared to CPython (blue). The .NET model outperforms even PyPy by a factor of ~5.\nThe second chart shows the queuing scenario, with up to one half of the entities waiting for a shared resource, and the other half being simultaneously processed:\nAs before, the longer runs of the Java model were omitted due to their duration. While CPython and .NET show an again seemingly linear growth, the exponential development of the PyPy execution time reveals a rather surprising slow-down in the long run compared to CPython.\nSummary  Static typing alone does (surprisingly) not guarantee any execution speed advantage. SimSharp did prove to work great and might definitely be worth further evaluation. The Java-based library should probably not be used when creating many simulated processes (e.g. one process per entity, with many rather short-lived entities as in the sample model). PyPy can provide significant speed-ups over CPython, closing the gap between Python and C# - however, that depends.  The shown figures were created from a first, tentative, prelimenary comparison, delivering results which are not even fully comparable (especially due to the omitted features in the Java and C# libraries). Apart from execution speed, the eco-system remains as a strong plus for creating discrete event simulation models with Python.\n","date":1608422400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608422400,"objectID":"412781be93fcb2e9ac19bfe2977467d1","permalink":"/post/csa4j+cs/","publishdate":"2020-12-20T00:00:00Z","relpermalink":"/post/csa4j+cs/","section":"post","summary":"Performance Comparison of Casymda-Ports for Uia-Sim and SimSharp","tags":null,"title":"Block-based Modeling with SimPy - in Java \u0026 C#","type":"post"},{"authors":["Wladimir Hofmann"],"categories":null,"content":"In his highly interesting, recently published PhD thesis (German), Toni Donhauser from the University Erlangen-Nürnberg gives an excellent example on how a production-synchronous digital twin can be used for automated, simulation-based order scheduling in masonry plants.\nAs a core feature, the developed simulation allows to initialize the work-in-process of the manufacturing system to precisely mirror the current state and create accurate short-term forecasts, which serve as a basis for comparing alternatives and optimizing production plans in case of unexpected disruptions. Tecnomatix Plant Simulation (Siemens) is used for the implementation of the simulation model. Manufacturing data is fetched via the built-in OPC-UA interface from an OPC server and via ODBC from an MS Access database. Simulation runs can be triggered manually by an operator using a management application written in C#.\nSince Plant Simulation is known for extensive features as well as for extensive licensing fees, this blog post will present an alternative implementation of such a production-synchronous digital twin, based on open-source frameworks and building on easy-to-operate, pay-per-use AWS infrastructure.\nThe complete setup can be deployed and tested locally using Docker, LocalStack and Terraform (no AWS account required).\n  Get the repo from github:\nhttps://github.com/fladdimir/csa-simulation-based-sc-forecast\n  Scenario \u0026amp; Scope The chart below shows a fictive and simplified order manufacturing process, serving as a minimal example to illustrate how a digital twin of the system can be implemented.\nAfter being created, orders are received and accepted by the company (\u0026ldquo;ingest\u0026rdquo;-step), and the order-specific raw material is ordered (\u0026ldquo;order_material\u0026rdquo;), leaving the order waiting until the corresponding material arrives (\u0026ldquo;wait_for_material\u0026rdquo;). When the material is delivered, the order proceeds to a queue (\u0026ldquo;wait_for_sop\u0026rdquo;), waiting to be processed in a capacity-constrained \u0026ldquo;production\u0026rdquo;-step, which is only able to process one order at a time. Eventually, the finished order gets delivered to the customer and leaves the system.\nWhenever material for an order is requested, an initial estimated time of arrival (ETA) is assigned. However, unexpected supplier-specific process deviations or other delivery problems may introduce delays at any point in time, so that ETA-updates are possible during this step. Since the production step uses a capacity-constrained resource and represents a possible bottleneck of the system, any unplanned under-utilization here may delay every upcoming order and diminish the system throughput (depending on how tight the schedule looks like). Therefore, it is desirable to be able to quantify the effects of any shift in time as soon as an ETA-update for an order occurs.\n Synchronized Digital Twin: Concept and Implementation The next figure shows a simple event-processing pipeline, able to ingest defined events and to persist the system state (event tracking), which in turn enables the simulation-based creation of forecasts for expected order completions times and delays (event analytics). A simple web-dashboard will be used to visualize the results.\n1. Publishing events of data producers During the processing of an order in the physical system, data producers such as sensors and IoT-devices are capturing information on the progress, i.e. events of state-changes as e.g. start or finish of the production step of an order. These order updates are published to a defined endpoint where they are collected and processed (2.). While those events would actually be happening in the physical manufacturing system, a simulation model might be used to create test-data for the digital twin (see the post on Virtual Commissioning for another example of this use-case for simulation).\n2. Capturing events with AWS Kinesis  Kinesis is an AWS service for continuous buffering and real-time processing of streaming data. A Kinesis stream decouples data producers and consumers and consists of a configurable number of shards, each of which is able to ingest up to 1 MB or 1000 records of data per second. Each record is put into one shard based on it\u0026rsquo;s specified partition key value, which gets important since in-order processing of records is guaranteed only on partition key level.\nIn the described scenario in-order processing becomes critical for ETA-updates of orders, since the message of an expected delay must not be processed before an earlier submitted update.\nNew records can be put to the stream e.g. using the AWS SDK, which is available for various languages, including Python which is used for the emulated test client.\n3. Processing events with AWS Lambda  Lambda is the function-as-a-service offer of AWS, which allows to run code on-demand, paying for the number of invocations as well as for execution time. Lambda functions can easily be integrated with other services such as SQS and DynamoDB. Since AWS provisions the function runtime on-demand, the short cold-start times of NodeJS and Python make them a popular choice for implementing lambdas, while \u0026ldquo;heavier\u0026rdquo; alternatives such as Java are less common (the JVM would need multiple invocations for the JIT-compilation to boost performance).\nThe lambda implemented for processing order updates is simple and just updates the corresponding item of the affected order in a specified DynamoDB table with data from the event provided as part of the invocation.\n4. Persisting the system state with DynamoDB  DynamoDB is used as a fast, flexible and managed NoSQL database. While this type of database by design lacks some of the amenities of relational databases (such as proper means to enforce referential integrity on the database level, or the availability of sophisticated ORMs and schema management tools), it is fine for our simple use-case which just involves updating single items and basic queries. DynamoDB requires a hashkey and optionally a partition key, both of which are used in combination to uniquely identify a stored item. For orders the string id can be used as the hashkey. A nice feature of DynamoDB is the option to enable streams, automatically providing information on table-updates. This way, order ETA-updates can trigger new forecasts.\n5. Simulating the future AWS allows to use Lambda functions as DynamoDB stream event consumers, so that simulation runs can forecast future order completion times on every state change.\nFor each run, the complete system state is fetched from the DynamoDB (which might actually need multiple requests, since a single scan might only return a page of up to 1 MB of data).\nBased on the registered process timestamps, the currently relevant process step of each order can be identified.\nThe simulation model is generated from the process diagram shown above using Casymda. For the sake of simplicity of this proof of concept, processing times are assumed to be deterministic (even though stochastic behavior could be easily modeled, it would require averaging multiple runs). Model blocks are implemented to account for already elapsed processing time of work-in-process-entities at the start of the simulation (one of the possibilities to initialize online simulation models discussed in the often-cited paper of Hanisch and Tolujew, 2005, further explored by Hotz, 2007). During the execution, forecast metrics are collected in form of predicted process step completion times. Currently, AWS allows Lambda function executions to take up to 15 minutes, so that even complex models can be run this way. However, frequent and long running calculations might make it more attractive to create a dedicated service.\n6. + 7. Forecast persistence and visualization At the end of each run, the gathered results are persisted in a second DynamoDB table, from where a dashboard application can access and visualize the data.\nPlotly Dash is a popular framework for analytics web-apps. It enables the quick creation of dynamic dashboards just by writing Python code. Under the hood, it uses flask to serve React websites with plotly charts to a browser. Data queries and analysis are done on the backend using Python. The implemented dashboard just contains a simple gantt-chart (and serves only as a very basic example, leaving lots of room for extension). Automatic dashboard refreshes are implemented using an interval-callback to cyclically poll the database for updates.\nA dashboard\u0026rsquo;s Docker container could be run on AWS (e.g. ECS/Fargate, but since the free version of LocalStack does not include this it will just be run locally for demonstration).\n Result To run the setup locally from within the cloned repository, Docker and Terraform need to be installed.\nEven though the performance is not comparable to the actual cloud service, LocalStack is an awesome option to serve a multitude of AWS services locally, including Kinesis, Lambda, and DynamoDB. LocalStack can be started in a privileged Docker container, spawning more containers as needed, e.g. for executing Lambdas. It can be started via:\ndocker-compose up localstack  Before the Lambda functions can be deployed, the function code and its dependencies need to be packaged:\ndocker-compose up package-ingest-lambda package-simulation-lambda   Terraform is a great and widespread tool which can automatically provision infrastructure resources described in configuration files (however, have a look at this article for a more nuanced analysis). To create all required resources, two terraform commands are needed:\ncd terraform terraform init # required once terraform apply # enter 'yes' when prompted to confirm the changes (or use -auto-approve) cd ../ # return to project root  (To prevent 404 errors when calling apply after a restart of LocalStack without calling terraform destroy, first delete the terraform.tfstate files next to main.tf.)\nAfter the successfull creation, two more containers can be started - one serving the dashboard and one running a simulation model to emulate real event producers:\ndocker-compose up dashboard emulation  Before (re-)starting any test-run, the DynamoDB-tables need to be cleared:\ndocker-compose up truncate-tables  http://localhost:8050 should now show the empty dashboard, while http://localhost:5001 should show the generic Casymda web canvas animation controls. To enable automatic refreshes use the switch above the chart on the dashboard.\nWhen starting the emulation, orders will be created at the source and flow through the defined process.\nAt the same time, the dashboard should update with a minor delay and visualize the completion times of the relevant process steps of all orders which are currently present in the system. A vertical line in the chart indicates the point in time when the simulation run started and the forecast was created.\n Sample flow 1. The first order is created The simulation forecasts process step completion times as defined in the model:  2. The second order arrives and Order-1 production starts The forecast does not show problems:  3. After some time, an ETA update for the Order-2 material delivery is communicated, and a delay of 1/3 is now expected The forecast shows the announced delay (orange) and the expected shift of the production step of Order-2:  4. Order-1 is finished (and therefore excluded from the forecast), but now Order-3 arrives The forecast reveals an upcoming problem! Caused by the capacity constraint of the production step (max. one order concurrently), the delay of Order-2 (orange) will also prevent to start the of production of Order-3 on time, even though the material is expected to be ready by then (red):  5. When Order-2 is almost finished, a 4th order comes in As the forecast shows, the delay of Order-2 will cascade and also affect Order-4:  Complete screen-cast:\n  While this was just a proof of concept and the presented example would have been easy to calculate by hand, there are plenty of improvements and extensions imaginable.\nLooking at the scenario and business use-case, it would be interesting to add more complexity to the process, such as inventory for raw materials, and different replenishment strategies. Similarly, the impacts of stochastic or planned machine maintenance intervals might be evaluated. Another extension would be to incorporate targets into the process, such as order-specific due dates or throughput goals. This might then ask for additional optimization procedures to determine optimal production control policies (similar to the case presented in the thesis mentioned in the beginning of this article).\nInteresting technical extensions include security aspects such as authentication and authorization of different data producing parties, as well as an integration of the IoT-related services of AWS, which might offer dedicated features to gather data with sensors and edge devices for the digital twin. Concerning the analytics of ingested event data, stream processing solutions such as AWS Kinesis Data Analytics might be useful to identify relevant patterns and trigger forecast and optimization runs only in case of critical process deviations.\n","date":1603756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603756800,"objectID":"dc64b061430e8718b9ed33ca22f54776","permalink":"/post/csa-simulation-based-sc-forecast/","publishdate":"2020-10-27T00:00:00Z","relpermalink":"/post/csa-simulation-based-sc-forecast/","section":"post","summary":"Proof of concept using Casymda on AWS, ft. Terraform and LocalStack","tags":null,"title":"Real Time Simulation-based Supply Chain Analytics","type":"post"},{"authors":["Wladimir Hofmann"],"categories":null,"content":"The planning and design of logistics systems - both at supply-chain and intralogistics level - is frequently supported by simulation studies, used for comparing design alternatives, assessing their feasibility, as well as estimating KPIs like lead-time or throughput.\nWhen it comes to the realization phase of logistics systems, major challenges relate to the development of controls and operational IT systems. Given the fact that testing, integration, commissioning (and bug-fixing) of these systems tend to consume a significant chunk of the realization phase, it becomes clear that it is beneficial to test a developed system as early as possible - even before physical construction takes place.\nVirtual Commissioning describes the testing of software against the digital counterpart of a real system, making use of simulation models to emulate real-world interaction.\nThis post will show an example of how the integration of simulation-based testing into today\u0026rsquo;s agile software development processes can look like, investigating a case-study on order management \u0026amp; delivery optimization.\n  Get the repo from github: https://github.com/fladdimir/csa-vcom\n  1. Scenario \u0026amp; Scope Remember La Pâtisserie, the small French bakery in Hamburg-Altona, which was experiencing a massive shift of demand towards at-home delivery of their sweet pastries?\nHaving evaluated different options of how to scale their business-model with help of an innovative open-source approach to urban delivery network simulation, the growing network now gets harder and harder to manage, calling for an increased software-based support of the bakery\u0026rsquo;s daily logistics operations\u0026hellip;\n2. Processes \u0026amp; Requirements To be able to focus on their core-competencies (to conjure up delicious treats, instead of fighting intractably inconsistent spread-sheet data), our bakery decides to go for a web-based logistics planning application.\nThe core processes to be supported are:\n Registration of customers, and tracking their orders Managing locations of the depots to plan the best-possible deliveries Keeping track of the trucks, delivering goods according to the planned tours  The following BPMN-diagram shows the the processes and a simple token-flow animation:\n  3. Test First: Simulation Model + Build-Pipeline To make sure that all required processes are adequatly supported by the developed software, our bakery\u0026rsquo;s software development division opts for a test-driven approach, backed by a build-pipeline which automatically checks all code pushed to the repository.\nBased on the specified business process a Casymda simulation model is generated, ready to emulate the real system, with which the developed software is supposed to work. As processes and scope of the application change, the simulation model is evolved in an agile way.\n Gitea and Drone form the basis of the continuous integration infrastructure. As part of a virtual commissioning step, the pipeline spins up the application in a service-container, against which the simulation model runs the test-scenario, emulating interaction and verifying the expected behavior of the software.\nThe pipeline is described by a .drone.yml file. Note that the pipeline could be improved in various ways, e.g. by properly waiting for the app (service) to become available for the simulation-step. A docker-compose.yml allows to start the gitea+drone setup locally (using a single-instance setup, which is not ideal, but sufficient for testing).\n 4. Application Design \u0026amp; Implementation Our bakery\u0026rsquo;s app is dealing with management of the data of customers, orders, depots, tours, and trucks. Additionally, it is required to support planning the delivery process by calculating efficient tours and assigning them to available trucks.\nThe app adopts a basic 3-layer structure consisting of a browser-based ui, a backend containing the business logic and optimization algorithms, and a persisting database. The graphic below summarizes the setup, including the simulation model which acts as a client in the automated build pipeline:\nThe backend is implemented using Django+ Django-Rest-Framework, and relying on Google-OR-Tools for optimization tasks. Tour planning is modeled as a capacitated vehicle routing problem with multiple depots. For an optimal assignment of pending tours to available trucks, OR-Tools offers a minimum-cost-flow solver which is used on a corresponding bi-partite graph.\nTo create the required distance matrices, we can utilize the Open Source Routing Machine, provided as a ready-to-use Docker image ( OSRM-in-a-box). OSRM offers a convenient API which is synchronously consumed upon creation of a new customer or depot. Open-street-map data can be downloaded e.g. from https://download.geofabrik.de. The map of Hamburg has a size of ~35 MB and OSRM-preprocessing (car-profile) takes about 30 seconds (i5 dual-core notebook processor).\n SQLite provides a simple database solution, however, Django makes it easy to switch to a client/server RDBMS like Postgres or MariaDB.\nThe basic frontend is built with Angular, Material, and Leaflet.js (easy to integrate thanks to ngx-leaflet).\n 5. Result The screencast below shows the workflow from a users perspective. It comprises registering a new customer, issuing an order, planning tours, assignment to a truck, and tracking deliveries as the tour proceeds:\n The shown process matches the one executed by the simulation model in the virtual commissioning pipeline build step, ensuring stable functionality for every version of the software:\nExtensive and automated integration testing with simulation models can help to enable and sustain software quality, particularly in the context of process-centric logistics applications. As we\u0026rsquo;ve seen, today\u0026rsquo;s software development tools and standards allow for an efficient integration of simulation techniques \u0026amp; virtual commissioning approaches into the development process.\n","date":1590278400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590278400,"objectID":"76695c1a9c02e94a19e6a072ed8a1b7c","permalink":"/post/csa-vcom/","publishdate":"2020-05-24T00:00:00Z","relpermalink":"/post/csa-vcom/","section":"post","summary":"Continuous Integration \u0026 Virtual Commissioning, OR-Tools, Django, Angular","tags":null,"title":"Logistics Process Models for Automated Integration Testing","type":"post"},{"authors":["Wladimir Hofmann"],"categories":null,"content":"A really nice and quite unique feature of Anylogic is the possibility to include GIS-maps into simulation models. It allows to place elements on a map and move them along existing routes, based on real spatial information. This is cool because it can be used to simulate entire supply chains, including means to provide a great, tangible visualization for complex problems.\nThis previous project used Anylogic to evaluate different designs and delivery schemes for a more sustainable urban logistics network in the city center of Grenoble in France. The data-driven simulation model allows to quickly calculate KPIs for various transshipment node locations and different types of transport equipment in a multi-tier supply-chain network.\nFollowing the success of the feature, Anylogic even built anyLogistix, combining pre-built \u0026amp; customizable simulation models with a commercial solver for integrated supply chain planning \u0026amp; optimization.\nObviously, those commercial features come at a price, so let\u0026rsquo;s see whether this kind of model can also be realized with different means.\nThe simulation model of this post will be based on a mini-case-study.\n   Get the repo from github.\n  Scenario \u0026amp; Scope Facing the fact that humanity gets more and more used to home-delivery of even everyday necessities, the small French bakery Die Patisserie in Hamburg-Altona wants to deliver sweet pastries to nearby customers.\n3 major purchasers were identified: the lost-and-found office Zentrales Fundbüro, Monkeys Music Club, and the publishing house Carlsen Verlag.\nCoordinates of the different locations:\n    Node Name Lat Lon     1. PAT Die Patisserie 53.55668 9.92815   2. ZFB Zentrales Fundbüro (lost-and-found office) 53.55817 9.92829   3. MMC Monkeys Music Club 53.55706 9.93161   4. CAV Carlsen Verlag (publishing house) 53.55703 9.92684    For the sake of simplicity, the order in which nodes are visited is assumed to be fixed. The tour starts \u0026amp; ends at the patisserie:\n Simulation Model The simulation model for the simplistic scenario is created with:\n OSMnx/networkx for retrieving geo-information and calculating shortest-paths SimPy/Casymda for simulating the tour Leaflet.js for browser-based animation  1. OSMnx The awesome OSMnx package provides the possibility to obtain a networkx-graph representation of a street-network from OpenStreetMap with a single line of code. A relevant section for our scenario can be obtained by specifying center and distance for osm-nodes to be included:\nCENTER = (53.55668, 9.92815) DISTANCE = 300 G = ox.graph_from_point(CENTER, distance=DISTANCE, network_type='drive')  OSMnx lets us pick the nearest osm-node for each of the 4 locations of the tour, and also offers convenient means to plot the network. Blue dots represent osm-nodes, connected by edges. The 4 relevant locations are shown in red:\nTo prepare all information needed by the simulation model, now all shortest paths between the 4 relevant nodes in the network are computed with networkx, and detailed information on all piece-wise linear segments for each route is included. The results are pickled and saved to disk to avoid fetching and recalculation for each run of the model (of course its kind to keep the load for the OSM-server as low as possible).\nThe above described approach could be improved, e.g. by automatically determining the area to be loaded from the given relevant locations. Instead of just picking the closest osm-node for each relevant location, it would also be more precise to first go for the closest edge in the network. And as the network size grows, it might be a better idea to directly query the shortest path between relevant nodes from the OSM-server, instead of fetching the network as a whole (the way Anylogic seems to do it).\n2. Casymda/SimPy  Casymda provides block-based modeling of discrete-event-simulation models on top of SimPy.\nOur model can be characterized by a simple process:\nA truck is created at a parameterized Source and then processed at a custom DriveTour-block, which contains the logic for elapsing time according to the length of a route and the movement speed of the truck. It also contains the option to calculate intermediate locations for animation. The nodes to be visited are specified via the text-annotation stops=[\u0026quot;ZFB\u0026quot;, \u0026quot;MMC\u0026quot;, \u0026quot;CAV\u0026quot;].\nThe animation is implemented by exposing information and resources via flask (similar to the tilemap-animation described in the previous post).\n3. Leaflet.js To visualize the location of nodes and entities on a map, Leaflet only requires a few lines. For setting the rotation angle, there is the Rotated.Marker-plugin.\nmarker = L.marker(element.coords, { icon: new L.Icon({iconUrl: element.icon_path}) }).addTo(map); marker.bindPopup(element.text); marker.setRotationAngle(element.direction);   Result To run the simulation via http://localhost:5000:\ndocker-compose up geo-web-animation  The screencast below shows a complete tour of a truck visiting all nodes in the defined order (Patisserie - Lost-and-found - Monkey\u0026rsquo;s - Carlsen Publishing - Patisserie).\n  The one-way street Völckersstraße is correctly taken into account when moving from Monkeys Music Club (3., right-most node) to Carlsen Verlag (4., left-most node).\n Of course there are numerous improvements and extensions imaginable, including e.g. the calculation of more realistic driving times based on actual speed limits which are already part of the available OSM-data.\n","date":1585958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585958400,"objectID":"af0bc37ce2a741595c24c45ed53e0aa9","permalink":"/post/csa-streetmap/","publishdate":"2020-04-04T00:00:00Z","relpermalink":"/post/csa-streetmap/","section":"post","summary":"Anylogic's GIS-Feature w/ SimPy, OSMnx and Leaflet.js","tags":null,"title":"Urban Logistics Network Simulation in Python","type":"post"},{"authors":["Wladimir Hofmann","Clemens L. Schwarz","Fredrik Branding"],"categories":null,"content":"Reinforcement learning represents an emerging technique from machine learning. It can autonomously derive complex action sequences in dynamic environments and is successfully applied in various fields, e.g. from robotics and gaming. Instead of explicitly defining a specific solution strategy for a problem, we can just provide an environment. A self-learning agent will then autonomously discover successful strategies just by interaction.\nNeedless to say, there is nothing new under the moon and previous studies show the general feasibility of using RL for solving production-logistics problems.\nSo why do we think that there is the need for yet another article about this very topic?\nFirst, there is a lot of active development in RL, as well as in the application of Digital Twins in production/logistics. We believe that there lies even more potential in integrating these concepts. Furthermore, we found the often derogatory-treated \u0026ldquo;low-level implementation work\u0026rdquo; to be an actual obstacle for making progress in this challenging and highly inter-disciplinary area of applied research. This contribution strives to show a working example based on a tool-stack which seamlessly integrates two of the most popular open-source software packages from their respective areas: stable-baselines for RL and SimPy for implementing Digital Twins.\n Get the repo: https://github.com/fladdimir/tugger-routing\n Outline   Outline  Introduction \u0026amp; Basics   Reinforcement Learning  Digital Twins and Discrete Event Simulation   Casymda-Package    Wrapping a DES-Model in a Gym-Environment    Case-Study   Scenario  Simulation Model  Preparing the Gym-Environment   Observation- \u0026amp; Action-Space  Rewards    RL-Agent Training \u0026amp; Evaluation  Performance Comparison    Summing Up  Introduction \u0026amp; Basics Reinforcement Learning If you still ask yourself what RL is capable of, we definitely recommend to have a look at what the guys from openai are doing.\nAdmittedly, thats probably a quite sophisticated and highly engineered example, but it breaks down to a simple interaction between an agent and an environment. Technically, this interaction is defined by an interface (or abstract base-class as Python likes to put it), which is part of the gym-package.\nThe graphic below illustrates the exchange of information between agent and environment. First, the agent calls the environment\u0026rsquo;s step method, providing the action to be executed. The environment then processes the action and returns:\n the new state of the system (observation), the reward which occured during the step (might be zero), a done value potentially indicating the end of an episode (and the need for a subsequent reset) and an info-object (might contain additional information e.g. for logging purposes).  The interface also prescribes more, such as the formats of action-space and observation_space, as well as render and reset behavior.\nThe various RL algorithms provided by the stable-baselines-package are ready to work with environments implementing this gym-interface. All that is left to do is creating a compliant environment - and in the next section we will show how this can be achieved in the domain of logistics.\nDigital Twins and Discrete Event Simulation Frankly, Digital Twin is probably the most overused buzzword of all the \u0026ldquo;Lostistics 4.0 / Industry 4.0\u0026rdquo; stuff that is out there. Even though we could not resist to put it into the title, from now on we\u0026rsquo;ll prove that we can do better and use the more specific term \u0026ldquo;Discrete Event Simulation\u0026rdquo; (DES).\nWhy DES? Discrete Event Simulation is one of the widespread tools for analysis and design of logistics systems. Today\u0026rsquo;s applications go beyond the traditional usage for systems planning. They include more operational use-cases such as virtual commissioning or short-term forecasts. Simulation models are getting integrated tightly into other IT-systems. This allows to increase process transparency and to improve our means to analyze, control, and optimize system performance in real-time. Doesn\u0026rsquo;t this sound pretty close to what Digital Twins always promise?\nMost industrial simulation uses are still based on commercial packages.\nHowever, there are a couple of open-source alternatives, which are typically closer to general-purpose language programming. Even though they tend to lack some convenient commercial features, there are upsides such as better scalability and simplified interfacing.\nRelated to Python we became aware of two popular DES packages: Salabim and SimPy. Both are not only free and open-source, but even built on top of the standard library of one of the world\u0026rsquo;s most popular programming languages - let\u0026rsquo;s see what we can get out of that!\nCasymda-Package Based on SimPy, we added bits of complementing functionality to gain some of the modeling convenience of commercial \u0026ldquo;block-based\u0026rdquo; DES-packages.\nCasymda facilitates the usage of bpmn-process-descriptions to generate corresponding simulation-model python-code. .bpmn-files (basically xml) can easily be created with the Camunda-Modeler.\nThis graphical modeling helps to maintain an overview of the high-level model-structure. Generated Casymda-models also include a generic, token-like animation of simulated processes out-of-the-box, ready to be run in a web-browser. For presentation and debugging, animations can be paused and their speed can be changed dynamically. Solely animation-related events are not scheduled if the simulation is run without visualization. This maximizes the execution speed - which becomes especially important related to RL, when a high number of runs is necessary.\nFurther features of Casymda include simulated movements along shortest paths in a 2D-tilemap-space, and gradual typing for development convenience (checkout pyright if you are using vscode).\nFor more info on Casymda have a look at the repo or the (German) website.\nWrapping a DES-Model in a Gym-Environment To be able to train an RL-agent inside a simulation model, we need to make the model implementing the Gym-interface described above.\nThe following diagram illustrates the coupling concept:\nWhen the step function of the Gym-Environment is called (1), the provided action is propagated to the relevant block of the simulation model (1.1). This is realized with help of an ActionHolder, so that a consuming piece of decision logic can dispatch according to the received information.\nSubsequently, the simulation is executed until a next_action_needed-Event is triggered by the simulation model (1.2). This is indicating the end of the current step and the need for another action of the agent.\n One Gym-step can thus comprise an arbitrary number of discrete SimPy-steps, each of which can in turn take an arbitrary amount of simulated time.\n Rewards are managed with help of a RewardHolder object, which is wired into the relevant blocks of the simulation model during environment initialization. At the end of each step, occured rewards are collected (1.3). Depending on the type of the optimization problem to solve, a post-processing of collected rewards can be applied (e.g. taking into account the amount elapsed time, so that an agent can learn time-efficient behavior).\nTo check whether an episode ended (the done part of the returned information), the current state of the model is checked against configured done_criteria (1.4). These can contain e.g. some goals to be reached or a certain amount of time to be simulated.\nTo provide the agent with an observation, a model-specific ModelStateToObservationConverter is used to collect relevant information from the model. The created observation conforms to the defined observation_space (1.5). This step could include e.g. counting the number of entities in different queues or checking inventory levels and creating a NumPy-array out of this information.\nFinally, collected information is returned to the agent (2), which can learn based on the reward and decide for the next action.\nHaving the basics covered, let\u0026rsquo;s see how we get this to work.\nCase-Study Back in August of last year at the MIM2019 in Berlin, we had the chance to attend an interesting talk of two Bavarian guys presenting their research on improving the tour-building for in-plant milk-run systems. These internal deliveries are commonly used for assembly line supply, and the tours are typically following a very rigid plan. Given the fact that the actual demand at the line tends to vary, their research revealed quite a lot of potential to decrease delivery lead times and to increase systems\u0026rsquo; utilization - just by making the tour-planning more dynamic.\nBased on this setting we constructed an abstracted and simplified version of an assembly line with a corresponding material supply system to provide a playground for reinforcement learning algorithms.\nScenario The image below shows a schematic layout plan of the system:\nUnfinished products enter the system on the upper right (I) and are assembled sequentially at 9 different stations, arranged in U-shape (I-IX). Finished products leave the system after the last assembly step (IX).\nStations require a certain amount of resource of either type A or B to be present in the station\u0026rsquo;s inventory before an assembly step can start.\nEach station can only hold one product at a time, and finished products can only be forwarded once the following station is empty (thus multiple upstream stations holding already finished products may be blocked by downstream stations which are still processing a product or waiting for material before being able to start processing).\nMaterial is supplied by a tugger, able to carry a limited discrete amount (\u0026ldquo;boxes\u0026rdquo;). The tugger can load material at a stock (A and/or B, located at the bottom). 1 discrete unit of material (\u0026ldquo;box\u0026rdquo;) can be loaded/unloaded at a time. The goal of the assembly line is achieving the maximal throughput, which also correlates with small lead-times of products.\nAssumptions:\n material can only be loaded at the stocks (A and B), each of which holds an infinite amount of material, so that the tugger never waits for material at a loading site material can only be unloaded at a station actually requiring this type of material (hence a tugger cannot unload a box of A at a station which needs B for assembly) the inventory capacity at the stations (I-IX) is infinite, so that the tugger never waits at an unloading site (otherwise livelocks could occur where a tugger cannot unload material wherever it moves)     System parameters      Takt-time: processing time per station per product 60s   Demand per product of stations type A 1.5 units   Demand per product of stations type B 0.5 units   Tugger movement speed 10 m/s   Tugger capacity 25 units   Amount of material (un-)loaded per step 5 units   Time needed per (un-)loading step 5s    Distances between stocks and stations (higher demands cause more frequent tours):\n   Relation Simple Demand-weighted     A -\u0026gt; T1 1096.40m 1644.60m   B -\u0026gt; T2 926.40m 463.20m   A -\u0026gt; T3 736.40m 1104.60m   B -\u0026gt; T4 566.40m 283.20m   A -\u0026gt; T5 234.10m 351.15m   B -\u0026gt; T6 556.40m 278.20m   A -\u0026gt; T7 726.40m 1089.60m   B -\u0026gt; T8 916.40m 458.20m   A -\u0026gt; T9 1086.40m 1629.60m    The table below shows a simple throughput estimation by calculating the average cycle time of the tugger and the expected station utilization. The estimation assumes \u0026ldquo;full truck loads\u0026rdquo;, always completely loading at one stock (either A or B), and fully unloading at a station (T1 - T9).\n   Throughput estimation      Max throughput 24h 60/h x 24h = 1440   Demand / product 9.5 units   Demand / time 9.5 / 60s = 0.16/s   Average weighted distance 811.37m   Average driving time 81.137s   (Un-)loading time 25 units 25s   Average cycle time (81.137s + 25s) x 2 = 212.274s   Delivered units / cycle 25   Delivered units / time 0.12/s   Average utilization 0.12/s / 0.16/s = 75%   Expected throughput per min 75% x 60/min = 45/min   Expected throughput per 24h ~1080/24h    As we can see, the delivery performance of the tugger represents the limiting factor (bottleneck) of the system, which means that each improvement made here will be directly reflected by a corresponding increase in the overall throughput.\nFor the sake of simplicity, no stochastic model behaviour (such as e.g. randomly distributed loading or movement times) is assumed, hence the simulation model will be deterministic.\nAs stated: the system as a whole is quite abstracted and simplified - but still capturing at least some of the basic complexity inherent to real-world problems. Will our RL-agent be able to\u0026hellip;\n grasp the underlying mechanics? distinguish different product types? discover the spots of demand and supply? deal with the limits of the tugger\u0026rsquo;s capacity? reach the maximal possible throughput?  We\u0026rsquo;ll find out, but let\u0026rsquo;s first have a look at what the learning environment will look like.\nSimulation Model The simulation model of the system basically consists of 2 processes, both depicted in the graphic below.\nOn the left side, products pass through the 9 assembly steps (ProductStation, rotated U-shape) before leaving the system, occasionally being blocked by downstream stations or waiting for material at a station.\nOn the right side the tugger passes through an infinite cycle of movement and loading/unloading process steps (after initial creation at location A by a TuggerSource):\n the next movement target is chosen and the movement is completed (no actual movement if the next target equals the current location) (TuggerMovement). Depending on the current location (being either a stock A/B) or a ProductStation, the next tugger process step is chosen:  TuggerStock A loading of one unit of A (if tugger-capacity not reached) TuggerStock B loading of one unit of B (if tugger-capacity not reached) TuggerStation unloading of one unit of A or B if possible (material required by station is loaded)    Note that even unsuccessful loading or unloading attempts are implemented to take a small, fixed amount of time, so that every possible Gym-step is guaranteed to take at least some simulated time (and a time-constrained episode is guaranteed to reach its end eventually).\nBelow you can see a process animation, as well as an animation of a tilemap. The agent here follows an explicitly defined simple rule of always delivering a complete load of 25 units to the station with the lowest inventory level. To run the animation just clone the repo, run the command, and visit http://localhost:5000.\nProcess animation:\ndocker-compose up web-animation-lia-process  Tilemap animation:\ndocker-compose up web-animation-lia  Preparing the Gym-Environment The TuggerEnv implements the Gym-Env interface and wraps the simulation model to be used for RL-agent training.\nGeneric functionalities like the mandatory step and reset functions and related helper methods are inherited and abstract/default parent-methods are overridden in a model-specific way as required (Template-Method Pattern):\n initialize_action_and_reward_holder specifies which model blocks\u0026hellip;  need access to gym-actions: TilemapMovement, choosing the next movement target based on the supplied target index number log achieved rewards: ProductSink, simply counting a reward of 1 for each finished product   get_reward specifies how the elapsed time is taken into account for reward calculation check_if_model_is_done implements a model-specific check whether a certain amount of time has been simulated. One episode is scheduled to take 24h (86400s).  The render method of the Gym-Env is not implemented, since animations at arbitrary moments in time - whenever a Gym-step is finished - do not make much sense for discrete event simulation environments. The animation is controlled separately.\nThe info return value of step is configured to return the number of finished_products which can then be logged.\nObservation- \u0026amp; Action-Space The model-specific extraction of the observation from the current model state is done by an instance of a TuggerEnvModelStateConverter which implements the ModelStateConverter \u0026ldquo;interface\u0026rdquo;.\nSpecifically, the observation consists of the following information which describes the current state of the system (overall 48 values):\n ProductStation observations (5 values x 9 stations = 45 values):  current inventory-level (normalized 0-1, counted up to a limit of 10 units) busy-state (binary) waiting_for_material-state (binary) empty-state (binary, whether a product is present or not) blocked-by-successor-state (binary)   TuggerEntity observations (3 values x 1 tugger = 3 values):  loaded amount of A (relative to capacity) loaded amount of B (relative to capacity) current location (index)    Note that parts of a station observation can be seen to be redundant (e.g. a station which is neither busy nor waiting nor empty can only be blocked) - behind lies the rationale that an intelligent algorithm will (hopefully) learn an importance of different components of an observation, so that we do not have to worry about more than providing all potentially useful information.\nThe action_space (of type gym.spaces.Discrete) consists of the 11 possible movement targets (9 stations + 2 stocks, encoded by index).\nRewards As stated above, the defined goal of the assembly line is to achieve the best possible throughput of products, which corresponds to producing as many products as possible e.g. during one episode (24h).\nHow do we achieve that? Which kind of incentive is suitable to stimulate such a behavior? The design of appropriate reward functions is known to be a non-trivial matter. In fact, the design of rewards and incentives even for (arguably more intelligent) humans is a major problem in management and education (remember the last time you studied for passing an exam instead of actually learning useful contents).\nFor the environment at hand, we could just think about giving a single reward at the end of each episode, proportionally to the number of achieved products in that fixed amount of time (24h), which would probably properly reflect our aim of maximizing the throughput. However, the resulting reward would be quite sparse and therefore greatly decelerate learning speed (taking the average duration of a random action, each episode would take more than 1000 actions to complete before an agent sees any reward).\nAnother idea would be to reward every successful delivery of material to any station, which would be possible to be completed within 2 steps (movement to the stock \u0026amp; movement to a suitable station consuming the loaded material). This way we would get less sparse rewards, but also an obvious problem of exploitability, caused by the fact that the delivery of material to one station alone would actually never lead to the completion of any product at all.\nAs a compromise, we simply decided to go for a reward of 1 everytime a product completes its final assembly step, which is possible be completed within 12 steps (minimum, not necessarily an optimal strategy). Even exhibiting a random behavior, this would allow an agent to generate a reward of around 50 during one episode, so that there are sufficient \u0026ldquo;randomly succesful\u0026rdquo; samples to learn from.\nOne problem with this reward comes from the fact that the simulated time needed to obtain a reward is not reflected by the reward itself. Since every gym-step can actually eat up a greatly varying amount of simulation time (from 5 seconds to \u0026gt;100), there is a huge implicit impact on the throughput, which the agent is unaware of. To solve this problem we introduced \u0026ldquo;costs of time\u0026rdquo;, which means we simply give a small negative reward every step, proportional to the amount of simulated time that passed. This finally leaves us with the subsequent question of how big these \u0026ldquo;costs\u0026rdquo; should be. If set too high, they would just overrule any of the few actual rewards at the beginning of the training. If put too low, there would not be sufficient stimulus to exhibit time-efficient behavior at all. Again, as a simple compromise, we implemented the costs to grow proportionally with the highest reward seen so far at the end of an episode, which guarantees a certain balance, and rewards increasing time-efficiency.\nThe above described reward that we designed is definitely not \u0026ldquo;perfect\u0026rdquo; and also feels a bit like putting too much effort into \u0026ldquo;reward engineering\u0026rdquo; - nevertheless its a first solution our agents can hopefully work with\u0026hellip;\nRL-Agent Training \u0026amp; Evaluation The environment presented above is characterized by a Discrete action space and a continuous (Box) observations space. The stable-baselines documentation lists available RL algorithms and their compatibility.\nDue to the type of action space, some algorithms are not feasible (i.e. DDPG, SAC, and TD3).\nTo train a stable-baselines RL algorithm, the TuggerEnv is vectorized, using a DummyVecEnv and a standard MlpPolicy. To leverage multiple CPUs for training, it can be desirable to use a SubprocVecEnv (but for simpler logging \u0026amp; analysis we did not go with that one here, instead we did multiple independent training runs in parallel).\nTrain an ACER-agent (by default for 10,000 steps only, which should take \u0026lt;1min):\ndocker-compose up acer-training  Plot performance (might require additional setup for connecting the display):\ndocker-compose up acer-plot-training  Tilemap-animation of the trained agent (http://localhost:5000):\ndocker-compose up acer-web-animation-tilemap  Below we can see an ACER-agent trained for 1m steps:\n As we can see, the agent manages to fully load the 25 units onto the tugger most of the time, seems to target correct (A/B) stations for material unloading, and the choice of stations with a currently low inventory level seems reasonable too!\n But how does the overall performance look like?\nPerformance Comparison For comparison we trained four algorithms (ACER, ACKTR, DQN, and PPO2) with standard settings for both 1 and 3 mio. (Gym-)steps. Training took up to 2.5 hours (DQN, 3mio. steps) on a 2.9GHz Intel i9, using a single-process DummyVecEnv as explained above.\nThe following graph shows the number of produced products per episode (24h) over the course of the training run for each algorithm, as well as the performance of the deterministic lowest-inventory heuristics (yellow line; always delivering a complete load of 25 units to the station with the currently lowest inventory), and the average performance of fully random actions (turquoise line, measured over 100 episodes).\n As we can see, all of the algorithms manage to increase the number of produced products per episode significantly above the level reached by random actions (turquoise line at the bottom), indicating successful learning progress. Furthermore, none of the trained algorithms reaches the performance of the lowest-inventory-heuristics (yellow line at the top). The lowest-inventory-heuristics performance reaches the estimated maximum possible throughput of the system (estimated to appr. 1080/episode). This strategy can therefore be considered to be close to a global optimum. During training, a complete breakdown in performance can occur. Most prominently: ACER_3mio. (blue line, episode 260, no recovery at all). Other algorithms show drops in performance as well but seem to recover better (e.g. ACKTR - green, PPO2 - pink). The best-performing RL algorithm (ACER trained for 1mio. steps, orange line) reached a maximum throughput of 856 products / episode (78% of the near-optimal heuristics performance).  The number of episodes varies due to the variable number of Gym-steps per episode (24h of simulated time), depending on the simulated time each Gym-step needs. The small number of episodes of the ACER_3mio. training is explained by the up to 17277 Gym-steps per episode, occurring from episode 260 on. Each step of such an episode takes only 5 seconds (the minimum possible time of all available Gym-steps, \u0026ldquo;achieved\u0026rdquo; by a repeated visit of the same location). This behavior might be caused by the defined negative reward per step, proportional to the amount of simulated time the step needed. Appearently, the agent does not remember how to generate a positive reward and only tries to maximize the short-term reward by minimizing the step-time. Obviously this behavior does not lead to any successful delivery, let alone completion of any product.\nIt is worth to be mentioned that all training runs were done with default algorithm settings, and that the evaluation of different hyperparameters is strongly recommended for performance optimization. Thus, it might not be improbable for an RL agent to close the performance gap towards the theoretically reachable optimum.\nSumming Up Short version: Our best RL agent reached about 78% of the best possible performance inside our production-logistics environment.\nOk, now is this good or bad?\nWell, one could be disappointed by the fact that our agent was not able to reach the performance of a hand-coded heuristics approach.\nBut did we believe when we started that we could get a generic piece of code to cope with the non-trivial relations of our specific and fairly complex environment? Certainly not!\nAnd this was just a first shot - we did not yet start with hyperparameter tuning or the evaluation of alternative rewards.\nWhat do your experiences with reinforcement learning look like?\nWhich logistics problems did you solve with RL?\nDid you spot a bug somewhere in the code or do you want to suggest an improvement?\nOr do you have questions concerning the presented implementation/toolstack?\nJust feel free to drop us a note, thanks for reading!\n Wladimir Hofmann - Clemens L. Schwarz - Fredrik Branding\n","date":1584748800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584748800,"objectID":"84970bbd3d98a4f423090d18e66425bb","permalink":"/post/tugger-routing/","publishdate":"2020-03-21T00:00:00Z","relpermalink":"/post/tugger-routing/","section":"post","summary":"Case-Study on Reinforcement-Learning in Logistics","tags":null,"title":"Digital Twin for Assembly Line Material Provisioning Planning","type":"post"},{"authors":["Wladimir Hofmann"],"categories":null,"content":"Discrete Event Simulation is a widespread tool for analysis and design of logistics systems.\nHowever, most industrial applications are realized using commercial simulators, and existing open-source alternatives still seem to lack some of the convenient features commercial packages are offering.\nThe Casymda-package strives to add some of these features, building on established standards such as BPMN and SimPy.\nThis post will introduce main features and show how to run a simple example.\n Get the repo.\n Existing Discrete Event Simulation Packages Current applications of DES go beyond the traditional usage for systems planning. They include more operational use-cases such as virtual commissioning or short-term forecasts \u0026amp; optimization. Consequently, simulation models are getting integrated tightly into other IT-systems. This allows to increase process transparency and to improve our means to analyze, control, and optimize system performance.\nMost industrial simulation uses are still based on commercial packages.\nAnd there are good reasons for this.\nIf you\u0026rsquo;ve already worked with commercial DES packages (such as Anylogic/Arena/ExtendSim/FlexSim/PlantSimulation/Simio/\u0026hellip;YouNameIt), you probably learned to like some typical characteristics:\n block-based graphical modeling of processes (often) vendor-specific scripting possibilities to define custom behavior and non-standard procedures (this is where things get fun) (3D) visualization / animation capabilities for debug / validation / presentation (fun as well, most of the time) domain-specific libraries with objects providing pre-built industry-specific behaviors (configuration and customization) interfacing options: spreadsheets, databases, socket, COM,\u0026hellip; (what\u0026rsquo;s the last one?)  However, there are a couple of open-source alternatives too.\nEven though they tend to lack some of the commercial features described above, there are upsides such as better scalability and simplified interfacing.\nRelated to Python there are (at least) two popular DES packages: Salabim and SimPy. Both are not only free and open-source, but even built on top of the standard library of one of the world\u0026rsquo;s most popular programming languages.\nCasymda: Features \u0026amp; Implementation Based on SimPy3, Casymda adds bits of complementing functionality to gain some of the modeling convenience of commercial \u0026ldquo;block-based\u0026rdquo; DES-packages.\nIt facilitates the usage of bpmn-process-descriptions to generate corresponding simulation-model python-code. .bpmn-files (basically xml) can easily be created with the Camunda-Modeler.\nThis graphical modeling helps to maintain an overview of the high-level model-structure. Generated Casymda-models also include a generic, token-like animation of simulated processes out-of-the-box, ready to be run in a web-browser. For presentation and debugging, animations can be paused and their speed can be changed dynamically. Solely animation-related events are not scheduled if the simulation is run without visualization. This maximizes the execution speed - which becomes especially important when a high number of runs is necessary.\nFurther features of Casymda include simulated movements along shortest paths in a 2D-tilemap-space, and gradual typing for development convenience (checkout pyright if you are using vscode).\nLet\u0026rsquo;s have a quick look at a simple example Casymda-model, illustrating some basic ideas.\nThe animation below shows a simple process consisting of 3 Casymda-blocks: Entities are created in a Source, pass a process-step called TilemapMovement, and leave the system via a Sink.\nTo run the example just enter the following command from within the repository and visit http://localhost:5000:\ndocker-compose up web-animation-tilemap-simple-process  Created block-objects can be parametrized with arguments provided as text-annotations (e.g. the inter_arrival_time=100 [seconds] of the entities at the source). The naming of blocks is parsed following the pattern ClassName:instance_name. The default process-animation includes additional information on the processed entities and on the state of each block.\nThe way in which animations are created by Casymda is inspired by the Anylogic implementation. A web-server is running the actual simulation, and providing frame information to be rendered by a browser. The corresponding Casymda functionality is implemented using flask and pixijs.\nBelow you can find an tilemap-animation of the TilemapMovement process step of the model. As specified in the text-annotation, entities move from_node=\u0026quot;A\u0026quot;, to_node=\u0026quot;C\u0026quot;. Tilemaps can be provided in .csv format, with field values indicating possible origin/destination nodes (e.g. A, B, and C), passable nodes (0), and impassable nodes (1). The size of each tile is configured as part of the tilemap configuration. Shortest paths and distances between all origin/destination nodes are computed using networkx.\nTo run the tilemap animation example just enter the following command and visit: http://localhost:5000\ndocker-compose up web-animation-tilemap-simple  Additional resources For additional information, feel free to have a look at other projects built with Casymda (German).\nInterested in machine-learning? The next post will show how to use a Casymda-model to train a reinforcement learning algorithm to solve a production logistics problem - stay tuned ;)\n","date":1584662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584662400,"objectID":"ac0e96e48e4078699830079dfbbe3f0f","permalink":"/post/casymda/","publishdate":"2020-03-20T00:00:00Z","relpermalink":"/post/casymda/","section":"post","summary":"Python-Package for Animated Discrete-Event-Simulation based on BPMN and SimPy","tags":null,"title":"Introducing Casymda","type":"post"},{"authors":["Wladimir Hofmann","Fredrik Branding"],"categories":null,"content":"Presented at: 9th IFAC Conference on Manufacturing Modelling, Management and Control 2019, Berlin, Germany\nFull text on ScienceDirect.\n","date":1566950400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566950400,"objectID":"2e24a158bf498d4b15206f774600b942","permalink":"/publication/mim2019/","publishdate":"2019-08-28T00:00:00Z","relpermalink":"/publication/mim2019/","section":"publication","summary":"Seaborne trade volumes are growing and the resulting traffic load on the road infrastructure in port areas calls for new solutions to improve handling and coordination of vehicles and shipments. In this contribution, a digital twin for truck dispatching operator assistance is presented, which enables the determination of optimal dispatching policies using simulation-based performance forecasts. Proprietary simulation software with limited interfaces, the application deployment in demanding industrial environments, and the integration of real-time sensor information represent three major challenges when realizing digital twin applications for logistics systems. This implementation, therefore, uses an extensible open-source simulation package and it is coupled with an IoT-platform for easy integration of real-time information. The digital twin is deployed as a cloud-based service, allowing for simple deployment and scalability.","tags":null,"title":"Implementation of an IoT- and Cloud-based Digital Twin for Real-Time Decision Support in Port Operations","type":"publication"},{"authors":["Wladimir Hofmann","Jan Hendrik Ulrich","Sebastian Lang","Tobias Reggelin","Juri Tolujew"],"categories":null,"content":"Presented at: 16th IFAC Symposium on Information Control Problems in Manufacturing, June 11-13 2018, Bergamo, Italy\nFull text on researchgate.\n","date":1528675200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528675200,"objectID":"6cc3ef54994f68b8354c46b8575df1c3","permalink":"/publication/incom2018/","publishdate":"2018-06-11T00:00:00Z","relpermalink":"/publication/incom2018/","section":"publication","summary":"Changeable material flow systems as well as the use of material flow simulation represent approaches to cope with the challenges of future logistics operations in times of growing complexity, frequently varying demands and shorter product lifecycles. Modular plug-and-play continuous conveying systems are a special type of changeable material flow systems suitable to meet the imposed requirements. This paper presents how simulation methods can be applied to support the development of modules for this kind of system. As an example, a simulation model for the virtual commissioning of modules for an “Industry 4.0 - Learning Factory” is described, which is currently developed at the Institute for Logistics and Material Handling Systems of the Otto-von-Guericke-University together with the partner institutions Fraunhofer IFF Magdeburg and TTI Riga, Latvia.","tags":null,"title":"Simulation and Virtual Commissioning of Modules for a Plug-and-Play Conveying System","type":"publication"},{"authors":["Wladimir Hofmann","Tom Assmann","Parisa Dolati Neghabadi","Van Dat Cung","Juri Tolujew"],"categories":null,"content":"Presented at: International Workshop on Simulation for Energy, Sustainable Development \u0026amp; Environment, September 18-20 2017, Barcelona, Spain\nFull text on researchgate.\n","date":1505692800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505692800,"objectID":"367266f93f5a50d6e616608075d10e10","permalink":"/publication/i3m2017/","publishdate":"2017-09-18T00:00:00Z","relpermalink":"/publication/i3m2017/","section":"publication","summary":"The use of cargo bikes for goods deliveries represents a promising concept of urban logistics. In this contribution, a new simulation-based assessment tool integrating this emission free vehicles in urban distribution systems is presented. First, typical schemes are identified and an analysis of the underlying planning problems is conducted. Second, the developed GIS-based discrete-event simulation model and the coupled tour-planning algorithm are described, implementing the pattern of control optimization. To the best of our knowledge, such a tool is not yet existing. Finally, the tool is applied, evaluating the potential use of cargo bikes for B2B-deliveries in the medium size city of Grenoble in France.","tags":null,"title":"A Simulation Tool to Assess the Integration of Cargo Bikes into an Urban Distribution System","type":"publication"}]