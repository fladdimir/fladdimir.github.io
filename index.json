[{"content":"Did you ever have the feeling that you know for sure that you did read about something, but you just cannot remember where? Sounds like it would be great to be able to index and search some stuff using a full-text search-engine..\nSimple design Consider the following simple design for an application\npersisting an uploaded document in an object-storage, saving metadata to a database, and indexing the document via a dedicated search-engine: After an upload request succeeded the search-index can be queried and relevant documents can be viewed/downloaded.\nAnd if something goes wrong? As described by Martin Kleppmann in his awesome book Designing Data-Intensive Applications, every component of a system should be expected to fail at any time (in particular when they are connected via network).\nThus, while the design shown above is simple, it may suffer from a couple of issues related to:\nAvailability: In the design shown above, all three data sinks need to be available to successfully process a document upload. If either one of them is (temporarily) unavailable, the request fails. In particular, the expensive indexing operation may become a bottleneck when processing concurrent requests. Consistency: Furthermore, only some of the three storage requests may actually succeed while others may fail. No matter how the three storage requests are ordered, a failure may leave the system in an inconsistent state, e.g. being able to find a document when searching via the index, but not when looking for the data in the object-storage (or vice-versa). These are known as dual-write issues. Decoupling components to improve availability Since the indexing is just relying on data which is also saved to the other stores, it could be postponed so that an upload request can succeed without requiring the search index to be available. In the following design, a message-queue is used to buffer indexing requests for asynchronous processing:\nThis may improve performance characteristics, since the indexing can limit the number of concurrently executed tasks by limiting the number of concurrently processed messages. Furthermore, the asnychronous processing of an indexing request can be automatically retried in case of temporary failures until it is successfully completed.\nHowever, upload requests will now succeed without the document actually being ready to be searched, which may be perceived as a kind of (temporary) inconsistency.\nAnd another problem: this still requires the message-queue to be available at upload-time and may suffer the same inconsistency issues as described above, since sending a message to the queue may also succeed or fail independently of the other storage requests.\nKeeping resources in sync One way to avoid having only some of the requests succeed is to let all resources participate in the same global, distributed transaction, using the 2-phase-commit protocol.\nWhile this is a common approach, it may not be supported by all resources, and it carries some complexity as it may entail manual recovery procedures (such as \u0026ldquo;system manager intervention\u0026rdquo; in case of deviating heuristic decisions after communication breakdowns).\nAnother way to avoid dual-write inconsistencies without resorting to 2-phase-commit is to persist the requirement of updating other resources as part of a local transaction, e.g. by using the transactional-outbox pattern.\nIn the following design, the indexing requirement is saved as part of the metadata storage transaction into an outbox table, which is monitored by a message relay component then creating messages for later processing to update the search-index:\nThis way, it is ensured that indexing messages are only created in case the transaction spanning the outbox-table-insert successfully committed.\nGiven a relay component that can asynchonously monitor the outbox table, there is also no need for the relay component or the message-queue to be available at upload-time to let a document upload request succeed.\nNevertheless, one dual-write remains in the system: during the initial processing of the upload request, the document is first stored in the object-storage, and the metadata is then stored together with the indexing request inside the database. In case the object-storage successfully completes the request but the database insertions fail, an orphan document will remain in the object-storage. This problem still needs to be mitigated, e.g. by periodically checking the object-storage for orphan documents which have no persisted metadata.\nAnother thing which needs to be taken into account is the possibility of failures during the processing of outbox entries and messages, since:\nthe relay component needs both to successfully create a message and to acknowledge the processing of the outbox entry the message both needs to be processed successfully and the successfull processing needs to be acknowledged Depending on whether the acknowledgements are done after or before the processing, this results in at-least-once or at-most-once processing.\nChoosing at-least-once to make sure that no documents remain non-indexed, repeated processing of indexing messages can occur. In our case, this should not be a problem since the processing may be made idempotent by first querying the index to check for already indexed documents, or the indexing could just be executed again since it can also be considered idempotent already.\nCDC with Debezium and the transactional-outbox pattern To implement the message relay component, microservices.io lists two options: polling the outbox table for events to be published as well as tailing the transaction log. The latter option is described as \u0026ldquo;relatively obscure although becoming increasingly common\u0026rdquo;, which is where Debezium comes into play, allowing for a convenient setup of the log-tailing approach.\nDebezium is a platform for change data capture, which is able to reliably capture data changes from a variety of sources (such as popular relational databases), and to emit these changes as an event stream via a variety of messaging infrastructures.\nIn our sample app, we use PostgreSQL for saving metadata on uploaded documents (and for the outbox table), Minio, an S3-compatible object-storage for the documents themselves, and OpenSearch for indexing and searching (an open-source fork of Elasticsearch). Redpanda is used as an Apache Kafka-like message broker, and Quarkus for implementing the backend of the user-facing application.\nAll required components can be setup locally using docker and docker-compose. Just clone the repository from Github and run the following commands from within the directory:\n# start needed services: # (postgres, minio, opensearch, kafka, debezium) docker-compose up # run the app, listening at http://localhost:8085 # (this will first build the app in a separate container) docker-compose -f docker-compose.app.yml To point it to a running Kafka instance, the Debezium Docker container is supplied an environment variable:\ndebezium: image: debezium/connect depends_on: - kafka environment: BOOTSTRAP_SERVERS: \u0026#34;kafka:9092\u0026#34; And for setting up Debezium to tail the transaction log of a specific table in a Postgres database, one request is needed:\ncurl --request POST \\ --url http://localhost:8083/connectors \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --data \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;upload-service-outbox-connector\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;connector.class\u0026#34;: \u0026#34;io.debezium.connector.postgresql.PostgresConnector\u0026#34;, \u0026#34;plugin.name\u0026#34;: \u0026#34;pgoutput\u0026#34;, \u0026#34;database.hostname\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;database.port\u0026#34;: \u0026#34;5432\u0026#34;, \u0026#34;database.user\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;database.password\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;database.dbname\u0026#34; : \u0026#34;postgres\u0026#34;, \u0026#34;table.include.list\u0026#34;: \u0026#34;public.outboxevent\u0026#34;, \u0026#34;topic.prefix\u0026#34;: \u0026#34;upload-service-outbox\u0026#34;, \u0026#34;transforms\u0026#34;: \u0026#34;outbox\u0026#34;, \u0026#34;transforms.outbox.type\u0026#34;: \u0026#34;io.debezium.transforms.outbox.EventRouter\u0026#34;, \u0026#34;topic.creation.default.partitions\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;topic.creation.default.replication.factor\u0026#34;: \u0026#34;1\u0026#34; } }\u0026#39; Publishing and consuming messages with Quarkus For simple setup during development, the request shown above may also be issued automatically during Quarkus startup, e.g. using a microprofile RestClient:\n@IfBuildProfile(\u0026#34;dev\u0026#34;) @ApplicationScoped public class SetupDebeziumOnStartup { @Inject @RestClient DebeziumSetupService service; public void onStart(@Observes StartupEvent ev) throws Exception { try { service.setupConnector(getBody()); } catch (ConflictException e) { // ok, already setup } } @IfBuildProfile(\u0026#34;dev\u0026#34;) @ApplicationScoped @RegisterRestClient(baseUri = \u0026#34;http://debezium:8083\u0026#34;) // configurable @RegisterProvider(ConflictDetectingResponseMapper.class) public static interface DebeziumSetupService { @POST @Path(\u0026#34;/connectors\u0026#34;) @Consumes(MediaType.APPLICATION_JSON) void setupConnector(JsonObject body); } } Having this configuration in place, the Quarkus app can then start to write to the outbox table, which can be further simplified by including the corresponding Quarkus extension as a Gradle dependency:\nimplementation \u0026#39;io.debezium:debezium-quarkus-outbox\u0026#39; This allows to write to the outbox table by simply firing a sub-classed ExportedEvent:\n@Inject Event\u0026lt;IndexingRequiredEvent\u0026gt; outbox; @Transactional(value = TxType.MANDATORY) public void indexAsync(DocEntity doc) { IndexingRequiredEvent event = new IndexingRequiredEvent(doc.getFilename(), doc.getFilename(), Instant.now()); outbox.fire(event); } If configured, the Quarkus extension will also take care of immediately deleting entries from the outbox table to prevent it from growing over time.\nDebezium will then start to capture the data changes and publish corresponding messages to the configured Kafka topic.\nReading messages from a Kafka topic with Quarkus is also straightforward as described in the corresponding guide, using Smallrye Reactive Messaging:\n@Incoming(\u0026#34;indexing-events\u0026#34;) // configured to map to a specific Kafka topic @Blocking(ordered = false) // messages only affect distinct documents, so ordering is expendable public void receive(String message) { String payload = getPayload(message); indexingProcessor.processIndexingRequest(payload); } The message processing should be extended by automatically retrying message processing in case of transient failures (e.g. caused by unavailable upstream services), as well as by eventually handling persistent problems, e.g. in a way described in this article (my personal favorite being the Robinhood approach which allows for the simple implementation of a dedicated UI for flexibly triggering a reprocessing of messages e.g. after bugfixes have been deployed).\nWhen processing an indexing request message, the document to be indexed is first downloaded from the Minio object-storage using the Quarkus Minio extension which provides convenient access to the Minio Java API.\nSubsequently, an indexing request is send to OpenSearch using the low-level RestClient. To be able to index PDF-documents, a special ingest-plugin for attachment processing needs to be installed:\n# custom OpenSearch Dockerfile to install the ingest-attachment plugin FROM opensearchproject/opensearch:2 RUN /usr/share/opensearch/bin/opensearch-plugin install --batch ingest-attachment Further OpenSearch configuration is automatically done on app startup via the RestClient.\nResult The following screenshots show how uploading and searching documents looks like and how the data processing proceeds:\nPDFs can be uploaded by dropping them onto the page:\nFiles are uploaded to Minio, as shown by the built-in UI:\nUpload-requests complete successfully, however no documents have been indexed yet:\nMetadata was saved to Postgres, together with the outbox table entries (automatic deletion disabled):\nDebezium captures the inserts and creates corresponding Kafka messages, which can be inspected e.g. using the Redpanda Console:\nThe app then processes the messages and indexes the documents, which can then be queried. Results also include highlights showing the context in which search terms occured, and the document can be viewed:\nThere should have been a video here but your browser does not seem to support it. Obviously, the presented example system is overengineered. Just using PostgreSQL for storing the documents as well as using it\u0026rsquo;s built-in full-text search capabilities would probably have resulted in a sufficient user-experience without ever having to worry about more than one single, local, ACID transaction.\nNevertheless, the example could still be extended in numerous ways, e.g. by adding dead-letter handling, taking full advantage of OpenSearch\u0026rsquo;s various search options, or properly splitting the uploading-related and the indexing-related code into two separate services, which would further decrease the coupling at the code-level and could increase the maintainability. Another interesting extension could include a user notification right after the indexing of an uploaded completed, implemented e.g. by publishing corresponding events and subscribing a dedicated backend service which could then ping the user e.g. via a server-sent event.\n","permalink":"https://fladdimir.github.io/post/document-search/","summary":"Debezium, Quarkus, Kafka - the Transactional Outbox pattern in action","title":"Availability and Consistency of an App with Multiple Datasources"},{"content":" Update: as of 11/2022 Heroku suspended their free tier offer\nmorling.dev describes render to come close to the Heroku offer, with Postgres databases expiring 90 days after creation\nWhether its about trying out a new framework or sketching your next big startup idea - its always great to get the code running somewhere. And its even better if you can be sure that you will never be forced to pay anything at all.\nMany platforms offer a free-tier for freely using some of their services, sometimes just for a limited period of time, and/or only after presenting a valid credit-card. Furthermore, especially services based on vendor-specific technologies tend to be offered freely.\nAWS for example offers one free EC2 compute instance as well as a relational database instance for the first 12 months after the registration. In the \u0026ldquo;free-forever\u0026rdquo; offer are vendor-specific technologies such as Lambda-invocations and DynamoDB-storage.\nWhile this obviously makes sense from a marketing perspective, it is not great to get locked into vendor-specific technologies, or to risk financial loss just because of configuration mistakes (or because of security breaches).\nThis post describes a couple of tools, technologies and services which may be used for developing and operating a full-stack web-application, without the need to show a credit-card anywhere, as of 02/2022. Vendor lock-in\u0026rsquo;s are avoided as much as possible by aiming to build on established standards.\nSample app \u0026ldquo;Collective Color Picking\u0026rdquo; is a small toy app illustrating the used technologies. It allows users to pick their favorite color and share it with all other connected users in real time. A default color, which is assigned to the first connecting user after application startup, is persisted and can be changed via HTTP.\nThe app consists of a minimal browser-based frontend, a backend which holds the state (the picked colors of all connected users), and a database which stores the default color.\nGitHub repository: https://github.com/fladdimir/collective-color-picking\nSample-App on Heroku: https://collective-color-picking.herokuapp.com\n(first request may take some seconds, due to a possibly sleeping Heroku dyno)\nApplication structure The app has a standard 3 tier structure.\nClient-side: Vue.js with Typescript, using the cool radial-color-picker and a canvas to display the picked colors. Websocket connection for sending and receiving color updates.\nServer-side: Quarkus, a growingly popular Java framework with a number of cool features (e.g. dev-mode, native-image compilation), built on JEE standards like CDI, JPA, Bean Validation. Websocket support is available as well. Seamlessly usable with mapstruct, lombok, AssertJ, and others that make Java programming even more fun. PostgresQL, widespread and compatible database, locally runnable e.g. via docker.\nFor local development, the vite frontend dev-server can proxy incoming requests to a locally running backend.\nThe actual deployment uses nginx to serve the static client files and proxies /api requests to the backend.\nTests \u0026amp; CI Both Vue and Quarkus offer good test support. An especially useful feature is the option to run Quarkus API tests not only against the application running on Java but also against a native-image, which helps to discover problems like missing @RegisterForReflection annotations on DTOs.\nStatic code analysis tools like sonarqube further help to ensure code quality. Sonarqube analysis can be incorporated into the build via a gradle-plugin, and also supports visualizing the test coverage, which can be obtained by integrating the Quarkus-jacoco-extension.\nThe test and static analysis can be run e.g. on every push to or PR at a remote repository. git-services like GitHub (actions) and GitLab (pipelines) offer free build time on their runners for public projects.\nAnalysis and coverage results can then be submitted to sonarcloud, a sonarqube service which is also freely available for public projects (and offers shiny badges, too).\nHosting \u0026amp; Deployment Different to major cloud platforms, Heroku offers not only free compute instances (dynos, 512 MB RAM), but also free standard PostgresQL databases (limited rows, size, connections).\nTo be able to switch platforms without extensive configuration changes, the application is provided in form of a docker image, which is pushed to the Heroku registry. Database credentials are provided to a started container via an environment variable (which may profit from further pre-processing so that the backend can connect successfully).\nThe application docker image builds on top of the official nginx image and includes the frontend files and the backend in a single image, which can conveniently be created using a multi-stage docker build, so that no build dependencies need to be included into the final image.\nSince free RAM is limited - and to reduce wake-up time after Heroku dynos were put to sleep - compiling the application backend to a native-image can be beneficial. The native-image compilation requires a large amount of memory (~6 GB for the simple app), but luckily the free build runners of GitHub are able to cope with this.\nThe port on which the application is supposed to listen is also provided by Heroku via environment variable. To tell nginx, the config is generated at runtime from a template with help of envsubst before the start.\nOn update of a dedicated branch, a corresponding GitHub action automatically builds and deploys the image, also including a health-check request after application update.\nMonitoring: Logs \u0026amp; Metrics For observing the state of a running application, Heroku offers dedicated add-ons for collecting and analyzing logs and a standard metrics collection, which are only available after registering a credit-card.\nTo circumvent this issue, the app uses a dedicated logging and metrics collection setup. All logs \u0026amp; metrics are sent to a free-tier grafana-cloud instance.\nApplication logs are sent by nginx and the Quarkus backend via syslog to a local grafana-agent, which forwards them to the grafana-cloud loki log database. Since the grafana-agent receives syslog logs only via TCP, and nginx sends syslog logs via UDP, rsyslog is additionally used for \u0026ldquo;protocol translation\u0026rdquo;.\nApart from log-forwarding, the local grafana-agent is also a slimmed-down prometheus in agent mode, which scrapes metrics information from a specified endpoint created by the Quarkus metrics extension (/q/metrics). The scraped metrics are then forwarded to the Prometheus instance of grafana-cloud.\nBesides forwarding logs and metrics, the grafana-agent acts as an OTLP trace receiver which can forward traces created by the Quarkus OTLP extension. Grafana-cloud free-tier includes a Tempo tracing backend.\nThe grafana-cloud connection credentials are provided via environment variables.\nThe complete setup is shown below:\nThe observability backend including grafana components can be setup locally, e.g. using docker-compose, so that the complete setup can be tested locally which is especially important due to the amount of involved configuration.\n","permalink":"https://fladdimir.github.io/post/stack-2022/","summary":"A no-credit-card way of developing, deploying, and monitoring a web application","title":"Credit-Card-Free Web Application Stack for 2022"},{"content":"Back at university we had a great time playing around with miniaturized Fischertechnik conveying systems. We learned about the challenges of PLC programming and the joy of using Arduino micro-controller boards to bring conveyor belts and turntables to life. We were learning about simulation-based controls testing using Emulate3D (awesome 3D physics engine, robot emulations) and Plant Simulation (also great for testing higher-level controls).\nHowever, the restrictive licensing - USB dongles and notoriously limited pool-licenses - made it challenging to create a simple and accessible controls development workflow suitable for all project team members.\nLet\u0026rsquo;s sketch the idea of a material flow simulation environment for developing, debugging and testing C-code inside a Python-based simulation model - non-proprietary and ready to be run anywhere, e.g. as part of CI.\nPublic repo: https://github.com/fladdimir/material-flow-control-c-emulation\n1. Scenario \u0026amp; Scope The \u0026ldquo;turntable\u0026rdquo; (image below) represents a typical Fischertechnik conveying module. It consists of 2 motors and 3 sensors:\nconveyor belt (motor 1) proximity sensor or photoelectric barrier to identify whether some item is present on the module (sensor 1) turning unit for changing the belt rotation by 90 degrees (motor 2) stop position sensors for checking whether the module fully rotated (sensors 2+3, both at 0 and 90 degrees) Even though the motors typically require 24V, relays can be used to control a module with a micro-controller boards typically working at 3-5V pin voltage. Micro-controller boards such as Arduinos also offer further options for interfacing with other systems via serial communication.\nPutting together multiple turntable modules, grid-like conveying layouts can be realized.\nHowever, writing control logic for Arduino can be challenging, especially since debugging code running on a connected board is not as simple. Additionally, central material flow control software also needs to be tested in interaction with module controls.\n2. System Structure A structure for controlling the flow of goods through a grid of connected turntable modules could look like this:\nevery turntable\u0026rsquo;s sensors and actors are controlled by a micro-controller (I/O) every micro-controller has a serial connection to communicate with a central material flow control server the server logic consists of different parts dedicated to communicating with connected modules, as well as central functions e.g. for pathfinding/routing of items through the system While systems such as Flexconveyor claim to work in a decentralized way without the need for a central \u0026ldquo;routing brain\u0026rdquo;, the described structure tries to shift all functions without hard real-time requirements from the micro-controllers to a central server (which makes particular sense when running on low-budget, resource-constrained boards such as the Arduino Uno).\n3. Emulation Interfaces Within the described setup, every micro-controller interacts with its environment via sensor-reads, actor-writes, and byte-wise serial-reads/writes. To be able to run the control logic on a development computer, the actual hardware-dependent read/write calls need to be replaced by interactions with simulated counterparts.\nOne way of achieving that using a Python-based emulation environment and exploiting the simple interfacing with C code could look like this:\nmodule control C code is called from a Python runtime with help of a generated CFFI wrapper device-dependent interaction methods are setup to call corresponding Python functions providing simulated inputs/outputs sensor-reads \u0026amp; actor-writes are run against a shared memory, which is also read/written by a simulation of the physical modules serial reads \u0026amp; writes are going to a pipe, which represents a connection to the server-side module agent a dedicated sub-process is created for every module control so that no global C variables are shared between different module controls CFFI allows for the simple creation of functions which are declared in C and called from Python, as well as the other way around. When generating the CFFI wrapper code, C header files can be used to prepare C functions to be called from Python. To be able to implement forward-declared C functions in Python, the follwing definition can be set:\nextern \u0026#34;Python+C\u0026#34; bool _light_barrier(); // provide info whether sensor is triggered This way, an implementing Python function can then be wired:\n@ffi.def_extern() def _light_barrier() -\u0026gt; bool: return shared_array[LIGHT_BARRIER_IDX] # simulated value from memory instead of actual sensor 4. 2D-Simulation To be able to emulate physical interactions of the module control code, real system components need to be simulated. While there are Python wrappers for awesome (3D) physics engines such as chrono, this implementation just uses a minimal 2D engine with very limited physics.\nSupported features include:\nnested element structures in 2D cheap collision//overlap detection for certain combinations of simple geometries (rectangles, straights, points) relative transition and rotation movements of elements and child-elements movement limits (e.g. to realize max. 90 degrees of rotation for turntables) While an elements global position is determined by its local position relative to the parent-element it is attached to, the global position is cached to avoid recalculation for nested objects in case no position changes occured for any parent element.\nThe collision detection uses a simple 2-phase check, first checking cheap circumcycles to identify potentially colliding objects before performing a more expensive cohen-sutherland evaluation. Collisions are used in the simulation e.g. to identify when a box is hitting a light barrier, or which conveyor belt movements are changing a box\u0026rsquo;s position.\n5. Putting it all together The screencast shows an animation of a small sample test scenario consisting of several modules forwarding one box towards randomly chosen target modules (indicated by \u0026lsquo;X\u0026rsquo;):\nThe visualization is created with help of the Arcade game engine, which allows to simply step forward the simulation inside the game loop and animate the current state. In addition to the advent of the simulated time, the (C-coded) control loop of each module is invoked sequentially to allow a reaction to potential sensor state changes.\nOn the server-side of the control hierarchy, the forwarding/receiving of boxes between modules and the awaiting of modules to reach readiness is realized using asyncio coroutines.\nThe determination of which modules to visit in order to reach a distant target module is done with help of networkx and a corresponding graph constructed from the module locations.\nThe cool thing about all this: we can debug every single layer of the control code at any point in time!\nIn addition to normal Python debugging (part of the VS Code Python extension) of the server-side control code, we can attach a C (gcc) debugger to any of the module sub-processes running the C code.\nThis also works great from within VS Code, where we can even run different debugging sessions at the same time.\nBeing able to \u0026ldquo;look inside\u0026rdquo; the current state of a C module control makes it amazingly easy to discover bugs, such as the bad evaluation of commands received via serial communication, confirmation serial writes at bad times, plain wrong if-conditions, misplaced early returns etc..\nAs animation is fully optional, running a \u0026ldquo;headless\u0026rdquo; simulation can be easily used for validating checked-in control code agains a set of defined test scenarios / module layouts e.g. as part of a CI pipeline.\nLimits and Shortcomings Despite the good level of support for development and debugging, there are serious shortcomings of the presented approach, so that there still remains the need for properly testing the complete physical system:\nC code is run on a normal PC instead of a resource-constrained micro-controller, so e.g. memory usage should be carefully checked the defined \u0026ldquo;hardware abstraction layer\u0026rdquo; hides the complexity of actual communication hardware and technologies (pins/bus systems/rxtx/i2c/\u0026hellip;) all control code is invoked sequentially and the simulation waits for all control loops to finish before the next time step, so real-time requirements should be checked with special care on the target hardware ","permalink":"https://fladdimir.github.io/post/material-flow-control-emulation/","summary":"Running C code as part of a Python simulation using CFFI","title":"Python-based Emulation for Developing Material Flow Controls in C"},{"content":"Getting up late every morning, efficient processes are crucial. Luckily, there are tools which enable the lazy late riser to get some structure into the start of the day. The diagram below shows a BPMN-definition of what needs to be achieved in which order on a typical morning.\nThe workflow engine Camunda can turn the corresponding BPMN file into an executable process, made of a series of completable user-tasks. Vaadin and SpringBoot enable the fast creation of a simple web-ui, showing the tasks which need to be completed next, combined with a progress-bar:\nParallel tasks can be completed in any order, and the current progress as well as the complete history with start times and task durations are saved to a Postgres database for further analysis.\nStart the morning with a clear plan: https://github.com/fladdimir/camunda-task-list\n","permalink":"https://fladdimir.github.io/post/camunda-task-list/","summary":"Getting up late every morning, efficient processes are crucial. Luckily, there are tools which enable the lazy late riser to get some structure into the start of the day. The diagram below shows a BPMN-definition of what needs to be achieved in which order on a typical morning.\nThe workflow engine Camunda can turn the corresponding BPMN file into an executable process, made of a series of completable user-tasks. Vaadin and SpringBoot enable the fast creation of a simple web-ui, showing the tasks which need to be completed next, combined with a progress-bar:","title":"Camunda Morning Task-List"},{"content":"Wouldn\u0026rsquo;t it be cool to be able to share your location with friends, but without relying on established service providers, which most probably already know way more about you than they should?\nThis post will look at a small web-app implementing essential basics of that functionality, using React and Leaflet at the frontend, Micronaut at the backend, Okta as identity provider, and Heroku for free hosting.\nGet the repo: https://github.com/fladdimir/locsharex.\nTL;DR - just show me the app!\n(first request may take some seconds, due to a possibly sleeping Heroku dyno)\nUpdate: as of 11/2022 Heroku suspended their free tier offer\nFeatures and UI Login screen To get a first impression without sign-up, 3 pre-defined test-users allow you to quickly see the app in action. Just click to login and play around.\nOkta-Login To create your own user, sign-in via Okta, a free Open-ID-Connect identity provider.\n(Well, free for any app as long as there are no more than 15k monthly users.)\nThe Map Main screen of the app, where you can see your and your friends\u0026rsquo; locations.\nEdit your location by dragging the marker onto the map, stop sharing your position, or rely on your browser/device location (consent needed). Filter for username in case of searching for someone specific.\nSettings The contact-administration page, with lots of space for more friends ;)\nLook for not-yet-connected people by username, change the name by which people may find you. Sign-out to try another test-user or check back later.\nTechnologies Frontend Single-page react-app, created with create-react-app and Material-UI. Open-street-maps integration with help of leaflet and react-leaflet for simple usage within react components with great typescript support. VSCode.\nWorth mentioning might be the awesome create-react-app tooling, including a proxy-mode for forwarding of /api requests to another locally running server (no cors hustle), and the HTTPS support required for using the geo-location browser api.\nBackend Micronaut, a popular JVM-based microservice framework, aiming for lower memory footprints and faster start-up times than Spring-Boot, and (at least currently) still with better support for creating native images with GraalVM (for further start-up time reduction). Thanks to the java-extension, VSCode also provides great support for backend development.\nConvenient entity persistence with Data Repositories and Hibernate. Below is a simple entity-relationship-model for the app, showing the AppUser with it\u0026rsquo;s app-internal ID, name, (embedded) position, and associated users (m-n self-reference):\nIn addition to the REST-API, Micronaut also provides the possibility to serve static files.\nIdentity Provider Micronaut Security offers a variety of options for securing an app, including support for OpenID Connect-based authentication flows. To link persisted user-entities with actual users authenticating via OIDC, the entity also contains information on the identity provider and the sub (a user ID from the identity provider). That information is only used once during login to identify the logged-in user before issuing a new JWT. No info from the identity-provider is given anywhere but to the database.\nMicronaut Security includes support for a couple of different OIDC providers out of the box (e.g. Auth0, AWS-Cognito, Okta, Keycloak).\nKeycloak is a popular open-source identity and access management solution, lately starting to move from Wildfly to Quarkus - Keycloak-X. Great for just spinning up a container for local development.\nAlternatively it is simple to switch to a managed IDP such as Okta.\nShown below is an overview of the application components and their interaction during OIDC login:\nThe user decides to login and issues a request to initiate the flow The response redirects to the identity provider The IDP login is loaded, where the user enters credentials Upon successful IDP login, the user is redirected to a callback-endpoint of the app (including a one-time code) The user issues the callback request (including the one-time code) The app backend makes a secure back-channel request to exchange the user-related one-time code for an ID-token (together with an app-specific, pre-configured client-secret) The IDP returns an ID-token containing user information The app backend creates a new JWT containing the app-internal user ID and returns the JWT as an http-only cookie as part of a redirecting response The browser then sends the cookie with every API request, allowing the backend to validate the JWT and the permission of the user to access requested resources During logout the user needs to clear the existing IDP session as well as the app session, which can be achieved by a series of redirects between the logout endpoints.\nSee e.g. this presentation for an in-depth explanation of OAuth 2 and OIDC.\nHeroku Heroku is a platform-as-service which offers a simple way to run an app in the cloud, including a free tier of 550 micro instance-hours per month and a postgres-database with a 10k row limit. Applications can be provided e.g. in form of jars or docker images (the latter may require custom processing of the environment variable storing the Database credentials). After 30 mins of inactivity without incoming requests, an instance is put to sleep and stops consuming instance-hours. To quickly respond to a request when waking up an instance, the usage of a native image of the app can be beneficial (reducing the app startup time from ~4.1 seconds to ~0.24s).\n","permalink":"https://fladdimir.github.io/post/location-sharing/","summary":"A simple web-app for sharing geo-locations with friends","title":"Playing around with React, Leaflet, Micronaut, Okta, \u0026 Heroku"},{"content":"When creating Python-based simulation models with Casymda /SimPy, a frequent remark is that Python - being a slow, dynamic, interpreted language - would be a bad choice for this type of endeavour.\nSo could compiled, statically-typed SimPy alternatives make model execution faster, therefore being a better choice for development?\nThis post will have a look at Uia-Sim and SimSharp, two SimPy ports for discrete event simulation in Java and C#. As a proof-of-concept, two small block-based modeling libraries were created, similar to Casymda for SimPy, and their execution speed was compared with help of a simple benchmark model.\nUia-Sim: SimPy for Java Uia-Sim is a recently published Java port of SimPy, published by UIA Java Solutions. Since Java does not provide generators/coroutines out of the box, the creator developed a \u0026ldquo;yield-like API\u0026rdquo; to enable blocking and resuming of simulation processes with help of threads.\nBased on Uia-Sim, a Casymda-like library for block-based composition of discrete event simulation models was created as a proof-of-concept. Csa4j implements some of the ideas from Casymda:\na Block as the basic class to compose simulation models is executing processing logic for received entities, and forwarding to successor-blocks can be extended for custom processing logic (e.g. elapsing time, as Delay) Source-blocks spawn entities and initiate their processing Sink-blocks end entity processing and cause removal from the simulation basic animation capabilities can visualize the entity flow between model blocks for debug / presentation As an improvement over Casymda, animation-related behavior and data was properly seperated from the simulation-related behavior of basic blocks, which just provide notifications whenever block-states change or entity movements occur.\nSimilar to Casymda\u0026rsquo;s debug animation based on Tkinter, corresponding visualizations can be created in Csa4j with JavaFX. While browser-based animation was out of scope for this PoC, the multitude of existing (micro-) web-frameworks for Java would make it easy to provide corresponding functionality. Further missing features which are present in Casymda include the parsing of .bpmn files to generate simulation model classes, the state-tracking of blocks, and tilemap-movements.\nThe project uses a basic gradle setup with Java 14 and JUnit-tests. Coverage info and static code analysis can be obtained with help of jacoco, sonarqube, and a sonarqube gradle plugin. Since Uia-Sim seems to be not yet available via maven-central, this dependency can be built locally and primarily be retrieved via a local maven repository. VSCode and its Java extension pack provide a great development experience.\nSimSharp: SimPy for .NET SimSharp is a .NET port of SimPy which is developed by the research group \u0026ldquo;Heuristic and Evolutionary Algorithms Laboratory\u0026rdquo; (HEAL) from Austria (also known for the HeuristicLab optimization framework). Similar to SimPy (and different to Uia-Sim), SimSharp is using iterators for resumable simulation-processes.\nCreated for this PoC, the Csa4cs-library provides the same features as \u0026ldquo;Csa4j\u0026rdquo; (described in the previous section), including a simple canvas animation based on skiasharp and gtksharp.\nThe project is based on the .NET 5.0 SDK, using the XUnit test framework. Similar to the Java project, coverage info and static code analysis can be obtained conveniently with sonarqube (even though the scan step requires a bit more setup effort compared with the gradle plugin usage in Java). Thanks to its C# extension, VSCode can offer great development support.\nPerformance Comparison To evaluate the execution speed of the simulation libraries, the same model was implemented using Casymda/SimPy, Csa4j/Uia-Sim, and Csa4cs/SimSharp. Additionally, the SimPy-model was executed using CPython and PyPy. Identical assertions on the results of the simulations verify the correctness of the model implementations.\nThe benchmark model is made of typically used, basic processing blocks and is shown below.\nOne source produces entities with a given inter-arrival-time and forwards them to a gateway, which alternatingly chooses either a delay-block with infinite capacity (parallel processing), or a buffer which is placed before a delay-block with capacity 1 (sequential processing). A second gateway joins both entity flows.\nDepending on the inter-arrival-time, 2 main scenarios can be simulated:\ninter-arrival-time \u0026gt; processing time not causing any queues or actually parallel processing, representing a plain processing of entities with a short event queue inter-arrival-time \u0026lt; processing time leading to a queue before the sequential processing (up to n/2 entities waiting), and a simultaneous processing of the other n/2 entities Different experiments simulate the processing of 10 to 200_000 entities and were carried out on an Ubuntu notebook with i5 processor.\nThe diagram below shows the execution time of the simulation runs for the first scenario where no queing occurs, depending on the number of created entities:\nAs we can see - and as one might expect - the execution time linearly grows with the number of processed entities on all platforms. Interestingly, the Java model (red) is considerably slower than the Python and the C# versions, so that the longer experiments were omitted. This performance drawback could be explained by fact that one os-thread is created per entity-process, combined with a high computational overhead of threads compared to generator/iterable-based coroutine-objects. Even for short runs, the PyPy JIT compiler (orange) can reach an impressive speed-up compared to CPython (blue). The .NET model outperforms even PyPy by a factor of ~5.\nThe second chart shows the queuing scenario, with up to one half of the entities waiting for a shared resource, and the other half being simultaneously processed:\nAs before, the longer runs of the Java model were omitted due to their duration. While CPython and .NET show an again seemingly linear growth, the exponential development of the PyPy execution time reveals a rather surprising slow-down in the long run compared to CPython.\nSummary Static typing alone does (surprisingly) not guarantee any execution speed advantage. SimSharp did prove to work great and might definitely be worth further evaluation. The Java-based library should probably not be used when creating many simulated processes (e.g. one process per entity, with many rather short-lived entities as in the sample model). PyPy can provide significant speed-ups over CPython, closing the gap between Python and C# - however, that depends. The shown figures were created from a first, tentative, prelimenary comparison, delivering results which are not even fully comparable (especially due to the omitted features in the Java and C# libraries). Apart from execution speed, the eco-system remains as a strong plus for creating discrete event simulation models with Python.\n","permalink":"https://fladdimir.github.io/post/csa4j+cs/","summary":"Performance Comparison of Casymda-Ports for Uia-Sim and SimSharp","title":"Block-based Modeling with SimPy - in Java \u0026 C#"},{"content":"In his highly interesting, recently published PhD thesis (German), Toni Donhauser from the University Erlangen-NÃ¼rnberg gives an excellent example on how a production-synchronous digital twin can be used for automated, simulation-based order scheduling in masonry plants.\nAs a core feature, the developed simulation allows to initialize the work-in-process of the manufacturing system to precisely mirror the current state and create accurate short-term forecasts, which serve as a basis for comparing alternatives and optimizing production plans in case of unexpected disruptions. Tecnomatix Plant Simulation (Siemens) is used for the implementation of the simulation model. Manufacturing data is fetched via the built-in OPC-UA interface from an OPC server and via ODBC from an MS Access database. Simulation runs can be triggered manually by an operator using a management application written in C#.\nSince Plant Simulation is known for extensive features as well as for extensive licensing fees, this blog post will present an alternative implementation of such a production-synchronous digital twin, based on open-source frameworks and building on easy-to-operate, pay-per-use AWS infrastructure.\nThe complete setup can be deployed and tested locally using Docker, LocalStack and Terraform (no AWS account required).\nGet the repo from github: https://github.com/fladdimir/csa-simulation-based-sc-forecast\nSlides: https://fladdimir.github.io/presentations/des-on-aws.html\nPaper on researchgate\nScenario \u0026amp; Scope The chart below shows a fictive and simplified order manufacturing process, serving as a minimal example to illustrate how a digital twin of the system can be implemented.\nAfter being created, orders are received and accepted by the company (\u0026ldquo;ingest\u0026rdquo;-step), and the order-specific raw material is ordered (\u0026ldquo;order_material\u0026rdquo;), leaving the order waiting until the corresponding material arrives (\u0026ldquo;wait_for_material\u0026rdquo;). When the material is delivered, the order proceeds to a queue (\u0026ldquo;wait_for_sop\u0026rdquo;), waiting to be processed in a capacity-constrained \u0026ldquo;production\u0026rdquo;-step, which is only able to process one order at a time. Eventually, the finished order gets delivered to the customer and leaves the system.\nWhenever material for an order is requested, an initial estimated time of arrival (ETA) is assigned. However, unexpected supplier-specific process deviations or other delivery problems may introduce delays at any point in time, so that ETA-updates are possible during this step. Since the production step uses a capacity-constrained resource and represents a possible bottleneck of the system, any unplanned under-utilization here may delay every upcoming order and diminish the system throughput (depending on how tight the schedule looks like). Therefore, it is desirable to be able to quantify the effects of any shift in time as soon as an ETA-update for an order occurs.\nSynchronized Digital Twin: Concept and Implementation The next figure shows a simple event-processing pipeline, able to ingest defined events and to persist the system state (event tracking), which in turn enables the simulation-based creation of forecasts for expected order completions times and delays (event analytics). A simple web-dashboard will be used to visualize the results.\n1. Publishing events of data producers During the processing of an order in the physical system, data producers such as sensors and IoT-devices are capturing information on the progress, i.e. events of state-changes as e.g. start or finish of the production step of an order. These order updates are published to a defined endpoint where they are collected and processed (2.). While those events would actually be happening in the physical manufacturing system, a simulation model might be used to create test-data for the digital twin (see the post on Virtual Commissioning for another example of this use-case for simulation).\n2. Capturing events with AWS Kinesis Kinesis is an AWS service for continuous buffering and real-time processing of streaming data. A Kinesis stream decouples data producers and consumers and consists of a configurable number of shards, each of which is able to ingest up to 1 MB or 1000 records of data per second. Each record is put into one shard based on it\u0026rsquo;s specified partition key value, which gets important since in-order processing of records is guaranteed only on partition key level.\nIn the described scenario in-order processing becomes critical for ETA-updates of orders, since the message of an expected delay must not be processed before an earlier submitted update.\nNew records can be put to the stream e.g. using the AWS SDK, which is available for various languages, including Python which is used for the emulated test client.\n3. Processing events with AWS Lambda Lambda is the function-as-a-service offer of AWS, which allows to run code on-demand, paying for the number of invocations as well as for execution time. Lambda functions can easily be integrated with other services such as SQS and DynamoDB. Since AWS provisions the function runtime on-demand, the short cold-start times of NodeJS and Python make them a popular choice for implementing lambdas, while \u0026ldquo;heavier\u0026rdquo; alternatives such as Java are less common (the JVM would need multiple invocations for the JIT-compilation to boost performance).\nThe lambda implemented for processing order updates is simple and just updates the corresponding item of the affected order in a specified DynamoDB table with data from the event provided as part of the invocation.\n4. Persisting the system state with DynamoDB DynamoDB is used as a fast, flexible and managed NoSQL database. While this type of database by design lacks some of the amenities of relational databases (such as proper means to enforce referential integrity on the database level, or the availability of sophisticated ORMs and schema management tools), it is fine for our simple use-case which just involves updating single items and basic queries. DynamoDB requires a hashkey and optionally a partition key, both of which are used in combination to uniquely identify a stored item. For orders the string id can be used as the hashkey. A nice feature of DynamoDB is the option to enable streams, automatically providing information on table-updates. This way, order ETA-updates can trigger new forecasts.\n5. Simulating the future AWS allows to use Lambda functions as DynamoDB stream event consumers, so that simulation runs can forecast future order completion times on every state change.\nFor each run, the complete system state is fetched from the DynamoDB (which might actually need multiple requests, since a single scan might only return a page of up to 1 MB of data).\nBased on the registered process timestamps, the currently relevant process step of each order can be identified.\nThe simulation model is generated from the process diagram shown above using Casymda. For the sake of simplicity of this proof of concept, processing times are assumed to be deterministic (even though stochastic behavior could be easily modeled, it would require averaging multiple runs). Model blocks are implemented to account for already elapsed processing time of work-in-process-entities at the start of the simulation (one of the possibilities to initialize online simulation models discussed in the often-cited paper of Hanisch and Tolujew, 2005, further explored by Hotz, 2007). During the execution, forecast metrics are collected in form of predicted process step completion times. Currently, AWS allows Lambda function executions to take up to 15 minutes, so that even complex models can be run this way. However, frequent and long running calculations might make it more attractive to create a dedicated service.\n6. + 7. Forecast persistence and visualization At the end of each run, the gathered results are persisted in a second DynamoDB table, from where a dashboard application can access and visualize the data.\nPlotly Dash is a popular framework for analytics web-apps. It enables the quick creation of dynamic dashboards just by writing Python code. Under the hood, it uses flask to serve React websites with plotly charts to a browser. Data queries and analysis are done on the backend using Python. The implemented dashboard just contains a simple gantt-chart (and serves only as a very basic example, leaving lots of room for extension). Automatic dashboard refreshes are implemented using an interval-callback to cyclically poll the database for updates.\nA dashboard\u0026rsquo;s Docker container could be run on AWS (e.g. ECS/Fargate, but since the free version of LocalStack does not include this it will just be run locally for demonstration).\nResult To run the setup locally from within the cloned repository, Docker and Terraform need to be installed.\nEven though the performance is not comparable to the actual cloud service, LocalStack is an awesome option to serve a multitude of AWS services locally, including Kinesis, Lambda, and DynamoDB. LocalStack can be started in a privileged Docker container, spawning more containers as needed, e.g. for executing Lambdas. It can be started via:\ndocker-compose up localstack Before the Lambda functions can be deployed, the function code and its dependencies need to be packaged:\ndocker-compose up package-ingest-lambda package-simulation-lambda Terraform is a great and widespread tool which can automatically provision infrastructure resources described in configuration files (however, have a look at this article for a more nuanced analysis). To create all required resources, two terraform commands are needed:\ncd terraform terraform init # required once terraform apply # enter \u0026#39;yes\u0026#39; when prompted to confirm the changes (or use -auto-approve) cd ../ # return to project root (To prevent 404 errors when calling apply after a restart of LocalStack without calling terraform destroy, first delete the terraform.tfstate files next to main.tf.)\nAfter the successfull creation, two more containers can be started - one serving the dashboard and one running a simulation model to emulate real event producers:\ndocker-compose up dashboard emulation Before (re-)starting any test-run, the DynamoDB-tables need to be cleared:\ndocker-compose up truncate-tables http://localhost:8050 should now show the empty dashboard, while http://localhost:5001 should show the generic Casymda web canvas animation controls. To enable automatic refreshes use the switch above the chart on the dashboard.\nWhen starting the emulation, orders will be created at the source and flow through the defined process.\nAt the same time, the dashboard should update with a minor delay and visualize the completion times of the relevant process steps of all orders which are currently present in the system. A vertical line in the chart indicates the point in time when the simulation run started and the forecast was created.\nSample flow 1. The first order is created The simulation forecasts process step completion times as defined in the model: 2. The second order arrives and Order-1 production starts The forecast does not show problems: 3. After some time, an ETA update for the Order-2 material delivery is communicated, and a delay of 1/3 is now expected The forecast shows the announced delay (orange) and the expected shift of the production step of Order-2: 4. Order-1 is finished (and therefore excluded from the forecast), but now Order-3 arrives The forecast reveals an upcoming problem! Caused by the capacity constraint of the production step (max. one order concurrently), the delay of Order-2 (orange) will also prevent to start the of production of Order-3 on time, even though the material is expected to be ready by then (red): 5. When Order-2 is almost finished, a 4th order comes in As the forecast shows, the delay of Order-2 will cascade and also affect Order-4: Complete screen-cast:\nThere should have been a video here but your browser does not seem to support it. While this was just a proof of concept and the presented example would have been easy to calculate by hand, there are plenty of improvements and extensions imaginable.\nLooking at the scenario and business use-case, it would be interesting to add more complexity to the process, such as inventory for raw materials, and different replenishment strategies. Similarly, the impacts of stochastic or planned machine maintenance intervals might be evaluated. Another extension would be to incorporate targets into the process, such as order-specific due dates or throughput goals. This might then ask for additional optimization procedures to determine optimal production control policies (similar to the case presented in the thesis mentioned in the beginning of this article).\nInteresting technical extensions include security aspects such as authentication and authorization of different data producing parties, as well as an integration of the IoT-related services of AWS, which might offer dedicated features to gather data with sensors and edge devices for the digital twin. Concerning the analytics of ingested event data, stream processing solutions such as AWS Kinesis Data Analytics might be useful to identify relevant patterns and trigger forecast and optimization runs only in case of critical process deviations.\n","permalink":"https://fladdimir.github.io/post/csa-simulation-based-sc-forecast/","summary":"Proof of Concept using Casymda on AWS, ft. Terraform and LocalStack","title":"Real Time Simulation-based Supply Chain Analytics"},{"content":"The huge effort for lifting oneself up from the couch and moving the distance to the connected PC makes it almost unbearable to do audio volume changes when watching Netflix on the big screen (not even speaking of the pain bending the fingers to reach hotkeys).\nLuckily, there are great libraries available to alleviate this agony with just a few lines of Python.\nOn the Ubuntu laptop, pyalsaaudio gives simple control over the system\u0026rsquo;s audio level, pycaw offers the same on Windows.\nFlask exposes a corresponding command-endpoint as well as a minimal web UI.\nTouch input within the dashed area is captured and translated to mouse cursor movements using pynput, giving a simple option for start \u0026amp; pause. In case the keyboard isn\u0026rsquo;t close either, pynput also enables remote keystrokes.\nStart the ease of the pain: https://github.com/fladdimir/automatic-octo-journey\nTested on Ubuntu 20.04 / Windows 10.\n","permalink":"https://fladdimir.github.io/post/audio-remote-control/","summary":"The huge effort for lifting oneself up from the couch and moving the distance to the connected PC makes it almost unbearable to do audio volume changes when watching Netflix on the big screen (not even speaking of the pain bending the fingers to reach hotkeys).\nLuckily, there are great libraries available to alleviate this agony with just a few lines of Python.\nOn the Ubuntu laptop, pyalsaaudio gives simple control over the system\u0026rsquo;s audio level, pycaw offers the same on Windows.","title":"Minimal Web-based Remote Control with Python and HTML"},{"content":"The planning and design of logistics systems - both at supply-chain and intralogistics level - is frequently supported by simulation studies, used for comparing design alternatives, assessing their feasibility, as well as estimating KPIs like lead-time or throughput.\nWhen it comes to the realization phase of logistics systems, major challenges relate to the development of controls and operational IT systems. Given the fact that testing, integration, commissioning (and bug-fixing) of these systems tend to consume a significant chunk of the realization phase, it becomes clear that it is beneficial to test a developed system as early as possible - even before physical construction takes place.\nVirtual Commissioning describes the testing of software against the digital counterpart of a real system, making use of simulation models to emulate real-world interaction.\nThis post will show an example of how the integration of simulation-based testing into today\u0026rsquo;s agile software development processes can look like, investigating a case-study on order management \u0026amp; delivery optimization.\nGet the repo from github: https://github.com/fladdimir/csa-vcom\nSlides: https://fladdimir.github.io/presentations/des-based-integration-tests.html\nPaper on researchgate\n1. Scenario \u0026amp; Scope Remember La PÃ¢tisserie, the small French bakery in Hamburg-Altona, which was experiencing a massive shift of demand towards at-home delivery of their sweet pastries?\nHaving evaluated different options of how to scale their business-model with help of an innovative open-source approach to urban delivery network simulation, the growing network now gets harder and harder to manage, calling for an increased software-based support of the bakery\u0026rsquo;s daily logistics operations\u0026hellip;\n2. Processes \u0026amp; Requirements To be able to focus on their core-competencies (to conjure up delicious treats, instead of fighting intractably inconsistent spread-sheet data), our bakery decides to go for a web-based logistics planning application.\nThe core processes to be supported are:\nRegistration of customers, and tracking their orders Managing locations of the depots to plan the best-possible deliveries Keeping track of the trucks, delivering goods according to the planned tours The following BPMN-diagram shows the the processes and a simple token-flow animation:\nThere should have been a video here but your browser does not seem to support it. 3. Test First: Simulation Model + Build-Pipeline To make sure that all required processes are adequatly supported by the developed software, our bakery\u0026rsquo;s software development division opts for a test-driven approach, backed by a build-pipeline which automatically checks all code pushed to the repository.\nBased on the specified business process a Casymda simulation model is generated, ready to emulate the real system, with which the developed software is supposed to work. As processes and scope of the application change, the simulation model is evolved in an agile way.\nGitea and Drone form the basis of the continuous integration infrastructure. As part of a virtual commissioning step, the pipeline spins up the application in a service-container, against which the simulation model runs the test-scenario, emulating interaction and verifying the expected behavior of the software.\nThe pipeline is described by a .drone.yml file. Note that the pipeline could be improved in various ways, e.g. by properly waiting for the app (service) to become available for the simulation-step. A docker-compose.yml allows to start the gitea+drone setup locally (using a single-instance setup, which is not ideal, but sufficient for testing).\n4. Application Design \u0026amp; Implementation Our bakery\u0026rsquo;s app is dealing with management of the data of customers, orders, depots, tours, and trucks. Additionally, it is required to support planning the delivery process by calculating efficient tours and assigning them to available trucks.\nThe app adopts a basic 3-layer structure consisting of a browser-based ui, a backend containing the business logic and optimization algorithms, and a persisting database. The graphic below summarizes the setup, including the simulation model which acts as a client in the automated build pipeline:\nThe backend is implemented using Django+Django-Rest-Framework, and relying on Google-OR-Tools for optimization tasks. Tour planning is modeled as a capacitated vehicle routing problem with multiple depots. For an optimal assignment of pending tours to available trucks, OR-Tools offers a minimum-cost-flow solver which is used on a corresponding bi-partite graph.\nTo create the required distance matrices, we can utilize the Open Source Routing Machine, provided as a ready-to-use Docker image (OSRM-in-a-box). OSRM offers a convenient API which is synchronously consumed upon creation of a new customer or depot. Open-street-map data can be downloaded e.g. from https://download.geofabrik.de. The map of Hamburg has a size of ~35 MB and OSRM-preprocessing (car-profile) takes about 30 seconds (i5 dual-core notebook processor).\nSQLite provides a simple database solution, however, Django makes it easy to switch to a client/server RDBMS like Postgres or MariaDB.\nThe basic frontend is built with Angular, Material, and Leaflet.js (easy to integrate thanks to ngx-leaflet).\n5. Result The screencast below shows the workflow from a users perspective. It comprises registering a new customer, issuing an order, planning tours, assignment to a truck, and tracking deliveries as the tour proceeds:\nThere should have been a video here but your browser does not seem to support it. The shown process matches the one executed by the simulation model in the virtual commissioning pipeline build step, ensuring stable functionality for every version of the software:\nExtensive and automated integration testing with simulation models can help to enable and sustain software quality, particularly in the context of process-centric logistics applications. As we\u0026rsquo;ve seen, today\u0026rsquo;s software development tools and standards allow for an efficient integration of simulation techniques \u0026amp; virtual commissioning approaches into the development process.\n","permalink":"https://fladdimir.github.io/post/csa-vcom/","summary":"Continuous Integration and Virtual Commissioning of Logistics Software","title":"Logistics Process Models for Automated Integration Testing"},{"content":"A really nice and quite unique feature of Anylogic is the possibility to include GIS-maps into simulation models. It allows to place elements on a map and move them along existing routes, based on real spatial information. This is cool because it can be used to simulate entire supply chains, including means to provide a great, tangible visualization for complex problems.\nThis previous project used Anylogic to evaluate different designs and delivery schemes for a more sustainable urban logistics network in the city center of Grenoble in France. The data-driven simulation model allows to quickly calculate KPIs for various transshipment node locations and different types of transport equipment in a multi-tier supply-chain network.\nFollowing the success of the feature, Anylogic even built anyLogistix, combining pre-built \u0026amp; customizable simulation models with a commercial solver for integrated supply chain planning \u0026amp; optimization.\nObviously, those commercial features come at a price, so let\u0026rsquo;s see whether this kind of model can also be realized with different means.\nThe simulation model of this post will be based on a mini-case-study.\nGet the repo from github.\nScenario \u0026amp; Scope Facing the fact that humanity gets more and more used to home-delivery of even everyday necessities, the small French bakery Die Patisserie in Hamburg-Altona wants to deliver sweet pastries to nearby customers.\n3 major purchasers were identified: the lost-and-found office Zentrales FundbÃ¼ro, Monkeys Music Club, and the publishing house Carlsen Verlag.\nCoordinates of the different locations:\nNode Name Lat Lon 1. PAT Die Patisserie 53.55668 9.92815 2. ZFB Zentrales FundbÃ¼ro (lost-and-found office) 53.55817 9.92829 3. MMC Monkeys Music Club 53.55706 9.93161 4. CAV Carlsen Verlag (publishing house) 53.55703 9.92684 For the sake of simplicity, the order in which nodes are visited is assumed to be fixed. The tour starts \u0026amp; ends at the patisserie:\nSimulation Model The simulation model for the simplistic scenario is created with:\nOSMnx/networkx for retrieving geo-information and calculating shortest-paths SimPy/Casymda for simulating the tour Leaflet.js for browser-based animation 1. OSMnx The awesome OSMnx package provides the possibility to obtain a networkx-graph representation of a street-network from OpenStreetMap with a single line of code. A relevant section for our scenario can be obtained by specifying center and distance for osm-nodes to be included:\nCENTER = (53.55668, 9.92815) DISTANCE = 300 G = ox.graph_from_point(CENTER, distance=DISTANCE, network_type=\u0026#39;drive\u0026#39;) OSMnx lets us pick the nearest osm-node for each of the 4 locations of the tour, and also offers convenient means to plot the network. Blue dots represent osm-nodes, connected by edges. The 4 relevant locations are shown in red:\nTo prepare all information needed by the simulation model, now all shortest paths between the 4 relevant nodes in the network are computed with networkx, and detailed information on all piece-wise linear segments for each route is included. The results are pickled and saved to disk to avoid fetching and recalculation for each run of the model (of course its kind to keep the load for the OSM-server as low as possible).\nThe above described approach could be improved, e.g. by automatically determining the area to be loaded from the given relevant locations. Instead of just picking the closest osm-node for each relevant location, it would also be more precise to first go for the closest edge in the network. And as the network size grows, it might be a better idea to directly query the shortest path between relevant nodes from the OSM-server, instead of fetching the network as a whole (the way Anylogic seems to do it).\n2. Casymda/SimPy Casymda provides block-based modeling of discrete-event-simulation models on top of SimPy.\nOur model can be characterized by a simple process:\nA truck is created at a parameterized Source and then processed at a custom DriveTour-block, which contains the logic for elapsing time according to the length of a route and the movement speed of the truck. It also contains the option to calculate intermediate locations for animation. The nodes to be visited are specified via the text-annotation stops=[\u0026quot;ZFB\u0026quot;, \u0026quot;MMC\u0026quot;, \u0026quot;CAV\u0026quot;].\nThe animation is implemented by exposing information and resources via flask (similar to the tilemap-animation described in the previous post).\n3. Leaflet.js To visualize the location of nodes and entities on a map, Leaflet only requires a few lines. For setting the rotation angle, there is the Rotated.Marker-plugin.\nmarker = L.marker(element.coords, { icon: new L.Icon({iconUrl: element.icon_path}) }).addTo(map); marker.bindPopup(element.text); marker.setRotationAngle(element.direction); Result To run the simulation via http://localhost:5000:\ndocker-compose up geo-web-animation The screencast below shows a complete tour of a truck visiting all nodes in the defined order (Patisserie - Lost-and-found - Monkey\u0026rsquo;s - Carlsen Publishing - Patisserie).\nThere should have been a video here but your browser does not seem to support it. The one-way street VÃ¶lckersstraÃe is correctly taken into account when moving from Monkeys Music Club (3., right-most node) to Carlsen Verlag (4., left-most node).\nOf course there are numerous improvements and extensions imaginable, including e.g. the calculation of more realistic driving times based on actual speed limits which are already part of the available OSM-data.\n","permalink":"https://fladdimir.github.io/post/csa-streetmap/","summary":"Building Anylogic\u0026rsquo;s GIS-Feature w/ SimPy, OSMnx and Leaflet.js","title":"Urban Logistics Network Simulation in Python"},{"content":"Reinforcement learning represents an emerging technique from machine learning. It can autonomously derive complex action sequences in dynamic environments and is successfully applied in various fields, e.g. from robotics and gaming. Instead of explicitly defining a specific solution strategy for a problem, we can just provide an environment. A self-learning agent will then autonomously discover successful strategies just by interaction.\nNeedless to say, there is nothing new under the moon and previous studies show the general feasibility of using RL for solving production-logistics problems.\nSo why do we think that there is the need for yet another article about this very topic?\nFirst, there is a lot of active development in RL, as well as in the application of Digital Twins in production/logistics. We believe that there lies even more potential in integrating these concepts. Furthermore, we found the often derogatory-treated \u0026ldquo;low-level implementation work\u0026rdquo; to be an actual obstacle for making progress in this challenging and highly inter-disciplinary area of applied research. This contribution strives to show a working example based on a tool-stack which seamlessly integrates two of the most popular open-source software packages from their respective areas: stable-baselines for RL and SimPy for implementing Digital Twins.\nGet the repo: https://github.com/fladdimir/tugger-routing\nSlides: https://fladdimir.github.io/presentations/des-python-rl.html\nPaper on researchgate\nIntroduction \u0026amp; Basics Reinforcement Learning If you still ask yourself what RL is capable of, we definitely recommend to have a look at what the guys from openai are doing.\nAdmittedly, thats probably a quite sophisticated and highly engineered example, but it breaks down to a simple interaction between an agent and an environment. Technically, this interaction is defined by an interface (or abstract base-class as Python likes to put it), which is part of the gym-package.\nThe graphic below illustrates the exchange of information between agent and environment. First, the agent calls the environment\u0026rsquo;s step method, providing the action to be executed. The environment then processes the action and returns:\nthe new state of the system (observation), the reward which occured during the step (might be zero), a done value potentially indicating the end of an episode (and the need for a subsequent reset) and an info-object (might contain additional information e.g. for logging purposes). The interface also prescribes more, such as the formats of action-space and observation_space, as well as render and reset behavior.\nThe various RL algorithms provided by the stable-baselines-package are ready to work with environments implementing this gym-interface. All that is left to do is creating a compliant environment - and in the next section we will show how this can be achieved in the domain of logistics.\nDigital Twins and Discrete Event Simulation Frankly, Digital Twin is probably the most overused buzzword of all the \u0026ldquo;Lostistics 4.0 / Industry 4.0\u0026rdquo; stuff that is out there. Even though we could not resist to put it into the title, from now on we\u0026rsquo;ll prove that we can do better and use the more specific term \u0026ldquo;Discrete Event Simulation\u0026rdquo; (DES).\nWhy DES? Discrete Event Simulation is one of the widespread tools for analysis and design of logistics systems. Today\u0026rsquo;s applications go beyond the traditional usage for systems planning. They include more operational use-cases such as virtual commissioning or short-term forecasts. Simulation models are getting integrated tightly into other IT-systems. This allows to increase process transparency and to improve our means to analyze, control, and optimize system performance in real-time. Doesn\u0026rsquo;t this sound pretty close to what Digital Twins always promise?\nMost industrial simulation uses are still based on commercial packages.\nHowever, there are a couple of open-source alternatives, which are typically closer to general-purpose language programming. Even though they tend to lack some convenient commercial features, there are upsides such as better scalability and simplified interfacing.\nRelated to Python we became aware of two popular DES packages: Salabim and SimPy. Both are not only free and open-source, but even built on top of the standard library of one of the world\u0026rsquo;s most popular programming languages - let\u0026rsquo;s see what we can get out of that!\nCasymda-Package Based on SimPy, we added bits of complementing functionality to gain some of the modeling convenience of commercial \u0026ldquo;block-based\u0026rdquo; DES-packages.\nCasymda facilitates the usage of bpmn-process-descriptions to generate corresponding simulation-model python-code. .bpmn-files (basically xml) can easily be created with the Camunda-Modeler.\nThis graphical modeling helps to maintain an overview of the high-level model-structure. Generated Casymda-models also include a generic, token-like animation of simulated processes out-of-the-box, ready to be run in a web-browser. For presentation and debugging, animations can be paused and their speed can be changed dynamically. Solely animation-related events are not scheduled if the simulation is run without visualization. This maximizes the execution speed - which becomes especially important related to RL, when a high number of runs is necessary.\nFurther features of Casymda include simulated movements along shortest paths in a 2D-tilemap-space, and gradual typing for development convenience (checkout pyright if you are using vscode).\nFor more info on Casymda have a look at the repo or the (German) website.\nWrapping a DES-Model in a Gym-Environment To be able to train an RL-agent inside a simulation model, we need to make the model implementing the Gym-interface described above.\nThe following diagram illustrates the coupling concept:\nWhen the step function of the Gym-Environment is called (1), the provided action is propagated to the relevant block of the simulation model (1.1). This is realized with help of an ActionHolder, so that a consuming piece of decision logic can dispatch according to the received information.\nSubsequently, the simulation is executed until a next_action_needed-Event is triggered by the simulation model (1.2). This is indicating the end of the current step and the need for another action of the agent.\nOne Gym-step can thus comprise an arbitrary number of discrete SimPy-steps, each of which can in turn take an arbitrary amount of simulated time.\nRewards are managed with help of a RewardHolder object, which is wired into the relevant blocks of the simulation model during environment initialization. At the end of each step, occured rewards are collected (1.3). Depending on the type of the optimization problem to solve, a post-processing of collected rewards can be applied (e.g. taking into account the amount elapsed time, so that an agent can learn time-efficient behavior).\nTo check whether an episode ended (the done part of the returned information), the current state of the model is checked against configured done_criteria (1.4). These can contain e.g. some goals to be reached or a certain amount of time to be simulated.\nTo provide the agent with an observation, a model-specific ModelStateToObservationConverter is used to collect relevant information from the model. The created observation conforms to the defined observation_space (1.5). This step could include e.g. counting the number of entities in different queues or checking inventory levels and creating a NumPy-array out of this information.\nFinally, collected information is returned to the agent (2), which can learn based on the reward and decide for the next action.\nHaving the basics covered, let\u0026rsquo;s see how we get this to work.\nCase-Study Back in August of last year at the MIM2019 in Berlin, we had the chance to attend an interesting talk of two Bavarian guys presenting their research on improving the tour-building for in-plant milk-run systems. These internal deliveries are commonly used for assembly line supply, and the tours are typically following a very rigid plan. Given the fact that the actual demand at the line tends to vary, their research revealed quite a lot of potential to decrease delivery lead times and to increase systems\u0026rsquo; utilization - just by making the tour-planning more dynamic.\nBased on this setting we constructed an abstracted and simplified version of an assembly line with a corresponding material supply system to provide a playground for reinforcement learning algorithms.\nScenario The image below shows a schematic layout plan of the system:\nUnfinished products enter the system on the upper right (I) and are assembled sequentially at 9 different stations, arranged in U-shape (I-IX). Finished products leave the system after the last assembly step (IX).\nStations require a certain amount of resource of either type A or B to be present in the station\u0026rsquo;s inventory before an assembly step can start.\nEach station can only hold one product at a time, and finished products can only be forwarded once the following station is empty (thus multiple upstream stations holding already finished products may be blocked by downstream stations which are still processing a product or waiting for material before being able to start processing).\nMaterial is supplied by a tugger, able to carry a limited discrete amount (\u0026ldquo;boxes\u0026rdquo;). The tugger can load material at a stock (A and/or B, located at the bottom). 1 discrete unit of material (\u0026ldquo;box\u0026rdquo;) can be loaded/unloaded at a time. The goal of the assembly line is achieving the maximal throughput, which also correlates with small lead-times of products.\nAssumptions:\nmaterial can only be loaded at the stocks (A and B), each of which holds an infinite amount of material, so that the tugger never waits for material at a loading site material can only be unloaded at a station actually requiring this type of material (hence a tugger cannot unload a box of A at a station which needs B for assembly) the inventory capacity at the stations (I-IX) is infinite, so that the tugger never waits at an unloading site (otherwise livelocks could occur where a tugger cannot unload material wherever it moves) System parameters Takt-time: processing time per station per product 60s Demand per product of stations type A 1.5 units Demand per product of stations type B 0.5 units Tugger movement speed 10 m/s Tugger capacity 25 units Amount of material (un-)loaded per step 5 units Time needed per (un-)loading step 5s Distances between stocks and stations (higher demands cause more frequent tours):\nRelation Simple Demand-weighted A -\u0026gt; T1 1096.40m 1644.60m B -\u0026gt; T2 926.40m 463.20m A -\u0026gt; T3 736.40m 1104.60m B -\u0026gt; T4 566.40m 283.20m A -\u0026gt; T5 234.10m 351.15m B -\u0026gt; T6 556.40m 278.20m A -\u0026gt; T7 726.40m 1089.60m B -\u0026gt; T8 916.40m 458.20m A -\u0026gt; T9 1086.40m 1629.60m The table below shows a simple throughput estimation by calculating the average cycle time of the tugger and the expected station utilization. The estimation assumes \u0026ldquo;full truck loads\u0026rdquo;, always completely loading at one stock (either A or B), and fully unloading at a station (T1 - T9).\nThroughput estimation Max throughput 24h 60/h x 24h = 1440 Demand / product 9.5 units Demand / time 9.5 / 60s = 0.16/s Average weighted distance 811.37m Average driving time 81.137s (Un-)loading time 25 units 25s Average cycle time (81.137s + 25s) x 2 = 212.274s Delivered units / cycle 25 Delivered units / time 0.12/s Average utilization 0.12/s / 0.16/s = 75% Expected throughput per min 75% x 60/min = 45/min Expected throughput per 24h ~1080/24h As we can see, the delivery performance of the tugger represents the limiting factor (bottleneck) of the system, which means that each improvement made here will be directly reflected by a corresponding increase in the overall throughput.\nFor the sake of simplicity, no stochastic model behaviour (such as e.g. randomly distributed loading or movement times) is assumed, hence the simulation model will be deterministic.\nAs stated: the system as a whole is quite abstracted and simplified - but still capturing at least some of the basic complexity inherent to real-world problems. Will our RL-agent be able to\u0026hellip;\ngrasp the underlying mechanics? distinguish different product types? discover the spots of demand and supply? deal with the limits of the tugger\u0026rsquo;s capacity? reach the maximal possible throughput? We\u0026rsquo;ll find out, but let\u0026rsquo;s first have a look at what the learning environment will look like.\nSimulation Model The simulation model of the system basically consists of 2 processes, both depicted in the graphic below.\nOn the left side, products pass through the 9 assembly steps (ProductStation, rotated U-shape) before leaving the system, occasionally being blocked by downstream stations or waiting for material at a station.\nOn the right side the tugger passes through an infinite cycle of movement and loading/unloading process steps (after initial creation at location A by a TuggerSource):\nthe next movement target is chosen and the movement is completed (no actual movement if the next target equals the current location) (TuggerMovement). Depending on the current location (being either a stock A/B) or a ProductStation, the next tugger process step is chosen: TuggerStock A loading of one unit of A (if tugger-capacity not reached) TuggerStock B loading of one unit of B (if tugger-capacity not reached) TuggerStation unloading of one unit of A or B if possible (material required by station is loaded) Note that even unsuccessful loading or unloading attempts are implemented to take a small, fixed amount of time, so that every possible Gym-step is guaranteed to take at least some simulated time (and a time-constrained episode is guaranteed to reach its end eventually).\nBelow you can see a process animation, as well as an animation of a tilemap. The agent here follows an explicitly defined simple rule of always delivering a complete load of 25 units to the station with the lowest inventory level. To run the animation just clone the repo, run the command, and visit http://localhost:5000.\nProcess animation:\ndocker-compose up web-animation-lia-process Tilemap animation:\ndocker-compose up web-animation-lia Preparing the Gym-Environment The TuggerEnv implements the Gym-Env interface and wraps the simulation model to be used for RL-agent training.\nGeneric functionalities like the mandatory step and reset functions and related helper methods are inherited and abstract/default parent-methods are overridden in a model-specific way as required (Template-Method Pattern):\ninitialize_action_and_reward_holder specifies which model blocks\u0026hellip; need access to gym-actions: TilemapMovement, choosing the next movement target based on the supplied target index number log achieved rewards: ProductSink, simply counting a reward of 1 for each finished product get_reward specifies how the elapsed time is taken into account for reward calculation check_if_model_is_done implements a model-specific check whether a certain amount of time has been simulated. One episode is scheduled to take 24h (86400s). The render method of the Gym-Env is not implemented, since animations at arbitrary moments in time - whenever a Gym-step is finished - do not make much sense for discrete event simulation environments. The animation is controlled separately.\nThe info return value of step is configured to return the number of finished_products which can then be logged.\nObservation- \u0026amp; Action-Space The model-specific extraction of the observation from the current model state is done by an instance of a TuggerEnvModelStateConverter which implements the ModelStateConverter \u0026ldquo;interface\u0026rdquo;.\nSpecifically, the observation consists of the following information which describes the current state of the system (overall 48 values):\nProductStation observations (5 values x 9 stations = 45 values): current inventory-level (normalized 0-1, counted up to a limit of 10 units) busy-state (binary) waiting_for_material-state (binary) empty-state (binary, whether a product is present or not) blocked-by-successor-state (binary) TuggerEntity observations (3 values x 1 tugger = 3 values): loaded amount of A (relative to capacity) loaded amount of B (relative to capacity) current location (index) Note that parts of a station observation can be seen to be redundant (e.g. a station which is neither busy nor waiting nor empty can only be blocked) - behind lies the rationale that an intelligent algorithm will (hopefully) learn an importance of different components of an observation, so that we do not have to worry about more than providing all potentially useful information.\nThe action_space (of type gym.spaces.Discrete) consists of the 11 possible movement targets (9 stations + 2 stocks, encoded by index).\nRewards As stated above, the defined goal of the assembly line is to achieve the best possible throughput of products, which corresponds to producing as many products as possible e.g. during one episode (24h).\nHow do we achieve that? Which kind of incentive is suitable to stimulate such a behavior? The design of appropriate reward functions is known to be a non-trivial matter. In fact, the design of rewards and incentives even for (arguably more intelligent) humans is a major problem in management and education (remember the last time you studied for passing an exam instead of actually learning useful contents).\nFor the environment at hand, we could just think about giving a single reward at the end of each episode, proportionally to the number of achieved products in that fixed amount of time (24h), which would probably properly reflect our aim of maximizing the throughput. However, the resulting reward would be quite sparse and therefore greatly decelerate learning speed (taking the average duration of a random action, each episode would take more than 1000 actions to complete before an agent sees any reward).\nAnother idea would be to reward every successful delivery of material to any station, which would be possible to be completed within 2 steps (movement to the stock \u0026amp; movement to a suitable station consuming the loaded material). This way we would get less sparse rewards, but also an obvious problem of exploitability, caused by the fact that the delivery of material to one station alone would actually never lead to the completion of any product at all.\nAs a compromise, we simply decided to go for a reward of 1 everytime a product completes its final assembly step, which is possible be completed within 12 steps (minimum, not necessarily an optimal strategy). Even exhibiting a random behavior, this would allow an agent to generate a reward of around 50 during one episode, so that there are sufficient \u0026ldquo;randomly succesful\u0026rdquo; samples to learn from.\nOne problem with this reward comes from the fact that the simulated time needed to obtain a reward is not reflected by the reward itself. Since every gym-step can actually eat up a greatly varying amount of simulation time (from 5 seconds to \u0026gt;100), there is a huge implicit impact on the throughput, which the agent is unaware of. To solve this problem we introduced \u0026ldquo;costs of time\u0026rdquo;, which means we simply give a small negative reward every step, proportional to the amount of simulated time that passed. This finally leaves us with the subsequent question of how big these \u0026ldquo;costs\u0026rdquo; should be. If set too high, they would just overrule any of the few actual rewards at the beginning of the training. If put too low, there would not be sufficient stimulus to exhibit time-efficient behavior at all. Again, as a simple compromise, we implemented the costs to grow proportionally with the highest reward seen so far at the end of an episode, which guarantees a certain balance, and rewards increasing time-efficiency.\nThe above described reward that we designed is definitely not \u0026ldquo;perfect\u0026rdquo; and also feels a bit like putting too much effort into \u0026ldquo;reward engineering\u0026rdquo; - nevertheless its a first solution our agents can hopefully work with\u0026hellip;\nRL-Agent Training \u0026amp; Evaluation The environment presented above is characterized by a Discrete action space and a continuous (Box) observations space. The stable-baselines documentation lists available RL algorithms and their compatibility.\nDue to the type of action space, some algorithms are not feasible (i.e. DDPG, SAC, and TD3).\nTo train a stable-baselines RL algorithm, the TuggerEnv is vectorized, using a DummyVecEnv and a standard MlpPolicy. To leverage multiple CPUs for training, it can be desirable to use a SubprocVecEnv (but for simpler logging \u0026amp; analysis we did not go with that one here, instead we did multiple independent training runs in parallel).\nTrain an ACER-agent (by default for 10,000 steps only, which should take \u0026lt;1min):\ndocker-compose up acer-training Plot performance (might require additional setup for connecting the display):\ndocker-compose up acer-plot-training Tilemap-animation of the trained agent (http://localhost:5000):\ndocker-compose up acer-web-animation-tilemap Below we can see an ACER-agent trained for 1m steps:\nAs we can see, the agent manages to fully load the 25 units onto the tugger most of the time, seems to target correct (A/B) stations for material unloading, and the choice of stations with a currently low inventory level seems reasonable too!\nBut how does the overall performance look like?\nPerformance Comparison For comparison we trained four algorithms (ACER, ACKTR, DQN, and PPO2) with standard settings for both 1 and 3 mio. (Gym-)steps. Training took up to 2.5 hours (DQN, 3mio. steps) on a 2.9GHz Intel i9, using a single-process DummyVecEnv as explained above.\nThe following graph shows the number of produced products per episode (24h) over the course of the training run for each algorithm, as well as the performance of the deterministic lowest-inventory heuristics (yellow line; always delivering a complete load of 25 units to the station with the currently lowest inventory), and the average performance of fully random actions (turquoise line, measured over 100 episodes).\nAs we can see, all of the algorithms manage to increase the number of produced products per episode significantly above the level reached by random actions (turquoise line at the bottom), indicating successful learning progress. Furthermore, none of the trained algorithms reaches the performance of the lowest-inventory-heuristics (yellow line at the top). The lowest-inventory-heuristics performance reaches the estimated maximum possible throughput of the system (estimated to appr. 1080/episode). This strategy can therefore be considered to be close to a global optimum. During training, a complete breakdown in performance can occur. Most prominently: ACER_3mio. (blue line, episode 260, no recovery at all). Other algorithms show drops in performance as well but seem to recover better (e.g. ACKTR - green, PPO2 - pink). The best-performing RL algorithm (ACER trained for 1mio. steps, orange line) reached a maximum throughput of 856 products / episode (78% of the near-optimal heuristics performance). The number of episodes varies due to the variable number of Gym-steps per episode (24h of simulated time), depending on the simulated time each Gym-step needs. The small number of episodes of the ACER_3mio. training is explained by the up to 17277 Gym-steps per episode, occurring from episode 260 on. Each step of such an episode takes only 5 seconds (the minimum possible time of all available Gym-steps, \u0026ldquo;achieved\u0026rdquo; by a repeated visit of the same location). This behavior might be caused by the defined negative reward per step, proportional to the amount of simulated time the step needed. Appearently, the agent does not remember how to generate a positive reward and only tries to maximize the short-term reward by minimizing the step-time. Obviously this behavior does not lead to any successful delivery, let alone completion of any product.\nIt is worth to be mentioned that all training runs were done with default algorithm settings, and that the evaluation of different hyperparameters is strongly recommended for performance optimization. Thus, it might not be improbable for an RL agent to close the performance gap towards the theoretically reachable optimum.\nSumming Up Short version: Our best RL agent reached about 78% of the best possible performance inside our production-logistics environment.\nOk, now is this good or bad?\nWell, one could be disappointed by the fact that our agent was not able to reach the performance of a hand-coded heuristics approach.\nBut did we believe when we started that we could get a generic piece of code to cope with the non-trivial relations of our specific and fairly complex environment? Certainly not!\nAnd this was just a first shot - we did not yet start with hyperparameter tuning or the evaluation of alternative rewards.\nWhat do your experiences with reinforcement learning look like?\nWhich logistics problems did you solve with RL?\nDid you spot a bug somewhere in the code or do you want to suggest an improvement?\nOr do you have questions concerning the presented implementation/toolstack?\nJust feel free to drop us a note, thanks for reading!\nWladimir Hofmann - Clemens L. Schwarz - Fredrik Branding\n","permalink":"https://fladdimir.github.io/post/tugger-routing/","summary":"Case-Study on Reinforcement-Learning in Logistics","title":"Digital Twin for Assembly Line Material Provisioning Planning"},{"content":"Discrete Event Simulation is a widespread tool for analysis and design of logistics systems.\nHowever, most industrial applications are realized using commercial simulators, and existing open-source alternatives still seem to lack some of the convenient features commercial packages are offering.\nThe Casymda-package strives to add some of these features, building on established standards such as BPMN and SimPy.\nThis post will introduce main features and show how to run a simple example.\nGet the repo.\nExisting Discrete Event Simulation Packages Current applications of DES go beyond the traditional usage for systems planning. They include more operational use-cases such as virtual commissioning or short-term forecasts \u0026amp; optimization. Consequently, simulation models are getting integrated tightly into other IT-systems. This allows to increase process transparency and to improve our means to analyze, control, and optimize system performance.\nMost industrial simulation uses are still based on commercial packages.\nAnd there are good reasons for this.\nIf you\u0026rsquo;ve already worked with commercial DES packages (such as Anylogic/Arena/ExtendSim/FlexSim/PlantSimulation/Simio/\u0026hellip;YouNameIt), you probably learned to like some typical characteristics:\nblock-based graphical modeling of processes (often) vendor-specific scripting possibilities to define custom behavior and non-standard procedures (this is where things get fun) (3D) visualization / animation capabilities for debug / validation / presentation (fun as well, most of the time) domain-specific libraries with objects providing pre-built industry-specific behaviors (configuration and customization) interfacing options: spreadsheets, databases, socket, COM,\u0026hellip; (what\u0026rsquo;s the last one?) However, there are a couple of open-source alternatives too.\nEven though they tend to lack some of the commercial features described above, there are upsides such as better scalability and simplified interfacing.\nRelated to Python there are (at least) two popular DES packages: Salabim and SimPy. Both are not only free and open-source, but even built on top of the standard library of one of the world\u0026rsquo;s most popular programming languages.\nCasymda: Features \u0026amp; Implementation Based on SimPy3, Casymda adds bits of complementing functionality to gain some of the modeling convenience of commercial \u0026ldquo;block-based\u0026rdquo; DES-packages.\nIt facilitates the usage of bpmn-process-descriptions to generate corresponding simulation-model python-code. .bpmn-files (basically xml) can easily be created with the Camunda-Modeler.\nThis graphical modeling helps to maintain an overview of the high-level model-structure. Generated Casymda-models also include a generic, token-like animation of simulated processes out-of-the-box, ready to be run in a web-browser. For presentation and debugging, animations can be paused and their speed can be changed dynamically. Solely animation-related events are not scheduled if the simulation is run without visualization. This maximizes the execution speed - which becomes especially important when a high number of runs is necessary.\nFurther features of Casymda include simulated movements along shortest paths in a 2D-tilemap-space, and gradual typing for development convenience (checkout pyright if you are using vscode).\nLet\u0026rsquo;s have a quick look at a simple example Casymda-model, illustrating some basic ideas.\nThe animation below shows a simple process consisting of 3 Casymda-blocks: Entities are created in a Source, pass a process-step called TilemapMovement, and leave the system via a Sink.\nTo run the example just enter the following command from within the repository and visit http://localhost:5000:\ndocker-compose up web-animation-tilemap-simple-process Created block-objects can be parametrized with arguments provided as text-annotations (e.g. the inter_arrival_time=100 [seconds] of the entities at the source). The naming of blocks is parsed following the pattern ClassName:instance_name. The default process-animation includes additional information on the processed entities and on the state of each block.\nThe way in which animations are created by Casymda is inspired by the Anylogic implementation. A web-server is running the actual simulation, and providing frame information to be rendered by a browser. The corresponding Casymda functionality is implemented using flask and pixijs.\nBelow you can find an tilemap-animation of the TilemapMovement process step of the model. As specified in the text-annotation, entities move from_node=\u0026quot;A\u0026quot;, to_node=\u0026quot;C\u0026quot;. Tilemaps can be provided in .csv format, with field values indicating possible origin/destination nodes (e.g. A, B, and C), passable nodes (0), and impassable nodes (1). The size of each tile is configured as part of the tilemap configuration. Shortest paths and distances between all origin/destination nodes are computed using networkx.\nTo run the tilemap animation example just enter the following command and visit: http://localhost:5000\ndocker-compose up web-animation-tilemap-simple Additional resources For additional information, feel free to have a look at other projects built with Casymda (German).\nInterested in machine-learning? The next post will show how to use a Casymda-model to train a reinforcement learning algorithm to solve a production logistics problem - stay tuned ;)\n","permalink":"https://fladdimir.github.io/post/casymda/","summary":"A Python-Package for Animated Discrete-Event-Simulation based on BPMN and SimPy","title":"Introducing Casymda"}]